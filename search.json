[{"title":"IE8不支持indexOf的解决办法","url":"/2018/02/24/Ie8-indexof.html","content":"在IE8版本以下（含IE8）IE浏览都不支持数组的Indexof()方法，在使用indexOf方法前，执行一下下面的js就可以解决。 原理就是如果发现数组没有indexOf方法，会添加上这个方法。\n\n\n放在脚本的上面即可\n// Production steps of ECMA-262, Edition 5, 15.4.4.14// Reference: http://es5.github.io/#x15.4.4.14if (!Array.prototype.indexOf) &#123;  Array.prototype.indexOf = function(searchElement, fromIndex) &#123;    var k;    // 1. Let o be the result of calling ToObject passing    //    the this value as the argument.    if (this == null) &#123;      throw new TypeError(&#x27;&quot;this&quot; is null or not defined&#x27;);    &#125;    var o = Object(this);    // 2. Let lenValue be the result of calling the Get    //    internal method of o with the argument &quot;length&quot;.    // 3. Let len be ToUint32(lenValue).    var len = o.length &gt;&gt;&gt; 0;    // 4. If len is 0, return -1.    if (len === 0) &#123;      return -1;    &#125;    // 5. If argument fromIndex was passed let n be    //    ToInteger(fromIndex); else let n be 0.    var n = fromIndex | 0;    // 6. If n &gt;= len, return -1.    if (n &gt;= len) &#123;      return -1;    &#125;    // 7. If n &gt;= 0, then Let k be n.    // 8. Else, n&lt;0, Let k be len - abs(n).    //    If k is less than 0, then let k be 0.    k = Math.max(n &gt;= 0 ? n : len - Math.abs(n), 0);    // 9. Repeat, while k &lt; len    while (k &lt; len) &#123;      // a. Let Pk be ToString(k).      //   This is implicit for LHS operands of the in operator      // b. Let kPresent be the result of calling the      //    HasProperty internal method of o with argument Pk.      //   This step can be combined with c      // c. If kPresent is true, then      //    i.  Let elementK be the result of calling the Get      //        internal method of o with the argument ToString(k).      //   ii.  Let same be the result of applying the      //        Strict Equality Comparison Algorithm to      //        searchElement and elementK.      //  iii.  If same is true, return k.      if (k in o &amp;&amp; o[k] === searchElement) &#123;        return k;      &#125;      k++;    &#125;    return -1;  &#125;;&#125;\n\n","categories":["随手记"],"tags":["IE"]},{"title":"几个缓存概念","url":"/2019/07/25/cache-notion.html","content":"面试经常问的几个关于缓存的概念问题\n\n\n缓存穿透获取数据的流程是先获取缓存，如果缓存没有再去数据库。如果查询的数据在缓存和数据库中都没有，那么这个请求就会一直会请求数据库给数据库造成压力，这个就是缓存穿透。\n解决办法\n缓存控制，在数据库获取数据为空的时候也缓存\n采用布隆过滤器\n\n缓存击穿大量的请求同时请求同一个key，此时这个key刚好失效了，导致了所有的请求都直接打到后端的数据库上面。\n解决办法\n使用互斥锁。\n在缓存失效的时候不是立即去数据库取数据， 而是加一下互斥锁，拿到锁之后再判断是否有缓存，如果没有再去数据库取数据。\n\n缓存雪崩缓存雪崩是指多个key在同一个时间过期，造成压力忽然增高\n解决办法解决的方法是通过给key的失效时间增加一个随机值\n","categories":["随手记"]},{"title":"Docker 入门使用","url":"/2023/02/01/docker-basic.html","content":"整理一些 docker 镜像、容器还有其他常用的命令。\n\n\n镜像相关命令docker pull 镜像拉取文档：docker pull\n# docker pull [OPTIONS] NAME[:TAG|@DIGEST]OPTIONS：--all-tags , -a\t\t下载所有标签的镜像到本地--disable-content-trust\ttrue\t跳过验证--platform\t\t设置平台--quiet , -q\t\t不显示详情Examples：docker pull mysql:5.7\n\ndocker search 镜像搜索文档：docker search\ndocker search [OPTIONS] TERMOptions:-f, --filter filter   过滤器--format string   格式化显示--limit int       最大显示数量，默认是25--no-trunc        不显示描述# --filter用法$ docker  docker search --filter=is-official=true php# stars starts数量，大于等于# is-automated 是否自动构建# is-official 是否官方# --format用法$ docker search --format &#x27;&#123;&#123;.Name&#125;&#125;:&#123;&#123;.StarCount&#125;&#125;&#x27; mysql# .Name        镜像名称# .Description 镜像描述# .StarCount   stars 数量# .IsOfficial  是否是官方# .IsAutomated 是否自动化构建\n\ndocker rmi 镜像删除文档：docker rmi\n# 删除镜像docker rmi [OPTIONS] IMAGE [IMAGE...]OPTIONS：--force , -f\t\t强制删除镜像Examples$ docker rmi mysql\n\ndocker images 镜像列表# 显示所有镜像docker images [OPTIONS] [REPOSITORY[:TAG]]Options：-a, --all             显示所有的镜像--digests         显示镜像的信息-f, --filter filter   过滤显示--format string   格式化输出--no-trunc        Don&#x27;t truncate output-q, --quiet           只显示镜像ID# 字段解释# REPOSITORY 镜像的仓库源# TAG 镜像标签# IMAGE ID 镜像ID# CREATED 镜像创建时间# SIZE 镜像大小\n\n容器相关命令docker run 新建容器并启动文档：Docker run reference\ndocker run [OPTIONS] IMAGE [COMMAND] [ARG...]常用OPTIONS：--detach,-d：后台运行容器--env,-e：指定环境变量--env-file：环境变量文件--group-add：增加用户组--link：增加连接的容器--name：启动的容器名称--network：指定容器要连接的网络--volume,-v：挂载的外部目录--workdir , -w：指定工作目录Examples：docker run -d --name mysql57 mysql:5.7\n\ndocker ps 显示运行的容器文档：docker ps\ndocker ps [OPTIONS]OPTIONS：--all , -a\t\t查看所有的容器，包含没有运行的容器--filter , -f\t\tFilter output based on conditions provided--format\t\tPretty-print containers using a Go template--last , -n\t-1\t查看最近运行的几个容器 | docker ps -a -n=2：查看最近运行的两个容器--latest , -l\t\tShow the latest created container (includes all states)--no-trunc\t\t不显示额外输出--quiet , -q\t\t只显示容器ID--size , -s\t\tDisplay total file sizes\n\ndocker exec 在容器中执行命令文档：docker exec\ndocker exec [OPTIONS] CONTAINER COMMAND [ARG...]OPTIONS：--detach , -d\t\t后台运行--detach-keys\t\tOverride the key sequence for detaching a container--env , -e\t\t设置环境变量--env-file\t\t指定环境变量文件--interactive , -i\t\t保持stdin处于打开状态，交互式会话--privileged\t\tGive extended privileges to the command--tty , -t\t\tAllocate a pseudo-TTY--user , -u\t\tUsername or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;])--workdir , -w\t\t指定工作目录Examples：docker exec -it mysql57 /bin/bash\n\ndocker start 启动容器文档：docker start\n启动容器docker start [OPTIONS] CONTAINER [CONTAINER...]Examples:docker start mysql57\n\ndocker restart 重启容器文档：docker restart\n重启容器docker restart [OPTIONS] CONTAINER [CONTAINER...]OPTIONS--signal , -s 发送信号到容器--time , -tExamples：docker restart mysql57\n\ndocker stop 容器停止文档：docker stop\ndocker stop [OPTIONS] CONTAINER [CONTAINER...]Examples：docker stop mysql57\n\ndocker rm 删除容器文档：docker rm\ndocker rm [OPTIONS] CONTAINER [CONTAINER...]Options：--force , -f\t\t强制删除正在运行的容器--link , -l\t\t删除指定的链接--volumes , -v\t\t移除与容器关联的匿名卷Examples：docker rm mysql57\n\n其他一些常用命令docker logs 容器日志文档：docker logs\ndocker logs [OPTIONS] CONTAINEROptions：--details\t\t显示一些额外的扩展信息--follow , -f\t\t跟踪日志的输出--since\t\tShow logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)--tail , -n\tall\tNumber of lines to show from the end of the logs--timestamps , -t\t\tShow timestamps--until\t\tShow logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)Examples：docker logs -f --until=2s mysql57\n\ndocker top 容器内部进程文档：docker top\n查看docker容器内部的进程信息docker top CONTAINER [ps OPTIONS]\n\ndocker inspect 容器元数据文档：docker inspect\n查看容器中的元数据docker inspect [OPTIONS] NAME|ID [NAME|ID...]\n\ndocker cp 容器内外复制文档：docker cp\n在容器和本地文件系统之间复制文件/文件夹docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-Examples:docker cp ./some_file CONTAINER:/work\n\n帮助命令官方文档：https://docs.docker.com/engine/reference/run/\ndocker 命令 --help | docker所有的命令，都可以使用docker 命令 --help 来查看帮助命令docker version # 显示docker的版本信息docker info # 显示docker的系统信息，包括镜像和容器的数量","categories":["Docker"],"tags":["docker"]},{"title":"Docker Compose 命令说明","url":"/2023/02/05/docker-compose-command.html","content":"docker compose 常用的命令整理。\n\n\ndocker compose 命令基本格式https://docs.docker.com/compose/reference/\ndocker compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...]options：-f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。-p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。--verbose 输出更多调试信息。-v, --version 打印版本并退出。\n\nuphttps://docs.docker.com/engine/reference/commandline/compose_up/\nup 命令可以自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。链接的服务都将会被自动启动（除非已经处于运行状态）。大部分时候都可以直接通过该命令来启动一个项目。\ndocker compose up [OPTIONS] [SERVICE...]OPTIONS-d 在后台运行服务容器。--no-color 不使用颜色来区分不同的服务的控制台输出。--no-deps 不启动服务所链接的容器。--force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。--no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。--no-build 不自动构建缺失的服务镜像。-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。\ndownhttps://docs.docker.com/engine/reference/commandline/compose_down/\ndown 命令用来停止并移除容器、网络\n$ docker compose down [OPTIONS]OPTIONS--remove-orphans 删除未在 Compose 文件中定义的服务的容器。--rmi 把镜像也删除--volumes , -v 删除附加卷和匿名卷\n\nbuildhttps://docs.docker.com/engine/reference/commandline/compose_build/\nbuild 命令用来构建（重新构建）项目中的服务容器。\n如果修改了服务的 Dockerfile 文件或者是一些其他构建的选项，就需要运行 docker compose build 来重新构建\n$ docker compose build [OPTIONS] [SERVICE...]OPTIONS--force-rm 删除构建过程中的临时容器。--no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。--pull 始终尝试通过 pull 来获取更新版本的镜像。\n\nstarthttps://docs.docker.com/engine/reference/commandline/compose_start/\nstart 命令可以启动已经存在的服务容器。\n$ docker compose start [SERVICE...]\n\nstophttps://docs.docker.com/engine/reference/commandline/compose_stop/\nstop 命令可以停止已经处于运行状态的容器，但不删除它。\n$ docker compose stop [OPTIONS] [SERVICE...]OPTIONS--timeout , -t\n\nrestarthttps://docs.docker.com/engine/reference/commandline/compose_restart/\nrestart 命令可以重启项目中的服务。\n$ docker compose restart [OPTIONS] [SERVICE...]OPTIONS--no-deps 不要重新启动依赖服务。--timeout , -t 指定重启前停止容器的超时（默认为 10 秒）。\n\npausehttps://docs.docker.com/engine/reference/commandline/compose_pause/\npause 命令可以暂停一个服务容器\n$ docker compose pause [SERVICE...]\n\nunpausehttps://docs.docker.com/engine/reference/commandline/compose_unpause/\nunpause 命令可以恢复处于暂停状态中的服务。\n$ docker compose unpause [SERVICE...]\n\nrmhttps://docs.docker.com/engine/reference/commandline/compose_rm/\nrm 命令可以删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。\n$ docker compose rm [OPTIONS] [SERVICE...]OPTIONS--force , -f 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。--volumes , -v 删除容器所挂载的数据卷。--stop , -s\t如果需要，在移除之前停止容器\n\npshttps://docs.docker.com/engine/reference/commandline/compose_ps/\nps 命令可以列出项目中目前的所有容器。\n$ docker compose ps [OPTIONS] [SERVICE...]OPTIONS--all , -a\t列出所有容器--filter --format 格式化输出，table | json--quiet , -q 只显示ID--services 显示服务容器--status 按照状态过滤容器\n\ntophttps://docs.docker.com/engine/reference/commandline/compose_top/\ntop 命令可以查看各个服务容器内运行的进程。\n$ docker compose top [SERVICES...]\n\nrunhttps://docs.docker.com/engine/reference/commandline/compose_run/\nrun 命令可以在在指定服务上执行一个命令。\n$ docker compose run [OPTIONS] SERVICE [COMMAND] [ARGS...]OPTIONS-d 后台运行容器。--name NAME 为容器指定一个名字。--entrypoint CMD 覆盖默认的容器启动指令。-e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。-u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。--no-deps 不自动启动关联的服务容器。--rm 运行命令后自动删除容器，d 模式下将忽略。-p, --publish=[] 映射容器端口到本地主机。--service-ports 配置服务端口并映射到本地主机。-T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。\n\nexechttps://docs.docker.com/engine/reference/commandline/compose_exec/\nexec 命令可以在正在运行的容器中执行命令。\n$ docker compose exec [OPTIONS] SERVICE COMMAND [ARGS...]OPTIONS--detach , -d 在后台运行命令--env , -e 设置环境变量--user , -u 设置运行命令的用户--workdir , -w 设置工作目录\n\nkillhttps://docs.docker.com/engine/reference/commandline/compose_kill/\nkill 命令可以强制停止服务容器，也可以用来给容器发送信号\n$ docker compose kill [OPTIONS] [SERVICE...]OPTIONS--remove-orphans 删除未在 Compose 文件中定义的服务的容器。--signal , -s 发送信号，默认是 SIGKILL\n\nlogshttps://docs.docker.com/engine/reference/commandline/compose_logs/\nlogs 命令可以查看服务容器的输出。\n$ docker compose logs [OPTIONS] [SERVICE...]OPTIONS--since--tail , -n 显示最后的多少行--timestamps , -t\n\nporthttps://docs.docker.com/engine/reference/commandline/compose_port/\nport 命令打印端口绑定的公共端口。\ndocker compose port [OPTIONS] SERVICE PRIVATE_PORTOPTIONS--protocol 指定端口协议，默认 tcp\n\nconfighttps://docs.docker.com/engine/reference/commandline/compose_config/\nconfig 命令用来验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。\n$ docker compose config [OPTIONS] [SERVICE...]OPTIONS--format 格式化方式，可以选 yaml 或者 json--images 打印出使用到的所有的镜像--output , -o 把结果保存在文件中--services 打印出所有的服务--volumes 打印出所有挂载的目录\n\nimageshttps://docs.docker.com/engine/reference/commandline/compose_images/\nimages 命令可以列出创建的容器使用的镜像。\n$ docker compose images [OPTIONS] [SERVICE...]OPTIONS--format 显示格式，table | json--quiet , -q 仅显示ID\n","categories":["Docker"],"tags":["docker","docker-compose"]},{"title":"Golang学习 - 上下文（context.Context类型）","url":"/2023/01/28/go-context.html","content":"context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等\n\n\ncontext接口type Context interface &#123;    Deadline() (deadline time.Time, ok bool)    Done() &lt;-chan struct&#123;&#125;    Err() error    Value(key interface&#123;&#125;) interface&#123;&#125;&#125;\n\nDeadline 方法的第一个返回值表示还有多久到期，第二个返回值 表示是否到期Done 方法返回一个通道，可以监听该通道的信号，如果收到信号则表示通道已经关闭，需要执行退出Err 方法会返回退出的原因value 方法返回指定key对应的value，这是context携带的值\n默认的上下文context包中最常用的方法还是context.Background、context.TODO，这两个方法都会返回预先初始化好的私有变量background和todo\ngo/src/context/context.go)\nvar (    background = new(emptyCtx)    todo       = new(emptyCtx))func Background() Context &#123;    return background&#125;func TODO() Context &#123;    return todo&#125;\n这两个私有变量都是通过new(emptyCtx)语句初始化的，它们是指向私有结构体context.emptyCtx的指针\ntype emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123;    return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123;    return nil&#125;func (*emptyCtx) Err() error &#123;    return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;    return nil&#125;func (e *emptyCtx) String() string &#123;    switch e &#123;        case background:        return &quot;context.Background&quot;        case todo:        return &quot;context.TODO&quot;    &#125;    return &quot;unknown empty Context&quot;&#125;\n\nemptyCtx什么内容都没有，其不可以被退出，也不能携带值。context.Background是上下文的默认值，所有其他的上下文都应该从它衍生出来，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递context.TODO应该仅在不确定应该使用哪种上下文时使用\nWithCancelcontext.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号。\nfunc main() &#123;    // 生成一个可以取消的Context    ctx, cancelFunc := context.WithCancel(context.Background())    go Op(ctx)    // 3s之后取消主协程    time.Sleep(time.Second * 3)    cancelFunc()    // 等待子协程输出信息    time.Sleep(time.Second)    fmt.Println(&quot;main stop&quot;)&#125;func Op(ctx context.Context) &#123;    for &#123;        select &#123;        default:            time.Sleep(time.Second)            fmt.Println(&quot;Op run&quot;)        case &lt;-ctx.Done():            fmt.Println(&quot;parent stop&quot;)            return        &#125;    &#125;&#125;//Op run//Op run//Op run//parent stop//main stop\n\nWithTimeoutcontext.WithTimeout 函数接收父上下文(parent)和一个超时时间，能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。执行取消函数时功能和WithCancel一样。\nfunc main()  &#123;    // 基于context.Background()为根，创建一个3秒后自动取消的子Context    ctx, cancelFunc := context.WithTimeout(context.Background(), time.Second*3)    defer cancelFunc()    go Op(ctx)    // 等待超时，自动取消    &lt;-ctx.Done()    // 等待子协程输出信息    time.Sleep(time.Second)    fmt.Println(&quot;main stop&quot;)&#125;func Op(ctx context.Context)  &#123;    for &#123;        select &#123;        default:            time.Sleep(time.Second)            fmt.Println(&quot;Op run&quot;)        case &lt;-ctx.Done():            fmt.Println(&quot;parent stop&quot;)            return        &#125;    &#125;&#125;\n\nWithDeadlinecontext.WithDeadline 函数接收父上下文(parent)和一个截止时间，能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。执行取消函数时功能和WithCancel一样。\nfunc main()  &#123;    // 基于context.Background()为根，创建一个5秒后自动取消的子Context    ctx, cancelFunc := context.WithDeadline(context.Background(), time.Now().Add(time.Second*5))    defer cancelFunc()    go Op(ctx)    // 5s后自动取消    &lt;-ctx.Done()    // 等待子协程输出信息    time.Sleep(time.Second)    fmt.Println(&quot;main stop&quot;)&#125;func Op(ctx context.Context)  &#123;    for &#123;        select &#123;        default:            time.Sleep(time.Second)            fmt.Println(&quot;Op run&quot;)        case &lt;-ctx.Done():            fmt.Println(&quot;parent stop&quot;)            return        &#125;    &#125;&#125;\n\nWithValuecontext.WithValue 能从父 Context中创建一个子子 Context,并传体一个键值对信息给子 Context，在子 Context中，通过context.Value获取对应的值信息。\nfunc main() &#123;    valueCtx := context.WithValue(context.Background(), &quot;name&quot;, &quot;hanpy&quot;)    go func(ctx context.Context) &#123;        fmt.Printf(&quot;取出上下文中的name: %v\\n&quot;,ctx.Value(&quot;name&quot;))    &#125;(valueCtx)    time.Sleep(time.Second)    fmt.Println(&quot;main stop&quot;)&#125;\n\n","categories":["Golang"],"tags":["go","context"]},{"title":"Golang学习 - 通道（channel）","url":"/2023/01/26/go-channel.html","content":"Channel 类型是 Go 语言自带的唯一一个可以满足并发安全性的类型，一个通道相当于一个先进先出的队列，各个元素值都是严格按照发送的顺序排列的，先被发送到通道的元素值一定会先被接收。\n\n\n通道的基本使用通道的声明与初始化在声明时，channel必须与一个实际的类型T绑定在一起，代表通道中能够读取和传递的元素类型。通道的表示形式有如下有三种:chan T、chan←T、←chan T\n// 如果只是声明,那通道的值是nilvar ch chan intfmt.Println(ch)\t// nilvar ch1 = make(chan int)\t// 无缓冲通道var ch2 = make(chan int, 5)\t// 有缓冲通道\n\n通道写入数据通道的写入语法很简单\nch1 := make(chan int)ch1 &lt;- 1\n\n无缓冲通道的写入还有一个地方需要注意，能够向通道写入数据的前提是必须有另一个协程在读取通道，否则当前的协程就会陷入休眠，如果读和写在一个协程中，还会发生死锁。\nch1 := make(chan int)ch1 &lt;- 1// fatal error: all goroutines are asleep - deadlock!\n\n// 无缓冲通道的写入ch1 := make(chan int)ch1 &lt;- 1&lt;-ch1// fatal error: all goroutines are asleep - deadlock!\n\n通道读取数据通道中读取数据可以直接使用←c\n// 方式1data := &lt;- ch//方式2 data 表示接收到的数据。未接收到数据时，data为channel类型的零值，ok（布尔类型）表示是否接收到数据data,ok := &lt;- ch\n和写入数据一样，如果不能直接读取通道的数据，那么当前的读 取协程将陷入堵塞，直到有协程写入通道为止\n循环接收\nfor循环需要判断通道关闭，需要自己根据情况来跳出循环，否则就会一直取到通道类型0值的数据for...range会自动判断出channel已关闭，而无须通过判断来终止循环\npackage mainimport &quot;fmt&quot;func main() &#123;    ch := make(chan int)    // 写入    go func() &#123;        for i := 0; i &lt; 5; i++ &#123;            ch &lt;- i        &#125;        close(ch)    &#125;()    // 1. for接收    for  &#123;        out,ok := &lt;-ch        if !ok &#123;            fmt.Println(&quot;通道已关闭&quot;)            break        &#125;        fmt.Printf(&quot;接收数据 ==&gt; %v \\n&quot;, out)    &#125;    // 2. for...range接收    //for i := range ch &#123;    //\tfmt.Printf(&quot;接收数据 ==&gt; %v \\n&quot;, i)    //&#125;    fmt.Println(&quot;程序运行结束!&quot;)&#125;\n\n通道关闭通道的关闭，需要用到内置的close函数\nch := make(chan int)close(ch)\n\n重复关闭一个channel将导致panic异常，试图关闭一个nil值 的channel也将导致panic异常。\n通道底层原理通道数据结构go/src/runtime/chan.go | hchan\ntype hchan struct &#123;    qcount   uint           // 通道队列中的数据个数    dataqsiz uint           // 通道队列中的数据大小    buf      unsafe.Pointer // 存放实际数据的指针    elemsize uint16\t// 通道类型大小    closed   uint32\t// 通道是否关闭    elemtype *_type // 通道类型    sendx    uint   // 记录发送者在buf中的序号    recvx    uint   // 记录接受者在buf中的序号    recvq    waitq  // 读取的阻塞协程队列    sendq    waitq  // 写入的阻塞协程队列    lock mutex\t// 锁，并发保护&#125;\n\n对于有缓存的通道，存储在buf中的数据虽然是线性的数组，但是 用数组和序号recvx、recvq模拟了一个环形队列，recvx可以找到从buf哪个位置获取通道中的元素，而sendx能够找到写 入时放入buf的位置\n\n《Go语言底层原理剖析》中的图\n\n\n通道初始化使用make初始化通道，经过类型检查之会转换为OMAKE类型的节点，最后会调用了makechan函数，第1个参数代表通道的类型，第2个参数代表通道中元素的大小go/src/runtime/chan.go | makechan\n// t:通道类型// size:通道元素的大小func makechan(t *chantype, size int) *hchan &#123;    elem := t.elem    // compiler checks this but be safe.    if elem.size &gt;= 1&lt;&lt;16 &#123;        throw(&quot;makechan: invalid channel element type&quot;)    &#125;    if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123;        throw(&quot;makechan: bad alignment&quot;)    &#125;\t    // 计算为元素分配的大小    mem, overflow := math.MulUintptr(elem.size, uintptr(size))    if overflow || mem &gt; maxAlloc-hchanSize || size &lt; 0 &#123;        panic(plainError(&quot;makechan: size out of range&quot;))    &#125;    var c *hchan    switch &#123;        case mem == 0:\t// 当分配的大小为0时，只用在内存中分配hchan结构体的大小即 可。        c = (*hchan)(mallocgc(hchanSize, nil, true))        c.buf = c.raceaddr()        case elem.ptrdata == 0:\t// 当通道的元素中不包含指针时，连续分配hchan结构体大小+size 元素大小。        c = (*hchan)(mallocgc(hchanSize+mem, nil, true))        c.buf = add(unsafe.Pointer(c), hchanSize)        default:\t// 当通道的元素中包含指针时，需要单独分配内存空间，因为当元 素中包含指针时，需要单独分配空间才能正常进行垃圾回收。        c = new(hchan)        c.buf = mallocgc(mem, elem, true)    &#125;    c.elemsize = uint16(elem.size)    c.elemtype = elem    c.dataqsiz = uint(size)    lockInit(&amp;c.lock, lockRankHchan)    if debugChan &#123;        print(&quot;makechan: chan=&quot;, c, &quot;; elemsize=&quot;, elem.size, &quot;; dataqsiz=&quot;, size, &quot;\\n&quot;)    &#125;    return c&#125;\n\n通道写入原理go/src/runtime/chan.go | chansend\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123;    // 通过为nil，休眠    if c == nil &#123;        if !block &#123;            return false        &#125;        gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2)        throw(&quot;unreachable&quot;)    &#125;\t// ---省略代码---        // 加锁    lock(&amp;c.lock)    // 通道被关闭，直接panic    if c.closed != 0 &#123;        unlock(&amp;c.lock)        panic(plainError(&quot;send on closed channel&quot;))    &#125;\t    // 存在等待的接收者时，通过 runtime.send 直接将数据发送给阻塞的接收者    if sg := c.recvq.dequeue(); sg != nil &#123;        // Found a waiting receiver. We pass the value we want to send        // directly to the receiver, bypassing the channel buffer (if any).        send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3)        return true    &#125;\t    // 当缓冲区存在空余空间时，将发送的数据写入 Channel 的缓冲区    if c.qcount &lt; c.dataqsiz &#123;        // Space is available in the channel buffer. Enqueue the element to send.        qp := chanbuf(c, c.sendx)        if raceenabled &#123;            racenotify(c, c.sendx, nil)        &#125;        typedmemmove(c.elemtype, qp, ep)        c.sendx++        if c.sendx == c.dataqsiz &#123;            c.sendx = 0        &#125;        c.qcount++        unlock(&amp;c.lock)        return true    &#125;    // 当不存在缓冲区或者缓冲区已满时，等待其他 Goroutine 从 Channel 接收数据        if !block &#123;        unlock(&amp;c.lock)        return false    &#125;    // 在 channel 上阻塞，receiver 会帮我们完成后续的工作    gp := getg()    mysg := acquireSudog()    mysg.releasetime = 0    if t0 != 0 &#123;        mysg.releasetime = -1    &#125;    mysg.elem = ep    mysg.waitlink = nil    mysg.g = gp    mysg.isSelect = false    mysg.c = c    gp.waiting = mysg    gp.param = nil    c.sendq.enqueue(mysg)    atomic.Store8(&amp;gp.parkingOnChan, 1)    gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2)    KeepAlive(ep)    if mysg != gp.waiting &#123;        throw(&quot;G waiting list is corrupted&quot;)    &#125;    gp.waiting = nil    gp.activeStackChans = false    closed := !mysg.success    gp.param = nil    if mysg.releasetime &gt; 0 &#123;        blockevent(mysg.releasetime-t0, 2)    &#125;    mysg.c = nil    releaseSudog(mysg)    if closed &#123;        if c.closed == 0 &#123;            throw(&quot;chansend: spurious wakeup&quot;)        &#125;        panic(plainError(&quot;send on closed channel&quot;))    &#125;    return true&#125;\n在写入的开始就加锁了，可以看出通道是并发安全的。写入元素时，分成了3种不同的情况\n1. 有正在等待的读取协程hchan结构中的recvq字段存储了正在等待的协程链表，每个 协程对应一个sudog结构，它是对协程的封装，包含了准备获取的协程 中的元素指针等。c.recvq.dequeue()会返回第一个等待的协程，send函数将元素直接复制到对应的 协程中，再唤醒被堵塞的协程\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123;    // ...    if sg := c.recvq.dequeue(); sg != nil &#123;        // Found a waiting receiver. We pass the value we want to send        // directly to the receiver, bypassing the channel buffer (if any).        send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3)        return true    &#125;    // ...&#125;\ngo/src/runtime/chan.go | send\nfunc send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123;    if raceenabled &#123;        if c.dataqsiz == 0 &#123;            racesync(c, sg)        &#125; else &#123;            racenotify(c, c.recvx, nil)            racenotify(c, c.recvx, sg)            c.recvx++            if c.recvx == c.dataqsiz &#123;                c.recvx = 0            &#125;            c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz        &#125;    &#125;    if sg.elem != nil &#123;        sendDirect(c.elemtype, sg, ep)        sg.elem = nil    &#125;    gp := sg.g    unlockf()    gp.param = unsafe.Pointer(sg)    sg.success = true    if sg.releasetime != 0 &#123;        sg.releasetime = cputicks()    &#125;    // Gwaiting -&gt; Grunnable    goready(gp, skip+1)&#125;\n\nsendDirect将发送的数据直接拷贝到对应的地址上goready将等待接收数据的Goroutine标记成可运行状态Grunnable并把该Goroutine放到发送方所在的处理器的runnext上等待执行，该处理器在下一次调度时会立刻唤醒数据的接收方；\n2. 缓冲区有空余Channel包含缓冲区并且Channel中的数据没有装满的情况\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123;        // ---省略代码---    if c.qcount &lt; c.dataqsiz &#123;        // 计算出下一个可以存储数据的位置        qp := chanbuf(c, c.sendx)        if raceenabled &#123;            racenotify(c, c.sendx, nil)        &#125;        // 将发送的数据拷贝到缓冲区中并增加 sendx 索引和 qcount 计数器        typedmemmove(c.elemtype, qp, ep)        c.sendx++        if c.sendx == c.dataqsiz &#123;            c.sendx = 0        &#125;        c.qcount++        unlock(&amp;c.lock)        return true    &#125;    // ---省略代码---&#125;\n\n3. 缓冲区无空余(会阻塞发送协程)如果当前通道无缓冲区或者当前缓冲区已经满了，则代表当前协程的sudog结构需要放入sendq链表末尾中，并且当前协程陷入休眠状态，等待被唤醒重新执行\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123;    // ...    if !block &#123;        unlock(&amp;c.lock)        return false    &#125;\t    // 获取当前发送数据使用的协程(Goroutine)    gp := getg()    // 获取 runtime.sudog 结构并设置这一次阻塞发送的相关信息(其实就是包装sudog)    mysg := acquireSudog()    mysg.releasetime = 0    if t0 != 0 &#123;        mysg.releasetime = -1    &#125;    mysg.elem = ep    mysg.waitlink = nil    mysg.g = gp    mysg.isSelect = false    mysg.c = c    gp.waiting = mysg    gp.param = nil        // 将刚刚创建并初始化的 runtime.sudog 加入发送等待队列，    // 设置到当前 Goroutine 的 waiting 上，表示 Goroutine 正在等待该 sudog 准备就绪；    c.sendq.enqueue(mysg)    atomic.Store8(&amp;gp.parkingOnChan, 1)    // 将这个发送 g 从 Grunning -&gt; Gwaiting    gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2)    KeepAlive(ep)    // someone woke us up.    if mysg != gp.waiting &#123;        throw(&quot;G waiting list is corrupted&quot;)    &#125;    gp.waiting = nil    gp.activeStackChans = false    closed := !mysg.success    gp.param = nil    if mysg.releasetime &gt; 0 &#123;        blockevent(mysg.releasetime-t0, 2)    &#125;    mysg.c = nil    releaseSudog(mysg)    if closed &#123;        if c.closed == 0 &#123;            throw(&quot;chansend: spurious wakeup&quot;)        &#125;        panic(plainError(&quot;send on closed channel&quot;))    &#125;    return true&#125;\n\n通道读取原理读取通道和写入通道的原理非常相似，在运行时调用了chanrecv函数。\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123;\t// ---省略代码---        // Channel 的 sendq 队列中包含处于等待状态的 Goroutine 时，该函数会取出队列头等待的 Goroutine    if sg := c.sendq.dequeue(); sg != nil &#123;        recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3)        return true, true    &#125;\t    // 当 Channel 的缓冲区中已经包含数据时，从 Channel 中接收数据会直接从缓冲区中 recvx 的索引位置中取出数据进行处理    if c.qcount &gt; 0 &#123;        // Receive directly from queue        qp := chanbuf(c, c.recvx)        if raceenabled &#123;            racenotify(c, c.recvx, nil)        &#125;        if ep != nil &#123;            typedmemmove(c.elemtype, ep, qp)        &#125;        typedmemclr(c.elemtype, qp)        c.recvx++        if c.recvx == c.dataqsiz &#123;            c.recvx = 0        &#125;        c.qcount--        unlock(&amp;c.lock)        return true, true    &#125;    if !block &#123;        unlock(&amp;c.lock)        return false, false    &#125; \t// 获取当前发送数据使用的协程(Goroutine)    gp := getg()    // 获取 runtime.sudog 结构并设置这一次阻塞发送的相关信息(其实就是包装sudog)    mysg := acquireSudog()    mysg.releasetime = 0    if t0 != 0 &#123;        mysg.releasetime = -1    &#125;    mysg.elem = ep    mysg.waitlink = nil    gp.waiting = mysg    mysg.g = gp    mysg.isSelect = false    mysg.c = c    gp.param = nil    c.recvq.enqueue(mysg)    atomic.Store8(&amp;gp.parkingOnChan, 1)    gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2)      if mysg != gp.waiting &#123;        throw(&quot;G waiting list is corrupted&quot;)    &#125;    gp.waiting = nil    gp.activeStackChans = false    if mysg.releasetime &gt; 0 &#123;        blockevent(mysg.releasetime-t0, 2)    &#125;    success := mysg.success    gp.param = nil    mysg.c = nil    releaseSudog(mysg)    return true, success&#125;\n\n","categories":["Golang"],"tags":["go","channel"]},{"title":"Golang学习 - 数据类型","url":"/2022/12/12/go-data-type.html","content":"在 Go 语言中，有基本数据类型（原生数据类型）和复合数据类型（派生数据类型）\n\n\n基本数据类型基本类型包括：整型(int)、浮点型(float)、复数型(complex)、布尔型(bool)、字符串(string)、字符（byte、rune）\n复合数据类型数组（array）、切片（slice）、映射（map）、函数（function）、结构体（struct）、通道（channel）、接口（interface）、指针（pointer）\n\n\n整型有符号整型：int8、int16、int32(别名:rune)、int64、int无符号整型：uint8(别名:byte)、uint16、uint32、uint64、uint\n整型的取值范围\n重点需要记住常用的几个：int32（4字节），int64（8字节）\n\n浮点型浮点型表示存储的数据是实数,浮点类型分: float32 和float64 两种，默认是float64\n\n\n\n类型\n字节\n说明\n\n\n\nfloat32\n4\n32位的浮点型\n\n\nfloat64\n8\n64位的浮点型\n\n\n字符串Go语言中的字符串是基本类型，这一点和C语言是不一样的，使用字符串就像使用其他原生基本数据类型int、float32、float64、bool一样。\n字符串都是采用UTF-8字符集编码。字符串是用一对双引号（””）或反引号（ ）括起来定义,字符串不可变，可以用 + 操作符 连接两个字符串\n// 简单使用var s strings1 := &quot;hello&quot;// 多行s2 := `\tvar a int = 1\tvar b int = 2 `\n\n字符字符串中的每一个元素叫作“字符”，定义字符时使用单引号\n\n\n\n类型\n字节\n说明\n\n\n\nbyte\n1\n表示UTF8字符串中的单个字节的值,别名:unit8\n\n\nrune\n4\n表示单个unicode字符，别名:int32\n\n\n","categories":["Golang"],"tags":["go"]},{"title":"Docker DockerFile","url":"/2023/02/03/docker-file.html","content":"Dockerfile 是一个用来构建镜像的文本文件，里面包含了一条条构建镜像所需的指令和说明。\n\n\n官方文档：Dockerfile reference\n指令说明\n文件中的每一行都是一个指令，每一个指令都是大写字母（不是强制的），指令是是从往下进行执行的，每一个指令都会创建一个新的镜像层，并提交。\nFROM 指定基础镜像FROM指令用来指定基础镜像，必须的指令，并且是第一条指令\nDocker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。\nFROM nginx:alpine\n\nCOPY 复制文件COPY指令将从构建上下文目录中 &lt;源路径&gt;的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置\nCOPY my.cnf /etc/mysql/conf.d/my.cnf \n\n源路径可以是多个，也可以使用通配符来匹配，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等，可以通过 --chown=&lt;user&gt;:&lt;group&gt;和 --chmod=&lt;perms&gt; 来改变复制到容器之后文件的所属用户和权限\n目标路径可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录\nCOPY hom* /mydir/COPY --chown=mysql:mysql my.cnf my.cn # 会复制到WORKDIR指定的目录下面，并且用户和用户组修改为mysql\n\nADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。在 COPY 基础上增加了一些功能。\n\n源路径可以是一个URL，会尝试下载然后复制到目标位置（权限为0666），修改权限需要再来一层 RUN 指令\n如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去\n\nRUN 执行命令RUN 指令是用来执行命令行命令的(构建镜像时运行的指令)\n有两种方式\n\nshell格式：就像直接在命令行中输入的命令一样\nexec格式：RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]\n\n# shell格式RUN chmod 0444 /etc/mysql/conf.d/my.cnf# exec格式RUN [&quot;chmod&quot;, &quot;0444&quot;, &quot;/etc/mysql/conf.d/my.cnf&quot;]\n\n每个指令都会生成一层，Run指令也是同样，所以在使用的时候最好是通过 &amp;&amp; 来连接各个命令，这样可以减少生成的层数。\nRUN set -x; buildDeps=&#x27;gcc libc6-dev make wget&#x27; \\    &amp;&amp; apt-get update \\    &amp;&amp; apt-get install -y $buildDeps \\    &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\    &amp;&amp; mkdir -p /usr/src/redis \\    &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\    &amp;&amp; make -C /usr/src/redis \\    &amp;&amp; make -C /usr/src/redis install \\    &amp;&amp; rm -rf /var/lib/apt/lists/* \\    &amp;&amp; rm redis.tar.gz \\    &amp;&amp; rm -r /usr/src/redis \\    &amp;&amp; apt-get purge -y --auto-remove $buildDeps\n\n拿上面的例子来说，在命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，这样会减小镜像的体积。\nCMD 容器启动命令CMD 指令就是用于指定默认的容器主进程的启动命令的。RUN 指令是在镜像构建的时候执行的，CMD 指令是容器启动的时候（docker run）执行的。\n命令格式\n\nshell格式：CMD &lt;命令&gt;\nexec格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]\n\n使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。\nCMD echo $HOME# 实际的命令会被包装为 sh -c 的参数的形式进行执行CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]\n\n需要注意的地方\n\nCMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\n如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。\n\nFROM ubuntu#1 docker run 覆盖情况CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;/bin/bash&quot;]#2 多个CMD覆盖情况CMD echo &quot;This is a test.&quot;\n\n# （假设没有第二个CMD指令的情况）这样写就是用cat /etc/os-release 替换了 /bin/bashdocker run -it ubuntu cat /etc/os-release# 虽然有两个CMD指令，但是第二个会覆盖第一个docker run -it ubuntu\n\nENTRYPOINT 入口点ENTRYPOINT 指令的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，需要通过docker run的参数--entrypoint来指定。当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令，换句话说实际执行时，将变为：&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot;\n需要注意的地方\n\ndocker run -it ubuntu cat /etc/os-release 执行时候执行的命令，也会被当做ENTRYPOINT的参数\nFROM ubuntu:18.04RUN apt-get update \\    &amp;&amp; apt-get install -y curl \\    &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://myip.ipip.net&quot; ]\n\n$ docker build -t myip .# -i 会作为ENTRYPOINT指令的参数，这样就能输出header头信息了$ docker run myip -i\n如果有多个 ENTRYPOINT 指令最后一条生效\n\n\nENV 设置环境变量ENV 指令用来设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。\n格式有两种：\n\nENV [key] [value]\nENV [key1]=[value1] [key2]=[value2]\n\nENV VERSION=1.0 DEBUG=on \\    NAME=&quot;Happy Feet&quot;\n\n下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、FROM、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD、RUN。\nARG 构建参数ARG &lt;参数名&gt;[=&lt;默认值&gt;]\nARG 和 ENV 的效果一样，都是设置环境变量。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。\n构建命令 docker build 中可以用 --build-arg &lt;参数名&gt; = &lt;值&gt; 来覆盖。\n# 只在 FROM 中生效ARG DOCKER_USERNAME=libraryFROM $&#123;DOCKER_USERNAME&#125;/alpine# 要想在 FROM 之后使用，必须再次指定ARG DOCKER_USERNAME=libraryRUN set -x ; echo $&#123;DOCKER_USERNAME&#125;\n\nVOLUME 定义匿名卷定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。\n作用：\n\n避免重要的数据，因容器重启而丢失，这是非常致命的。\n避免容器不断变大。\n\nEXPOSE 暴露端口格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]\nEXPOSE 指令是声明容器运行时提供服务的端口，这只是一个声明，在容器运行时并不会因为这个声明应用就会开启这个端口的服务。\n作用：\n\n帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射\n运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口\n\nWORKDIR 指定工作目录格式: WORKDIR &lt;工作目录路径&gt;\n使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。\nWORKDIR /appRUN echo &quot;hello&quot; &gt; world.txt\n\n会在/app/word.txt写入内容\nUSER 指定当前用户格式：USER &lt;用户名&gt;[:&lt;用户组&gt;]\nUSER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。\n注意，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。\n","categories":["Docker"],"tags":["docker","Dockerfile"]},{"title":"Docker Compose 模版文件","url":"/2023/02/04/docker-compose-yam.html","content":"Docker Compose 是定义和运行多个 Docker 容器的应用。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）\n\n\n两个术语服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。项目 (project)：由一组关联的应用容器组成的一个完整业务单元。\nDocker Compose 模板文件常用指令默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。\n# docker compose的版本version: &quot;3&quot;# 服务列表services:  # 服务的名称是 webapp  webapp:  \t# 使用的惊喜那个是 examples/web    image: examples/web    # 映射的端口    ports:      - &quot;80:80&quot;    # 挂载的目录    volumes:      - &quot;/data&quot;\n\nbuildCompose file build reference (docker.com)\n指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。会使用这个Dockerfile来生成镜像\nversion: &quot;3&quot;services:  nginx:    build: ./nginx\n\nbuild指定的路径里面默认的Dockerfile的名字就是Dockerfile\ncontext、dockerfile可以使用 context 指令指定 Dockerfile 所在文件夹的路径。使用 dockerfile 指令指定 Dockerfile 文件名。\nversion: &quot;3&quot;services:  nginx:    build:      context: ./nginx      dockerfile: Dockerfile-nginx\n\narg指令指定构建镜像时的变量，就是在Dockerfile中定义的\ncommand覆盖容器启动后默认执行的命令（也就是在dockerFile中定义的CMD指令）\n如果值设置为 null,就会以镜像中的为准，如果值为[]或者&#39;&#39;,就会覆盖镜像中的并设置为空\ncontainer_name指定容器的名称，默认将会使用 项目名称_服务名称_序号 这样的格式\n注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称\ndepends_on声明依赖关系，白话意思就是要启动现在这个服务要先启动谁\nversion: &quot;3&quot;services:  nginx:    build:       context: ./nginx      dockerfile: DockerFile-nginx    container_name: hanpy_nginx    depends_on:      - redis      - php\n\n瞎写的，举例一下用法\ndns自定义 DNS 服务器。可以是一个值，也可以是一个列表。\ndns: 8.8.8.8dns:  - 8.8.8.8  - 114.114.114.114\n\ndns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。\ndns_search: example.comdns_search:  - domain1.example.com  - domain2.example.com\n\nentrypoint指定服务容器启动后执行的入口文件，这个会覆盖在DockerFile中ENTRYPOINT指令所设置的\nenv_file从文件中获取环境变量，可以为单独的文件路径或列表。\n如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。\n如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。\nenv_file: .envenv_file:  - ./common.env  - ./apps/web.env  - /opt/secrets.env\n\n环境变量文件中每一行必须符合格式，支持 # 开头的注释行。\n# common.env: Set development environmentPROG_ENV=development\n\nenvironment设置环境变量。你可以使用数组或字典两种格式。\n有两种设置方式：\nenvironment:  RACK_ENV: development  SHOW: &quot;true&quot;  USER_INPUT:  environment:  - RACK_ENV=development  - SHOW=true  - USER_INPUT\n\nenv_file 和 environment 同时设置，environment 设置的优先\nextra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。\nextra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot;\n\n会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。\n8.8.8.8 googledns52.1.157.61 dockerhub\n\nimage指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。\nlabels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。\nlinks链接到其它服务中的容器。使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以。\nlinks: - db - db:database - redis\n\nports暴露端口信息。\n使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\nports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot;\n\nvolumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。\n该指令中路径支持相对路径。\nvolumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro\n","categories":["Docker"],"tags":["docker","docker-compose"]},{"title":"Golang学习 - defer延迟调用","url":"/2023/01/23/go-defer.html","content":"Go 语言的 defer 会在当前函数返回前执行传入的函数，它会经常被用于关闭文件描述符、关闭数据库连接以及解锁资源。\n\n\ndefer关键字的常见使用场景资源释放\nfunc CopyFile(dstName, srcName string) (written int64, err error) &#123;    src, err := os.Open(srcName)    if err != nil &#123;        return 0, err    &#125;    defer src.Close()    dst, err := os.Create(dstName)    if err != nil &#123;        return 0, err    &#125;    defer dst.Close()    return io.Copy(dst, src)&#125;\n\n捕获错误defer的特性是无论后续函数的执行路径如何以及是否发生了panic，在函数结束后一定会得到执行，所以用来捕获错误就很适合了\npackage mainimport &quot;fmt&quot;func main() &#123;    executeOp()    fmt.Println(&quot;main end&quot;)&#125;func executeOp() &#123;    defer func() &#123;        if err := recover(); err != nil &#123;            fmt.Println(err)        &#125;        fmt.Println(&quot;recover func msg&quot;)    &#125;()    panic(&quot;executeOp func panic msg&quot;)    fmt.Println(&quot;executeOp end&quot;)&#125;// executeOp func panic msg// recover func msg// main end\n\ndefer使用时的注意事项执行顺序：在同一个函数中，defer函数调用的执行顺序与它们分别所属的defer语句的出现顺序（更严谨地说，是执行顺序）完全相反。\npackage mainimport &quot;fmt&quot;func main() &#123;    for i := 0; i &lt; 5; i++ &#123;        defer fmt.Println(i)    &#125;    fmt.Println(&quot;main stop&quot;)&#125;// 4// 3// 2// 1// 0\n\n参数的预计算函数到达defer语句时，延迟调用的参数将立 即求值，传递到defer函数中的参数将预先被固定，而不会等到函数执 行完成后再传递参数到defer中。\nfunc main() &#123;    i := 10    defer fmt.Printf(&quot;defer:%d\\n&quot;, i)    i++    defer fmt.Printf(&quot;main:%d\\n&quot;, i)&#125;// main:11// defer:10\n\n想要解决这个问题的方法非常简单，我们只需要向defer关键字传入匿名函数：虽然调用defer关键字时也使用值传递，但是因为拷贝的是函数指针，所以会打印出符合预期的结果。\nfunc main() &#123;    i := 10    defer func() &#123;        fmt.Printf(&quot;defer:%d\\n&quot;, i)    &#125;()    i++    defer fmt.Printf(&quot;main:%d\\n&quot;, i)&#125;// main:11// defer:11\n\n返回值陷阱还有一种特殊的情况需要注意，就是函数执行完在defer中对返回值修改的情况\nvar g int = 100func main() &#123;\ti := f()\tfmt.Printf(&quot;main %d \\n&quot;, i)\t// 100&#125;func f() (r int) &#123;\tdefer func() &#123;\t\tg = 200\t&#125;()\treturn g&#125;\n\nvar g int = 100func main() &#123;\ti := f()\tfmt.Printf(&quot;main %d \\n&quot;, i) // 200&#125;func f() (r int) &#123;\tr = g\tdefer func() &#123;\t\tr = 200\t&#125;()\treturn r&#125;\n\n出现上面的情况是因为return并不是原子的，包含下面几步，将返回值保存在栈上→执行defer函数→函数返回\n第一种情况g=100r=gg=200return第二种情况g=100r=gr=200r=200return\n\n\n\ndefer的数据结构type _defer struct &#123;    siz     int32 // includes both arguments and results    started bool    heap    bool    openDefer bool    sp        uintptr  // sp at time of defer    pc        uintptr  // pc at time of defer    fn        *funcval // can be nil for open-coded defers    _panic    *_panic  // panic that is running defer    link      *_defer    fd   unsafe.Pointer // funcdata for the function associated with the frame    varp uintptr        // value of varp for the stack frame    framepc uintptr&#125;\n\n\nsiz 是参数和结果的内存大小；\nsp 和 pc 分别代表栈指针和调用方的程序计数器；\nfn 是 defer 关键字中传入的函数；\n_panic 是触发延迟调用的结构体，可能为空；\nopenDefer 表示当前 defer 是否经过开放编码的优化；\n\nruntime._defer结构体是延迟调用链表上的一个元素，所有的结构体都会通过 link 字段串联成链表。\n\n","categories":["Golang"],"tags":["go","defer"]},{"title":"Golang面试题整理","url":"/2022/10/13/go-exam-list.html","content":"常见的面试题整理，来源是各个地方…\n\n\n1. Go有那些数据类型基础类型：整型、浮点型、布尔型、字符串、字符 复合类型：数组、切片、map、指针、channel\n\n2. 方法与函数的区别在Go语言中函数是一等公民，可以赋值给变量也可以在函数间传递，函数是不属于任何自定义结构的的。方法必须有接收者才可以\n3. 方法是值接收者和是指针接收者的区别值类型的接收者，无论调用者是对象还是指针对象，修改数据对调用者是没有影响的指针类型的接收者，无论调用者是对象还是指针对象，修改数据都会影响调用者\n4. 函数返回局部变量的指针是否安全？一般来说局部变量会在函数返回之后销毁，因此被返回的引用就成为了”无所指”的引用。不过这样的情况在go语言中是安全的，Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上，因为他们不在栈区，即使释放函数，其内容也不会受影响。\n5. 函数参数传递到底是值传递还是引用传递？Go语言中所有的参数传递都是值传递，都是一个副本、一个拷贝所有传给函数的参数值都会被复制，函数在其内部使用的并不是参数值的原值，而是它的副本。值类型，所以每一次复制都会拷贝它，以及它的所有元素值。引用类型，比如：切片、字典、通道，像上面那样复制它们的值，只会拷贝它们本身而已，并不会拷贝它们引用的底层数据。也就是说，这时只是浅表复制，而不是深层复制。\n6. 内置函数make和new的区别？变量的初始化是分为两个步骤的，声明和分配内容。var是用来声明的，new和make是用来分配内存的。var声明值类型会自动分配内存，如果是引用类型是不会自动分配内存的，默认是nil。new可以给任意类型分配内存，返回值是一个指向该类型的指针make函数只能给slice、map、channel分配内存，返回值是类型本身\n7. 设置GOPATH的意义可以把GOPATH理解为Go语言的工作目录，它可以是一个目录也可以是多个目录，每个目录都代表一个工作区，利用这些工作区来放置Go的源码文件，编译之后生成的文件，还有安装后的归档文件\n","categories":["面试题","Golang"],"tags":["面试"]},{"title":"Golang学习 - 垃圾回收机制（GC）","url":"/2023/04/03/go-gc.html","content":"垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，可以自动释放不需要的内存对象，并让出存储器资源。\n\n\n一、垃圾回收的认识1.1、垃圾回收的定义当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而负责垃圾回收的程序组件，即为垃圾回收器。垃圾回收器的执行过程被划分为两个半独立的组件：\n\n赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。\n回收器（Collector）：负责执行垃圾回收的代码。\n\n1.2、根对象根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象。\n下面的都是根对象\n\n全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。\n执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。\n寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。\n\n1.3、常见的垃圾回收机制GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这两种形式。\n追踪式 GC：\n从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的对象，从而回收所有可回收的对象。\n引用计数式 GC：\n每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。\n二、Go Gc2.1、标记-清除（mark and sweep）算法Golang1.3之前的时候主要用的普通的标记-清除算法，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段\n\n标记阶段 — 从根对象出发查找并标记堆中所有存活的对象；\n清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表；\n\n标记清除算法明了，但是需要在一开始就需要进行 STW（stop the world）让程序暂停，效率很低。\n2.2、三色标记三色标记法实际上就是通过三个阶段的标记来确定清除的对象都有哪些。白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收；黑色对象：已经被标记（不会被回收）灰色对象：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；\n简单来说三色标记在工作的时候程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。\n三色标记垃圾收集器的执行过程\n\n从灰色对象的集合中选择一个灰色对象并将其标记成黑色；\n将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收；\n重复上述两个步骤直到对象图中不存在灰色对象；\n\n\n\n\nA、F 是根节点，所以标记为灰色\n从灰色的集合中取出一个 A，并标记为黑色\n将 A 指向的对象 B 标记为灰色\n\n下面是三色标记完成之后的状态：\n\n\n用户程序对标记结果的影响\n用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW。\n\n\n用户程序建立了从 A 对象到 D 对象的引用，但是因为程序中已经不存在灰色对象了，所以 D 对象会被垃圾收集器错误地回收。这种情况叫悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性，想要并发或者增量地标记对象还是需要使用屏障技术。\n2.3、屏障技术内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束。\n想要在并发或者增量的标记算法中保证正确性（对象不丢失），我们需要达成以下两种三色不变性中的一种\n\n强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象\n弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径\n\n\n\n插入写屏障\n可以满足强三色不变式(不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)\nwritePointer(slot, ptr):    shade(ptr)    *slot = ptr\n\n当执行类似 *slot = ptr 的表达式时，我们会执行上述写屏障通过 shade 函数尝试改变指针的颜色。如果 ptr 指针是白色的，那么该函数会将该对象设置成灰色，其他情况则保持不变。\n\n举例：在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)\n\n\n\n上图是垃圾收集器和用户程序交替运行的场景：\n\n垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；\n用户程序修改 A 对象的指针，将原本指向 B 对象的指针指向 C 对象，这时触发写屏障将 C 对象标记成灰色；\n垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色；\n\n在 Go 语言 v1.7 版本之前,会使用插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。在实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描\n删除写屏障\n因为一旦该写屏障 开始工作，它会保证开启写屏障时堆上所有对象的可达，所以也被称作快照垃圾收集（Snapshot GC）\n老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。\n\n被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。\n\n\n\n上图是垃圾收集器和用户程序交替运行的场景:\n\n垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；\n用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变；\n用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色；\n垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色；\n\n混合写屏障Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈重新扫描的过程，极大的减少了STW的时间\n混合写屏障规则&amp;&amp;具体操作：\n\nGC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，\nGC期间，任何在栈上创建的新对象，均为黑色。\n被删除的对象标记为灰色。\n被添加的对象标记为灰色。\n\n","categories":["Golang"],"tags":["gc"]},{"title":"Gin框架学习记录 - 中间件的使用","url":"/2023/03/27/go-gin-middleware.html","content":"Gin 框架中间件的使用方式\n\n\n官方文档中有关中间件的内容（这个文档写的真的是看的费劲啊…..）不使用默认的中间件 | Gin Web Framework (gin-gonic.com)使用 BasicAuth 中间件 | Gin Web Framework (gin-gonic.com)使用中间件 | Gin Web Framework (gin-gonic.com)在中间件中使用 Goroutine | Gin Web Framework (gin-gonic.com)\n默认的中间件gin.Default() 会使用 Logger(), Recovery() 两个中间件Logger 中间件将日志写入 gin.DefaultWriter，即使你将 GIN_MODE 设置为 releaseRecovery 中间件会 recover 任何 panic。如果有 panic 的话，会写入500。\n// Default 使用 Logger 和 Recovery 中间件engine := gin.Default()// github.com/gin-gonic/gin@v1.7.2/gin.gofunc Default() *Engine &#123;    debugPrintWARNINGDefault()    engine := New()    engine.Use(Logger(), Recovery())    return engine&#125;// github.com/gin-gonic/gin@v1.7.2/logger.gofunc Logger() HandlerFunc &#123;    return LoggerWithConfig(LoggerConfig&#123;&#125;)&#125;// github.com/gin-gonic/gin@v1.7.2/recovery.gofunc Recovery() HandlerFunc &#123;    return RecoveryWithWriter(DefaultErrorWriter)&#125;\n\n全局中间件全局中间件顾名思义就是所有的请求都会使用到的。上面的Logger(), Recovery()两个中间件就是全局中间件。\n单个路由使用r := gin.New()// 路由使用单个中间件r.GET(&quot;/m1&quot;, gin.Logger(), func(ctx *gin.Context) &#123;    // ...&#125;)// 单个路由使用多个中间件r.GET(&quot;/m2&quot;, gin.Logger(), gin.Recovery(), func(ctx *gin.Context) &#123;    // ...&#125;)r.Run(&quot;:9090&quot;)\n\n路由组中使用r := gin.New()uGroup := r.Group(&quot;/user&quot;).Use(gin.Logger())&#123;    uGroup.GET(&quot;/get&quot;, func(ctx *gin.Context) &#123;        // ...    &#125;)&#125;r.Run(&quot;:9090&quot;)\n\n自定义中间件的使用从 gin.Logger() 和 gin.Recovery() 的源码中可以看到，定义中间件，只需要返回类型是gin.HandlerFunc 即可c.Next() ： 而要终止执行时则需调用c.Abort() ：终止请求\n// 自定义中间件func MyMiddleware() gin.HandlerFunc &#123;    return func(ctx *gin.Context) &#123;        fmt.Println(&quot;MyMiddleware--请求前&quot;)        token := ctx.DefaultQuery(&quot;token&quot;, &quot;&quot;)        if token != &quot;hanpy&quot; &#123;            // 终止执行调用这个函数            ctx.JSON(400, gin.H&#123;&quot;errorMsg&quot;: &quot;token验证失败&quot;&#125;)            ctx.Abort()        &#125;        // 继续执行调用这个函数        ctx.Next()        fmt.Println(&quot;MyMiddleware--请求后&quot;)    &#125;&#125;r := gin.New()r.Use(gin.Logger())r.GET(&quot;/check&quot;, MyMiddleware(), func(ctx *gin.Context) &#123;    fmt.Println(&quot;输出之前...&quot;)    ctx.JSON(200, gin.H&#123;&quot;status&quot;: &quot;OK!&quot;&#125;)&#125;)r.Run(&quot;:9090&quot;)\n\n#1$ curl --url &quot;http://127.0.0.1:9090/check&quot;&#123;&quot;errorMsg&quot;:&quot;token验证失败&quot;&#125;#1 控制台输出MyMiddleware--请求前MyMiddleware--请求后[GIN] 2023/03/27 - 22:09:02 | 400 |     147.361µs |       127.0.0.1 | GET      &quot;/check&quot;#2$ curl --url &quot;http://127.0.0.1:9090/check?token=hanpy&quot;&#123;&quot;status&quot;:&quot;OK!&quot;&#125;#2 控制台输出MyMiddleware--请求前输出之前...MyMiddleware--请求后[GIN] 2023/03/27 - 22:09:41 | 200 |      187.88µs |       127.0.0.1 | GET      &quot;/check?token=hanpy&quot;\n\n多个中间件的执行// 自定义中间件1func OneMiddleware() gin.HandlerFunc &#123;    return func(ctx *gin.Context) &#123;        fmt.Println(&quot;One中间件-请求前&quot;)        ctx.Next()        fmt.Println(&quot;One中间件-请求后&quot;)    &#125;&#125;// 自定义中间件2func TwoMiddleware() gin.HandlerFunc &#123;    return func(ctx *gin.Context) &#123;        fmt.Println(&quot;Two中间件-请求前&quot;)        ctx.Next()        fmt.Println(&quot;Two中间件-请求后&quot;)    &#125;&#125;func main() &#123;    r := gin.Default()    r.GET(&quot;/multipleMiddleware&quot;, OneMiddleware(), TwoMiddleware(), func(ctx *gin.Context) &#123;        fmt.Println(&quot;multipleMiddleware方法输出&quot;)    &#125;)    _ = r.Run(&quot;:9090&quot;)&#125;\n\n#1 $ curl --url &quot;http://127.0.0.1:9090/multipleMiddleware&quot;#1 控制台输出One中间件-请求前Two中间件-请求前multipleMiddleware方法输出Two中间件-请求后One中间件-请求后[GIN] 2023/03/27 - 22:22:59 | 200 |      18.089µs |       127.0.0.1 | GET      &quot;/multipleMiddleware&quot;\n\n","categories":["Golang","Gin"],"tags":["go","gin"]},{"title":"Gin框架学习记录 - 快速开始","url":"/2023/03/23/go-gin-quick.html","content":"Gin 框架 hello word\n\n\n文档地址\nhttps://github.com/gin-gonic/gin\n文档 | Gin Web Framework (gin-gonic.com)\nGin中文文档\n\n安装go get -u github.com/gin-gonic/gin\n\nHello Wordpackage mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123;    // 创建一个默认的路由引擎    engine := gin.Default()    // 注册路由,并设置一个匿名的handlers，返回JSON格式数据    engine.GET(&quot;/&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;            &quot;msg&quot;: &quot;请求成功&quot;,        &#125;)    &#125;)    // 启动服务，并监听端口9090，    // 不填默认监听 0.0.0.0:8080    _ = engine.Run(&quot;:9090&quot;)&#125;\n启动服务➜ go run main.go[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode)[GIN-debug] GET    /                         --&gt; main.main.func1 (3 handlers)[GIN-debug] Listening and serving HTTP on :9090\n\n➜ curl localhost:9090&#123;&quot;msg&quot;:&quot;请求成功&quot;&#125;%\n\n","categories":["Golang","Gin"],"tags":["go","gin"]},{"title":"Gin框架学习记录 - 参数绑定","url":"/2023/03/26/go-gin-bind.html","content":"单独接收参数应该在实际的项目中用的不多，因为灵活性比较差，而且不容易扩展，用到的更多的应该是参数绑定。\n\n\nGin提供了Must bind 和 Should bind两种类型的绑定方法。Bind*类型的方法是对MustBindWith封装；Should*类型的方法是对ShouldBindWith的封装。\n\nMust bind \n方法： Bind, BindJSON, BindXML, BindQuery, BindYAML行为：些方法属于 MustBindWith 的具体调用。 如果发生绑定错误，则请求终止，并触发 c.AbortWithError(400, err).SetType(ErrorTypeBind)。响应状态码被设置为 400 并且 Content-Type 被设置为 text/plain; charset=utf-8。 如果您在此之后尝试设置响应状态码，Gin 会输出日志 [GIN-debug] [WARNING] Headers were already written. Wanted to override status code 400 with 422。 \n\nShould bind\n方法：ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML行为：这些方法属于 ShouldBindWith 的具体调用。 如果发生绑定错误，Gin 会返回错误并由开发者处理错误和请求\n\n\n绑定GET参数分别使用BindQuery 和 ShouldBindQuery\ntype User struct &#123;    Name string `json:&quot;name&quot; form:&quot;name&quot; binding:&quot;required&quot;` // 必填    Age  int    `json:&quot;age&quot; form:&quot;age&quot; binding:&quot;required&quot;`   // 必填    Home string `json:&quot;home&quot; form:&quot;home&quot; binding:&quot;required&quot;` // 必填&#125;func Bind(r *gin.Engine) &#123;    bindRoute := r.Group(&quot;/bindGet&quot;)    &#123;        // BindQuery        bindRoute.GET(&quot;/getMust&quot;, func(ctx *gin.Context) &#123;            user := &amp;User&#123;&#125;            err := ctx.BindQuery(user)            if err != nil &#123;                ctx.JSON(200, gin.H&#123;&quot;error&quot;: fmt.Sprintln(err)&#125;)                return            &#125;            ctx.JSON(200, gin.H&#123;&quot;user&quot;: user&#125;)        &#125;)\t\t        // ShouldBindQuery        bindRoute.GET(&quot;/getShould&quot;, func(ctx *gin.Context) &#123;            user := &amp;User&#123;&#125;            err := ctx.ShouldBindQuery(user)            if err != nil &#123;                ctx.JSON(200, gin.H&#123;&quot;error&quot;: fmt.Sprintln(err)&#125;)                return            &#125;            ctx.JSON(200, gin.H&#123;&quot;user&quot;: user&#125;)        &#125;)    &#125;&#125;\n\n使用BindQuery的情况\n#1 三个字段都是必须要传的，只传一个会输出错误$ curl &quot;http://127.0.0.1:9090/bindGet/getMust?home=beijing&quot;&#123;&quot;error&quot;:&quot;Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag\\nKey: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag\\n&quot;&#125;%#2 同上一样的请求，看一下头信息$ curl -i &quot;http://127.0.0.1:9090/bindGet/getMust?home=beijing&quot;HTTP/1.1 400 Bad RequestDate: Sun, 26 Mar 2023 12:32:45 GMTContent-Length: 172Content-Type: text/plain; charset=utf-8&#123;&quot;error&quot;:&quot;Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag\\nKey: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag\\n&quot;&#125;#3 控制台输出[GIN-debug] [WARNING] Headers were already written. Wanted to override status code 400 with 200[GIN] 2023/03/26 - 20:32:45 | 200 |      87.344µs |       127.0.0.1 | GET      &quot;/bindGet/getMust?home=beijing&quot;#4 正常绑定情况$ curl &quot;http://127.0.0.1:9090/bindGet/getMust?home=beijing&amp;name=hanpy&amp;age=30&quot;&#123;&quot;user&quot;:&#123;&quot;name&quot;:&quot;hanpy&quot;,&quot;age&quot;:30,&quot;home&quot;:&quot;beijing&quot;&#125;&#125;\n\n从上面的信息可以看出，使用BindQuery(Must Bind方式)发生错误响应头状态码会设置成400（Bad Request/错误请求），并且在控制台也能看到响应的提示信息\n使用ShouldBindQuery的情况\n#1 三个字段都是必须要传的，只传一个会输出错误$ curl &quot;http://127.0.0.1:9090/bindGet/getShould?home=beijing&quot;&#123;&quot;error&quot;:&quot;Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag\\nKey: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag\\n&quot;&#125;%#2 同上一样的请求，看一下头信息$ curl -i &quot;http://127.0.0.1:9090/bindGet/getShould?home=beijing&quot;HTTP/1.1 200 OKContent-Type: application/json; charset=utf-8Date: Sun, 26 Mar 2023 12:56:13 GMTContent-Length: 172&#123;&quot;error&quot;:&quot;Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag\\nKey: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag\\n&quot;&#125;#3 正常绑定情况$ curl &quot;http://127.0.0.1:9090/bindGet/getShould?home=beijing&amp;name=hanpy&amp;age=30&quot;&#123;&quot;user&quot;:&#123;&quot;name&quot;:&quot;hanpy&quot;,&quot;age&quot;:30,&quot;home&quot;:&quot;beijing&quot;&#125;&#125;\n\n绑定POST参数绑定POST数据主要是使用 BindWith() 和 ShouldBindWith()\n// 绑定POST请求数据r.POST(&quot;/bind/post&quot;, func(ctx *gin.Context) &#123;    user := &amp;User&#123;&#125;    // ctx.BindWith(user, binding.FormPost)    err := ctx.ShouldBindWith(user, binding.FormPost)    if err != nil &#123;        ctx.JSON(200, gin.H&#123;&quot;error&quot;: fmt.Sprintln(err)&#125;)        return    &#125;    ctx.JSON(200, gin.H&#123;&quot;user&quot;: user&#125;)&#125;)\n\n#1 绑定验证失败$ curl -d &quot;home=beijing&amp;name=hanpy&quot; &quot;http://127.0.0.1:9090/bind/post&quot; &#123;&quot;error&quot;:&quot;Key: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag\\n&quot;&#125;#2 绑定成功$ curl -d &quot;home=beijing&amp;name=hanpy&amp;age=30&quot; &quot;http://127.0.0.1:9090/bind/post&quot;&#123;&quot;user&quot;:&#123;&quot;name&quot;:&quot;hanpy&quot;,&quot;age&quot;:30,&quot;home&quot;:&quot;beijing&quot;&#125;&#125;\n\n绑定Json数据主要使用 BindJSON() 和 ShouldBindJSON()\nr.POST(&quot;/bind/json&quot;, func(ctx *gin.Context) &#123;    user := &amp;UserJson&#123;&#125;    //ctx.BindJSON()    err := ctx.ShouldBindJSON(user)    if err != nil &#123;        ctx.JSON(200, gin.H&#123;&quot;error&quot;: fmt.Sprintln(err)&#125;)        return    &#125;    ctx.JSON(200, gin.H&#123;&quot;user&quot;: user&#125;)&#125;)\n\n#1 $ curl -H &#x27;Content-Type: application/json&#x27; --url http://127.0.0.1:9090/bind/json --data &#x27;&#123;  &quot;name&quot;: &quot;hanpy&quot;,  &quot;likes&quot;:[&quot;eat&quot;, &quot;sleep&quot;]&#125;&#x27;#1 返回数据&#123;&quot;user&quot;:&#123;&quot;name&quot;:&quot;hanpy&quot;,&quot;likes&quot;:[&quot;eat&quot;,&quot;sleep&quot;]&#125;&#125;\n\n绑定Header数据type Header struct &#123;    ContentType string `header:&quot;Content-Type&quot;`    UserAgenet  string `header:&quot;user-agent&quot;`&#125;r.POST(&quot;/bind/header&quot;, func(ctx *gin.Context) &#123;    header := &amp;Header&#123;&#125;    err := ctx.ShouldBindHeader(header)    if err != nil &#123;        ctx.JSON(200, gin.H&#123;&quot;error&quot;: fmt.Sprintln(err)&#125;)        return    &#125;    ctx.JSON(200, gin.H&#123;&quot;header&quot;: header&#125;)&#125;)\n\n#1 访问数据$ curl --request &quot;POST&quot; -H &quot;content-type:application/json&quot; -A &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.50&quot; --url &quot;http://127.0.0.1:9090/bind/header&quot;#1 返回数据&#123;    &quot;header&quot;: &#123;        &quot;ContentType&quot;: &quot;application/json&quot;,        &quot;UserAgenet&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.50&quot;    &#125;&#125;\n\n通过上面的列子得出一个结论，绑定 header 数据的时候大小写是不敏感的。\n","categories":["Golang","Gin"],"tags":["go","gin"]},{"title":"Gin框架学习记录 - 接收参数","url":"/2023/03/24/go-gin-param.html","content":"记录一下获取GET和POST参数的方式和注意事项。\n\n\nGET参数获取路由参数获取路由格式为:/path/:a/:b 时，:x指的就是路由参数，可以直接通过Param(&quot;x&quot;)获取值信息\nfunc RouteParam() &#123;    r := gin.Default()    r.GET(&quot;/updateUser/:name/:age&quot;, func(ctx *gin.Context) &#123;        name := ctx.Param(&quot;name&quot;)        age := ctx.Param(&quot;age&quot;)        // 找不到就会返回空字符串        birth := ctx.Param(&quot;birth&quot;)        ctx.JSON(200, gin.H&#123;&quot;name&quot;: name, &quot;age&quot;: age, &quot;birth&quot;: birth&#125;)    &#125;)    _ = r.Run(&quot;:9090&quot;)&#125;\n\n访问一下\n#1$ curl localhost:9090/updateUser/hanpy/20&#123;&quot;age&quot;:&quot;20&quot;,&quot;birth&quot;:&quot;&quot;,&quot;name&quot;:&quot;hanpy&quot;&#125;\n\n接收单个值主要用到下面几个函数Query、DefaultQuery、GetQueryQuery: 不存在就返回空字符串DefaultQuery: 不存在就返回后面默认的值GetQuery: 显式的返回是否存在\nfunc RouteUrl(r *gin.Engine) &#123;    urlRoute := r.Group(&quot;/url&quot;)    &#123;        urlRoute.GET(&quot;/get&quot;, func(ctx *gin.Context) &#123;            // #1 不存在就返回空字符串            name := ctx.Query(&quot;name&quot;)            // #2 不存在就返回后面默认的值            age := ctx.DefaultQuery(&quot;age&quot;, &quot;30&quot;)            // #3 显式的返回是否存在            birth, isExist := ctx.GetQuery(&quot;birth&quot;)            ctx.JSON(200, gin.H&#123;                &quot;name&quot;:         name,                &quot;age&quot;:          age,                &quot;birth&quot;:        birth,                &quot;birthIsExist&quot;: isExist,            &#125;)        &#125;)    &#125;&#125;\n\n#1 $ curl localhost:9090/url/get\\?name=hanpy\\&amp;age=2 &#123;&quot;age&quot;:&quot;2&quot;,&quot;birth&quot;:&quot;&quot;,&quot;birthIsExist&quot;:false,&quot;name&quot;:&quot;hanpy&quot;&#125;%   #2$ curl localhost:9090/url/get\\?name=hanpy\\&amp;age=2\\&amp;birth=1991&#123;&quot;age&quot;:&quot;2&quot;,&quot;birth&quot;:&quot;1991&quot;,&quot;birthIsExist&quot;:true,&quot;name&quot;:&quot;hanpy&quot;&#125;% \n\n接收数组主要使用QueryArray 和 GetQueryArray\narrRoute := r.Group(&quot;/array&quot;)&#123;    arrRoute.GET(&quot;/get&quot;, func(ctx *gin.Context) &#123;        name := ctx.QueryArray(&quot;name[]&quot;)        age, isExist := ctx.GetQueryArray(&quot;age[]&quot;)        ctx.JSON(200, gin.H&#123;            &quot;name&quot;:       name,            &quot;age&quot;:        age,            &quot;ageIsExist&quot;: isExist,        &#125;)    &#125;)&#125;\n\n$ curl http://127.0.0.1:9090/array/get?name[]=zhangsan&amp;name[]=lisi&amp;age[]=20&amp;age[]=30&#123;    &quot;age&quot;: [        &quot;20&quot;,        &quot;30&quot;    ],    &quot;ageIsExist&quot;: true,    &quot;name&quot;: [        &quot;zhangsan&quot;,        &quot;lisi&quot;    ]&#125;\n\n接收Map主要使用 QueryMap 和 GetQueryMap\nmapRoute := r.Group(&quot;/map&quot;)&#123;    mapRoute.GET(&quot;/get&quot;, func(ctx *gin.Context) &#123;        user := ctx.QueryMap(&quot;user&quot;)        ctx.JSON(200, user)    &#125;)    mapRoute.GET(&quot;/get1&quot;, func(ctx *gin.Context) &#123;        user, isExist := ctx.GetQueryMap(&quot;user&quot;)        ctx.JSON(200, gin.H&#123;            &quot;user&quot;:    user,            &quot;isExist&quot;: isExist,        &#125;)    &#125;)&#125;\n\n#1 $ curl http://127.0.0.1:9090/map/get?user[lisi]=20&amp;user[wangwu]=30&#123;    &quot;lisi&quot;: &quot;20&quot;,    &quot;wangwu&quot;: &quot;30&quot;&#125;#2 $ curl http://127.0.0.1:9090/map/get1?user[lisi]=20&amp;user[wangwu]=30&#123;    &quot;isExist&quot;: true,    &quot;user&quot;: &#123;        &quot;lisi&quot;: &quot;20&quot;,        &quot;wangwu&quot;: &quot;30&quot;    &#125;&#125;\n\nPOST参数获取接收单个值主要使用 PostForm、DefaultPostForm 和 GetPostForm\npostRoute := r.Group(&quot;/post&quot;)&#123;    postRoute.POST(&quot;/user&quot;, func(ctx *gin.Context) &#123;        // #1 不存在就返回空字符串        name := ctx.PostForm(&quot;name&quot;)        // #2 不存在就返回后面默认的值        age := ctx.DefaultPostForm(&quot;age&quot;, &quot;30&quot;)        // #3 显式的返回是否存在        birth, isExist := ctx.GetPostForm(&quot;birth&quot;)        ctx.JSON(200, gin.H&#123;            &quot;name&quot;:         name,            &quot;age&quot;:          age,            &quot;birth&quot;:        birth,            &quot;birthIsExist&quot;: isExist,        &#125;)    &#125;)&#125;\n\n# 1 $ curl -d &quot;name=hanpy&amp;age=30&amp;birth=1991&quot; http://127.0.0.1:9090/post/user&#123;    &quot;age&quot;: &quot;30&quot;,    &quot;birth&quot;: &quot;1991&quot;,    &quot;birthIsExist&quot;: true,    &quot;name&quot;: &quot;hanpy&quot;&#125;\n\n接收数组主要使用 PostFormArray 和 GetPostFormArray\npostRoute.POST(&quot;/arr&quot;, func(ctx *gin.Context) &#123;    // #1 如果不存在返回空字符串切片    list := ctx.PostFormArray(&quot;list[]&quot;)    // #2 显式的返回是否有    like, isExist := ctx.GetPostFormArray(&quot;like[]&quot;)    ctx.JSON(200, gin.H&#123;        &quot;list&quot;:    list,        &quot;like&quot;:    like,        &quot;isExist&quot;: isExist,    &#125;)&#125;)\n\n#1$ curl -d &quot;list[]=red&amp;list[]=green&amp;like[]=sleep&quot; http://127.0.0.1:9090/post/arr&#123;    &quot;isExist&quot;: true,    &quot;like&quot;: [        &quot;sleep&quot;    ],    &quot;list&quot;: [        &quot;red&quot;,        &quot;green&quot;    ]&#125;\n\n接收Map主要使用 PostFormMap 和 GetPostFormMap\npostRoute.POST(&quot;/map&quot;, func(ctx *gin.Context) &#123;    // #1 如果不存在就返回空的 map[string]string    userMap := ctx.PostFormMap(&quot;user&quot;)    // #2 显式的返回是否存在    classMap, isExist := ctx.GetPostFormMap(&quot;class&quot;)    ctx.JSON(200, gin.H&#123;        &quot;userMap&quot;:  userMap,        &quot;classMap&quot;: classMap,        &quot;isExist&quot;:  isExist,    &#125;)&#125;)\n\n#1$ curl -d &quot;user[name]=hanpy&amp;user[age]=20&amp;class[one]=100&quot; http://127.0.0.1:9090/post/map&#123;    &quot;classMap&quot;: &#123;        &quot;one&quot;: &quot;100&quot;    &#125;,    &quot;isExist&quot;: true,    &quot;userMap&quot;: &#123;        &quot;age&quot;: &quot;20&quot;,        &quot;name&quot;: &quot;hanpy&quot;    &#125;&#125;\n\n","categories":["Golang","Gin"],"tags":["go","gin"]},{"title":"Gin框架学习记录 - 路由的简单使用","url":"/2023/03/24/go-gin-route.html","content":"Gin框架的路由是基于httprouter,httprouter使用[基数树(也叫基数特里树或压缩前缀树)]这种数据结构来维护映射路由关系，通过前缀树快速路由.\n\n\n基本路由示例http中的请求方法都有对应的方法来生成路由\npackage mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123;    // 创建一个默认的路由引擎    engine := gin.Default()    RouteBasicUse(engine)    _ = engine.Run(&quot;:9090&quot;)&#125;//// RouteBasicUse//  @Description: 路由测试//  @param r//func RouteBasicUse(r *gin.Engine) &#123;    r.GET(&quot;/get&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;GET&quot;&#125;)    &#125;)    r.POST(&quot;/post&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;POST&quot;&#125;)    &#125;)    r.PUT(&quot;/put&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;PUT&quot;&#125;)    &#125;)    r.DELETE(&quot;/delete&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;DELETE&quot;&#125;)    &#125;)    r.HEAD(&quot;/head&quot;, func(ctx *gin.Context) &#123;        ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;HEAD&quot;&#125;)    &#125;)&#125;\n\n访问一下\n#1 GET$ curl localhost:9090/get&#123;&quot;method&quot;:&quot;GET&quot;&#125;#2 POST$ curl -X POST localhost:9090/post&#123;&quot;method&quot;:&quot;POST&quot;&#125;#3 PUT$ curl -X PUT localhost:9090/put&#123;&quot;method&quot;:&quot;PUT&quot;&#125;#4 DELETE$ curl -X DELETE localhost:9090/delete&#123;&quot;method&quot;:&quot;DELETE&quot;&#125;\n\n匹配所有的HTTP请求方式\nAny 方法可以匹配所有的\nengine.Any(&quot;/any&quot;, func(ctx *gin.Context) &#123;    ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;Any&quot;&#125;)&#125;)\n\n路由组Routes Group是为了管理一些相同的URL，直接看下面的例子\nfunc RouteGroup() &#123;    r := gin.Default()    userRoute := r.Group(&quot;/user&quot;)    &#123;        userRoute.GET(&quot;/info&quot;, func(ctx *gin.Context) &#123;            ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;/user/info&quot;&#125;)        &#125;)        userRoute.POST(&quot;/setUser&quot;, func(ctx *gin.Context) &#123;            ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;/user/setUser&quot;&#125;)        &#125;)\t\t        // 分组也是可以嵌套的        setGroup := userRoute.Group(&quot;/setting&quot;)        &#123;            setGroup.GET(&quot;/secure&quot;, func(ctx *gin.Context) &#123;                ctx.JSON(200, gin.H&#123;&quot;method&quot;: &quot;/user/setting/secure&quot;&#125;)            &#125;)        &#125;    &#125;    _ = r.Run(&quot;:9090&quot;)&#125;\n会注册下面的路由\n[GIN-debug] GET    /user/info                --&gt; main.RouteGroup.func1 (3 handlers)[GIN-debug] POST   /user/setUser             --&gt; main.RouteGroup.func2 (3 handlers)[GIN-debug] GET    /user/setting/secure      --&gt; main.RouteGroup.func3 (3 handlers)\n","categories":["Golang","Gin"],"tags":["go","gin"]},{"title":"Golang学习 - 接口（interface）","url":"/2023/01/21/go-interface.html","content":"interface 是 Go 语言的基础特性之一，可以理解为一种类型的规范或者约定。\n\n\n接口的声明// 空接口type interfaceName interface &#123;&#125;\n\n接口指定了类型应该具有的方法，类型决定了如何实现这些方法。\n// 有方法列表的接口type PeopleInface interface &#123;    GetName() string    GetAge() int&#125;\n\n接口的实现Go语言中，接口的实现是隐式的。不用明确地指出某一个类型实现了某一个接口，只要在某一类型的方法中实现了接口中的全部方法签名，就意味着此类型实现了这一接口。\ntype PeopleInface interface &#123;    GetName() string    GetAge() int&#125;type Student struct &#123;    Name string    Age  int&#125;func (s Student) GetName() string &#123;    return s.Name&#125;func (s Student) GetAge() int &#123;    return s.Age&#125;\n\n接口动态类型存储在接口变量中的类型称为接口的动态类型，而将接口本身的类型称为接口的静态类型\n下面的代码中，sp是接口变量，sp的动态类型是student,静态类型是speak。sp的静态类型永远是speak，动态类型却会随着我们赋给它的动态值而变\npackage mainimport &quot;fmt&quot;type speak interface &#123;    sayHello()&#125;type student struct &#123;    Name string&#125;func (s student) sayHello() &#123;    fmt.Println(&quot;sayHello&quot;)&#125;func main() &#123;    var sp speak    stu := student&#123;&quot;zhangsan&quot;&#125;    sp = stu&#125;\n\n接口动态调用当接口变量中存储了具体的动态类型时，可以调用接口中所有的方法。在对接口变量进行动态调用时，调用的方法只能是接口中具有的方法。\ntype Speak interface &#123;    sayHello()&#125;type Student struct&#123;&#125;func (s Student) sayHello() &#123;    fmt.Println(&quot;Student SayHello&quot;)&#125;type Teacher struct&#123;&#125;func (t Teacher) sayHello() &#123;    fmt.Println(&quot;Teacher SayHello&quot;)&#125;func (t Teacher) sayGoodBy() &#123;    fmt.Println(&quot;Teacher SayGoodBy&quot;)&#125;func main() &#123;    var s Speak    // 接口变量存储了不同的动态类型，接口动态 调用表现出不同动态类型的行为    s = Student&#123;&#125;    s.sayHello() // Student SayHello    s = Teacher&#123;&#125;    s.sayHello() // Teacher SayHello    // sayGoodBy()是接口之外的方法就是不能调用的 | 未解析的引用 &#x27;sayGoodBy&#x27;    s.sayGoodBy()&#125;\n\n指针和接口在实现接口的时候有两种方式，结构体实现和指针实现\n\n《Go语言设计与实现》中的图\n\n\n\n结构体类型和指针类型是不同的，在实现接口时这两种类型也不能划等号。虽然两种类型不同，但是上图中的两种实现不可以同时存在，Go 语言的编译器会在结构体类型和指针类型都实现一个方法时报错 “method redeclared”。\n\n实现接口时可以选择接受者的类型，即结构体或者结构体指针，在初始化时也可以初始化成结构体或者指针。在初始化成结构体的时候，是可以调用接受者是结构体和结构体指针的方法。在初始化成指针的时候，只可以调用接受者是结构体指针的方法。\n……这特么的看代码吧！\ntype Duck interface &#123;    Walk()    Quack()&#125;type Cat struct &#123;&#125;func (c Cat) Walk() &#123;    fmt.Println(&quot;catWalk&quot;)&#125;func (c *Cat) Quack() &#123;    fmt.Println(&quot;catMeow&quot;)&#125;func main() &#123;    // 这种情况是不能编译成功的    // cannot use Cat&#123;&#125; (type Cat) as type Duck in assignment:    // Cat does not implement Duck (Quack method has pointer receiver)    // 结构体类型就没有实现Duck接口    var c Duck = Cat&#123;&#125;    c.Walk()    c.Quack()    // 这种情况是可以通过编译的    // 当我们使用结构体实现接口时，指针类型和结构体类型都会实现该接口    // Walk方法接受者虽然是结构体,但是会隐式的有一个接受者是指针的实现    var c1 Duck = &amp;Cat&#123;&#125;    c1.Walk()    c1.Quack()&#125;\n\n\n至于为什么这样，在《Go语言设计与实现》中有这样的解释\n\n\n两种接口的数据结构Go 语言根据接口类型是否包含一组方法将接口类型分成了两类：\n\n使用 runtime.iface 结构体表示包含方法的接口\n使用 runtime.eface 结构体表示不包含任何方法的 interface&#123;&#125; 类型\n\neface结构体type eface struct &#123; // 16 字节    _type *_type    data  unsafe.Pointer&#125;type _type struct &#123;    size       uintptr    ptrdata    uintptr    hash       uint32    tflag      tflag    align      uint8    fieldAlign uint8    kind       uint8    equal      func(unsafe.Pointer, unsafe.Pointer) bool    gcdata     *byte    str        nameOff    ptrToThis  typeOff&#125;\n\nsize 字段存储了类型占用的内存空间，为内存空间的分配提供信息；\nhash 字段能够帮助我们快速确定类型是否相等；\nequal 字段用于判断当前类型的多个对象是否相等，该字段是为了减少 Go 语言二进制包大小从 typeAlg 结构体中迁移过来的\n\niface结构体runtime.itab 结构体是接口类型的核心组成部分，每一个 runtime.itab 都占 32 字节，我们可以将其看成接口类型和具体类型的组合，它们分别用 inter 和 _type 两个字段表示：\ntype itab struct &#123; // 32 字节    inter *interfacetype    _type *_type    hash  uint32    _     [4]byte    fun   [1]uintptr&#125;\n\n\nhash 是对 _type.hash 的拷贝，当我们想将 interface 类型转换成具体类型时，可以使用该字段快速判断目标类型和具体类型 runtime._type 是否一致\nfun 是一个动态大小的数组，它是一个用于动态派发的虚函数表，存储了一组函数指针。虽然该变量被声明成大小固定的数组，但是在使用时会通过原始指针获取其中的数据，所以 fun 数组中保存的元素数量是不确定的\n\n","categories":["Golang"],"tags":["go","interface"]},{"title":"Golang学习 - 字典（Map）","url":"/2023/01/14/go-map.html","content":"Map 的底层实现是通过 Hash 表来进行的，Map 中所有的 key 都有相同的类型，所有的 value 也有着相同的类型，但是 key 和 value 之间可以是不同的数据类型。\n\n\nMap的键类型会受到那些限制字典类型其实是一种哈希表的实现，键是需要在哈希表中定位元素使用的。一般都是通过hash函数来确认桶的位置，然后在桶中再通过键来查找元素，所以字典的键必须是能够做==和!=操作的类型\n那些类型不能够做键？\n正是因为有了上面的限制，所以函数类型、字典类型、切片类型是不能做为map的key的，因为它们都不支持==和!=操作\n优先考虑哪些类型作为Map的键类型字典是基于hash表的封装，所以对于键来说，“把键值转换为哈希值”以及“把要查找的键值与哈希桶中的键值做对比”，明显是两个重要且比较耗时的操作，求哈希和判等操作的速度越快，对应的类型就越适合作为键类型。\n所有的基本类型、指针类型，以及数组类型、结构体类型和接口类型，Go 语言都有一套算法与之对应。这套算法中就包含了哈希和判等。以求哈希的操作为例，宽度(指它的单个值需要占用的字节数)越小的类型速度通常越快。对于布尔类型、整数类型、浮点数类型、复数类型和指针类型来说都是如此。对于字符串类型，由于它的宽度是不定的，所以要看它的值的具体长度，长度越短求哈希越快。\n数组类型的值求哈希实际上是依次求得它的每个元素的哈希值并进行合并，所以速度就取决于它的元素类型以及它的长度。细则同上。与之类似，对结构体类型的值求哈希实际上就是对它的所有字段值求哈希并进行合并，所以关键在于它的各个字段的类型以及字段的数量。而对于接口类型，具体的哈希算法，则由值的实际类型决定。\n优先选用数值类型和指针类型，通常情况下类型的宽度越小越好。如果非要选择字符串类型的话，最好对键值的长度进行额外的约束。\n在值为nil的Map上执行读写操作会发生什么var m map[int]stringfmt.Println(m == nil) // truev := m[100]fmt.Println(v)v1, ok := m[200]fmt.Println(v1)fmt.Println(ok)// panic: assignment to entry in nil map [recovered]m[300] = &quot;test_string&quot;\n\n除了添加键-元素对，我们在一个值为nil的字典上做任何操作都不会引起错误。当我们试图在一个值为nil的字典中添加键-元素对的时候，Go 语言的运行时系统就会立即抛出一个panic。\nMap的底层数据结构Map的底层是一种Hash表的实现，主要涉及到两个数据结构，一个叫hmap ，一个是bmap ，bmap就是常说的桶go/src/runtime/map.go\ntype hmap struct &#123;    count      int            //元素个数，调用len(map)时直接返回    flags      uint8          //标志map当前状态,正在删除元素、添加元素.....    B          uint8          //单元(buckets)的对数 B=5表示能容纳32个元素 2^B放代表有多少个桶    noverflow  uint16        //单元(buckets)溢出数量，如果一个单元能存8个key，此时存储了9个，溢出了，就需要再增加一个单元    hash0      uint32         //哈希种子    buckets    unsafe.Pointer //指向单元(buckets)数组,大小为2^B，可以为nil    oldbuckets unsafe.Pointer //扩容的时候，buckets长度会是oldbuckets的两倍    nevacute   uintptr        //指示扩容进度，小于此buckets迁移完成    extra      *mapextra      //与gc相关 可选字段&#125;type mapextra struct &#123;    // 如果 key 和 value 都不包含指针，并且可以被 inline(&lt;=128 字节)    // 使用 extra 来存储 overflow bucket，这样可以避免 GC 扫描整个 map    // 然而 bmap.overflow 也是个指针。这时候我们只能把这些 overflow 的指针    // 都放在 hmap.extra.overflow 和 hmap.extra.oldoverflow 中了    // overflow 包含的是 hmap.buckets 的 overflow 的 bucket    // oldoverflow 包含扩容时的 hmap.oldbuckets 的 overflow 的 bucket    overflow    *[]*bmap    oldoverflow *[]*bmap    // 指向空闲的 overflow bucket 的指针    nextOverflow *bmap&#125;// runtime.bmap 定义的结构type bmap struct &#123;    tophash [bucketCnt]uint8 // bucketCnt=1&lt;&lt;3,每个捅只能存储8个元素,tophash存储了键的Hash的高8位&#125;//实际上编译期间会生成一个新的数据结构type bmap struct &#123;    topbits  [8]uint8     // 值能存放8个元素,存储的键的Hash的高8位    keys     [8]keytype   // 指向keytype的指针    values   [8]valuetype // 指向valuetype的支持    overflow uintptr      // 溢出桶的地址&#125;\n\nMap原理图解借用一下同事画的一张图\n\n初始化make方式初始化使用make的方式初始化的时候，在类型检查阶段会转化为runtime.makemap,makemap函数会计算出需要的桶的数量，即log2N，并调用makeBucketArray函数生成桶和溢出桶。如果初始化时生成了溢出桶， 则会放置到map的extra字段里去。\n/usr/local/go/src/runtime/map.go | makemap\nfunc makemap(t *maptype, hint int, h *hmap) *hmap &#123;    mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)    if overflow || mem &gt; maxAlloc &#123;        hint = 0    &#125;    // initialize Hmap    if h == nil &#123;        h = new(hmap)    &#125;    h.hash0 = fastrand()    // 按照提供的元素个数，计算所需要的桶的数量    B := uint8(0)    for overLoadFactor(hint, B) &#123;        B++    &#125;    h.B = B    // allocate initial hash table    // if B == 0, the buckets field is allocated lazily later (in mapassign)    // If hint is large zeroing this memory could take a while.    if h.B != 0 &#123;        var nextOverflow *bmap        h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)        if nextOverflow != nil &#123;            h.extra = new(mapextra)            h.extra.nextOverflow = nextOverflow        &#125;    &#125;    return h&#125;\n函数的执行逻辑\n\n计算哈希占用的内存是否溢出或者超出能分配的最大值\n调用runtime.fastrand获取一个随机的哈希种子；\n根据传入的hint计算出需要的最小需要的桶的数量；\n使用runtime.makeBucketArray创建用于保存桶的数组；\n\nruntime.makeBucketArray会根据传入的 B 计算出的需要创建的桶数量并在内存中分配一片连续的空间用于存储数据：\nfunc makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) &#123;    base := bucketShift(b)    nbuckets := base    if b &gt;= 4 &#123;        nbuckets += bucketShift(b - 4)        sz := t.bucket.size * nbuckets        up := roundupsize(sz)        if up != sz &#123;            nbuckets = up / t.bucket.size        &#125;    &#125;    if dirtyalloc == nil &#123;        buckets = newarray(t.bucket, int(nbuckets))    &#125; else &#123;        buckets = dirtyalloc        size := t.bucket.size * nbuckets        if t.bucket.ptrdata != 0 &#123;            memclrHasPointers(buckets, size)        &#125; else &#123;            memclrNoHeapPointers(buckets, size)        &#125;    &#125;    if base != nbuckets &#123;        nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize)))        last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize)))        last.setoverflow(t, (*bmap)(buckets))    &#125;    return buckets, nextOverflow&#125;\n\n\n\n字面量初始化如果map采取了字面量初始化的方式，那么它最终仍然需要转换为 make操作。map的长度被自动推断为字面量的长度。\n当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中：\nhash := make(map[string]int, 3)hash[&quot;1&quot;] = 2hash[&quot;3&quot;] = 4hash[&quot;5&quot;] = 6\n\n一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希：\nhash := make(map[string]int, 26)vstatk := []string&#123;&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, ... ， &quot;26&quot;&#125;vstatv := []int&#123;1, 2, 3, ... , 26&#125;for i := 0; i &lt; len(vstak); i++ &#123;    hash[vstatk[i]] = vstatv[i]&#125;\n\nMap访问原理赋值语句左侧接受参数的个数会决定使用的运行时方法：当接受一个参数时，会使用runtime.mapaccess1，该函数仅会返回一个指向目标值的指针；当接受两个参数时，会使用runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的bool值：主要是对key进行hash计算，计算后用低B位(决定桶的位置)和高8位hash(桶中key的位置)找到对应的位置:\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer &#123;\t// --省略代码--        // 计算hash值    hash := t.hasher(key, uintptr(h.hash0))    m := bucketMask(h.B)    // b 就是 bucket 的地址    b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize)))        // oldbuckets 不为 nil，说明发生了扩容    if c := h.oldbuckets; c != nil &#123;        // 判断是不是同容量扩容,如果不是,那就是2倍扩容 | same:相同        if !h.sameSizeGrow() &#123;            // There used to be half as many buckets; mask down one more power of two.            m &gt;&gt;= 1        &#125;        oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize)))        if !evacuated(oldb) &#123;            b = oldb        &#125;    &#125;    // tophash 取其高 8bit 的值    top := tophash(hash)    bucketloop:    // 依次遍历正常桶和溢出桶中的数据    for ; b != nil; b = b.overflow(t) &#123;        for i := uintptr(0); i &lt; bucketCnt; i++ &#123;            if b.tophash[i] != top &#123;                // emptyRest意思后面都是空的了 | [h1][h2][h3][h4][h5][emptyRest][emptyOne][emptyOne]                if b.tophash[i] == emptyRest &#123;                    break bucketloop                &#125;                continue            &#125;            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))            if t.indirectkey() &#123;                k = *((*unsafe.Pointer)(k))            &#125;            if t.key.equal(key, k) &#123;                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))                if t.indirectelem() &#123;                    e = *((*unsafe.Pointer)(e))                &#125;                return e            &#125;        &#125;    &#125;    return unsafe.Pointer(&amp;zeroVal[0])&#125;\n\n这个地方是比较的哈希的高8位，这种设计能够减少同一个桶中有大量相等tophash的概率影响性能。\n\n《Go语言设计与实现》中的图\n\n\nMap赋值原理map的赋值主要是通过mapassign系列函数来进行的\ngo/src/runtime/map.go | mapassign\n先根据传入的键拿到对应的哈希和桶\n// 计算key的hash值hash := t.hasher(key, uintptr(h.hash0))// 修改map的状态为写入h.flags ^= hashWriting// 如果没有buckt分配第一个bucktif h.buckets == nil &#123;    h.buckets = newobject(t.bucket) // newarray(t.bucket, 1)&#125;again:// 计算低B位 hash，根据计算出的bucketMask选择对应的bucketbucket := hash &amp; bucketMask(h.B)// 当前的map正在重建，则会优先完成重建过程if h.growing() &#123;    growWork(t, h, bucket)&#125;// 计算出存储的 bucket 的内存位置b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))// 计算tophash top := tophash(hash)\n\n通过遍历比较桶(包括溢出桶)中存储的 tophash 和键的哈希，如果找到了相同结果就会返回目标位置的地址。\nvar inserti *uint8\t// 目标元素的在桶中的索引var insertk unsafe.Pointer\t// insertk 和 elem 分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对 k 和 val：var elem unsafe.Pointerbucketloop:for &#123;    for i := uintptr(0); i &lt; bucketCnt; i++ &#123;        if b.tophash[i] != top &#123;            // 如果这个槽位没有被占，说明可以往这里塞 key 和 value            if isEmpty(b.tophash[i]) &amp;&amp; inserti == nil &#123;                inserti = &amp;b.tophash[i]                insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))                elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))            &#125;            if b.tophash[i] == emptyRest &#123;                break bucketloop            &#125;            continue        &#125;        k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))        if t.indirectkey() &#123;            k = *((*unsafe.Pointer)(k))        &#125;                // 上面是在比较tophash，这个地方应该是比较key        if !t.key.equal(key, k) &#123;            continue        &#125;        // 对应的位置已经有 key 了，直接更新就行        if t.needkeyupdate() &#123;            typedmemmove(t.key, k, key)        &#125;        elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))        goto done    &#125;    // bucket 的 8 个槽没有满足条件的能插入或者能更新的，去 overflow 里继续找    ovf := b.overflow(t)    if ovf == nil &#123;        break    &#125;    b = ovf&#125;\n\n没有找到 key，分配新的空间\n// 如果触发了最大的 load factor，或者已经有太多 overflow buckets// 并且这个时刻没有在进行 growing 的途中，那么就开始 growingif !h.growing() &amp;&amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;    hashGrow(t, h)    goto again // Growing the table invalidates everything, so try again&#125;// 前面在桶里找的时候，没有找到能塞这个 tophash 的位置// 说明当前所有 buckets 都是满的，分配一个新的 bucketif inserti == nil &#123;    // The current bucket and all the overflow buckets connected to it are full, allocate a new one.    newb := h.newoverflow(t, b)    inserti = &amp;newb.tophash[0]    insertk = add(unsafe.Pointer(newb), dataOffset)    elem = add(insertk, bucketCnt*uintptr(t.keysize))&#125;// 把新的 key 和 value 存储到应插入的位置if t.indirectkey() &#123;    kmem := newobject(t.key)    *(*unsafe.Pointer)(insertk) = kmem    insertk = kmem&#125;if t.indirectelem() &#123;    vmem := newobject(t.elem)    *(*unsafe.Pointer)(elem) = vmem&#125;typedmemmove(t.key, insertk, key)*inserti = toph.count++done:if h.flags&amp;hashWriting == 0 &#123;    throw(&quot;concurrent map writes&quot;)&#125;h.flags &amp;^= hashWritingif t.indirectelem() &#123;    elem = *((*unsafe.Pointer)(elem))&#125;return elem\n函数只会返回内存地址，真正的赋值操作是在编译期间插入的\nMap的扩容为什么要进行扩容随着向 map 中添加的 key 越来越多，key 发生碰撞的概率也越来越大。bucket 中的 8 个 cell 会被逐渐塞满，查找、插入、删除 key 的效率也会越来越低，这个时候就很有必要进行扩容来提升操作map的效率。\n扩容进行的条件1. 负载因为≥6.52. 溢出桶太多    a. buckets的个数&lt;2^15的时候，如果溢出桶的个数大于bucket的个数，就认为溢出桶太多    b. bucket的个数&gt;2^15的时候，如果溢出桶的个数大于2^15的时候，就认为溢出桶太多\n\n扩容的方式1. 负载因子≥6.5的情况（这种情况反应的是桶里的8个元素都快满了），会把hmap中的B加12. 溢出桶太多的情况，会进行重新hash，让元素更紧密\n\n扩容相关的源码func hashGrow(t *maptype, h *hmap) &#123;   \t// 判断是不是超过了负载因子，（如果不是桶的数量就不用增多）    bigger := uint8(1)    if !overLoadFactor(h.count+1, h.B) &#123;        bigger = 0        h.flags |= sameSizeGrow    &#125;    oldbuckets := h.buckets    // 创建新的桶和溢出桶    newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)    flags := h.flags &amp;^ (iterator | oldIterator)    if h.flags&amp;iterator != 0 &#123;        flags |= oldIterator    &#125;        // 提交扩容结果    h.B += bigger    h.flags = flags    h.oldbuckets = oldbuckets    h.buckets = newbuckets    h.nevacuate = 0    h.noverflow = 0    if h.extra != nil &amp;&amp; h.extra.overflow != nil &#123;        // 把当前的 overflow 赋值给 oldoverflow        if h.extra.oldoverflow != nil &#123;            throw(&quot;oldoverflow is not nil&quot;)        &#125;        h.extra.oldoverflow = h.extra.overflow        h.extra.overflow = nil    &#125;    if nextOverflow != nil &#123;        if h.extra == nil &#123;            h.extra = new(mapextra)        &#125;        h.extra.nextOverflow = nextOverflow    &#125;\t// 实际的哈希表元素的拷贝工作是在 growWork 和 evacuate 中增量慢慢地进行的&#125;\n\nfunc growWork(t *maptype, h *hmap, bucket uintptr) &#123;    // 确保我们移动的 oldbucket 对应的是我们马上就要用到的那一个    evacuate(t, h, bucket&amp;h.oldbucketmask())    // 如果还是扩容中，再迁移一个    if h.growing() &#123;        evacuate(t, h, h.nevacuate)    &#125;&#125;\n\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) &#123;    b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))    newbit := h.noldbuckets()    if !evacuated(b) &#123;        // TODO: reuse overflow buckets instead of using new ones, if there        // is no iterator using the old buckets.  (If !oldIterator.)        // xy contains the x and y (low and high) evacuation destinations.        var xy [2]evacDst        x := &amp;xy[0]        x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))        x.k = add(unsafe.Pointer(x.b), dataOffset)        x.e = add(x.k, bucketCnt*uintptr(t.keysize))        if !h.sameSizeGrow() &#123;            // Only calculate y pointers if we&#x27;re growing bigger.            // Otherwise GC can see bad pointers.            y := &amp;xy[1]            y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))            y.k = add(unsafe.Pointer(y.b), dataOffset)            y.e = add(y.k, bucketCnt*uintptr(t.keysize))        &#125;        for ; b != nil; b = b.overflow(t) &#123;            k := add(unsafe.Pointer(b), dataOffset)            e := add(k, bucketCnt*uintptr(t.keysize))            for i := 0; i &lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) &#123;                top := b.tophash[i]                if isEmpty(top) &#123;                    b.tophash[i] = evacuatedEmpty                    continue                &#125;                if top &lt; minTopHash &#123;                    throw(&quot;bad map state&quot;)                &#125;                k2 := k                if t.indirectkey() &#123;                    k2 = *((*unsafe.Pointer)(k2))                &#125;                var useY uint8                if !h.sameSizeGrow() &#123;                    // Compute hash to make our evacuation decision (whether we need                    // to send this key/elem to bucket x or bucket y).                    hash := t.hasher(k2, uintptr(h.hash0))                    if h.flags&amp;iterator != 0 &amp;&amp; !t.reflexivekey() &amp;&amp; !t.key.equal(k2, k2) &#123;                        // If key != key (NaNs), then the hash could be (and probably                        // will be) entirely different from the old hash. Moreover,                        // it isn&#x27;t reproducible. Reproducibility is required in the                        // presence of iterators, as our evacuation decision must                        // match whatever decision the iterator made.                        // Fortunately, we have the freedom to send these keys either                        // way. Also, tophash is meaningless for these kinds of keys.                        // We let the low bit of tophash drive the evacuation decision.                        // We recompute a new random tophash for the next level so                        // these keys will get evenly distributed across all buckets                        // after multiple grows.                        useY = top &amp; 1                        top = tophash(hash)                    &#125; else &#123;                        if hash&amp;newbit != 0 &#123;                            useY = 1                        &#125;                    &#125;                &#125;                if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY &#123;                    throw(&quot;bad evacuatedN&quot;)                &#125;                b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY                dst := &amp;xy[useY]                 // evacuation destination                if dst.i == bucketCnt &#123;                    dst.b = h.newoverflow(t, dst.b)                    dst.i = 0                    dst.k = add(unsafe.Pointer(dst.b), dataOffset)                    dst.e = add(dst.k, bucketCnt*uintptr(t.keysize))                &#125;                dst.b.tophash[dst.i&amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check                if t.indirectkey() &#123;                    *(*unsafe.Pointer)(dst.k) = k2 // copy pointer                &#125; else &#123;                    typedmemmove(t.key, dst.k, k) // copy elem                &#125;                if t.indirectelem() &#123;                    *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e)                &#125; else &#123;                    typedmemmove(t.elem, dst.e, e)                &#125;                dst.i++                // These updates might push these pointers past the end of the                // key or elem arrays.  That&#x27;s ok, as we have the overflow pointer                // at the end of the bucket to protect against pointing past the                // end of the bucket.                dst.k = add(dst.k, uintptr(t.keysize))                dst.e = add(dst.e, uintptr(t.elemsize))            &#125;        &#125;        // Unlink the overflow buckets &amp; clear key/elem to help GC.        if h.flags&amp;oldIterator == 0 &amp;&amp; t.bucket.ptrdata != 0 &#123;            b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))            // Preserve b.tophash because the evacuation            // state is maintained there.            ptr := add(b, dataOffset)            n := uintptr(t.bucketsize) - dataOffset            memclrHasPointers(ptr, n)        &#125;    &#125;    if oldbucket == h.nevacuate &#123;        advanceEvacuationMark(h, t, newbit)    &#125;&#125;","categories":["Golang"],"tags":["go","map"]},{"title":"Golang学习 - 方法","url":"/2023/01/18/go-method.html","content":"Go 没有沿袭传统面向对象编程中的诸多概念，也没有提供类( class )，但是它提供了结构体( struc)，方法( method )可以在结构体上添加。与类相似，结构体提供了捆绑数据和方法的行为。\n\n\n\n\n结构体类型也可以不包含任何字段，可以为类型关联上一些方法，方法需要有名字，不能被当作值来看待，最重要的是，它必须隶属于某一个类型。方法所属的类型会通过其声明中的接收者（receiver）声明体现出来。\ntype People struct &#123;&#125;func (p People) GetName() string &#123;    return &quot;&quot;&#125;\n\n方法的基本语法和使用package mainimport &quot;fmt&quot;type People struct &#123;    Name string    Age  int&#125;func (p People) GetName() string &#123;    return p.Name&#125;func main() &#123;    p := People&#123;        Name: &quot;hanpy&quot;,        Age:  31,    &#125;    name := p.GetName()    fmt.Println(name)&#125;\n\n值接收者和指针接收者package mainimport &quot;fmt&quot;type Person struct &#123;    age int&#125;func (p Person) howOld() int &#123;    return p.age&#125;func (p *Person) growUp() &#123;    p.age += 1&#125;func main() &#123;    // qcrao 是值类型    qcrao := Person&#123;age: 18&#125;    // 值类型 调用接收者也是值类型的方法    fmt.Println(qcrao.howOld())    // 值类型 调用接收者是指针类型的方法    qcrao.growUp()    fmt.Println(qcrao.howOld())    // ----------------------    // stefno 是指针类型    stefno := &amp;Person&#123;age: 100&#125;    // 指针类型 调用接收者是值类型的方法    fmt.Println(stefno.howOld())    // 指针类型 调用接收者也是指针类型的方法    stefno.growUp()    fmt.Println(stefno.howOld())&#125;// 18// 19// 100// 101\n\n不管方法的接收者是什么类型，该类型的值和指针都可以调用，不必严格符合接收者的类型。\n两者分别在何时使用如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。\n使用指针作为方法的接收者的理由：\n\n方法能够修改接收者指向的值。\n避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。\n\n方法继承匿名字段实现了一个方法，那么包含这个匿名字段的struct也能调用该匿名字段中的方法。\npackage mainimport &quot;fmt&quot;type People struct &#123;    Name string    Age  int&#125;func (p People) Hello() &#123;    fmt.Printf(&quot;Hello Name is %s,Age is %d&quot;, p.Name, p.Age)&#125;type Student struct &#123;    People&#125;type Teacher struct &#123;    People&#125;func main() &#123;    s := Student&#123;People&#123;&quot;张学生&quot;, 15&#125;&#125;    t := Teacher&#123;People&#123;&quot;李老师&quot;, 35&#125;&#125;    // 调用父类方法    s.Hello()    t.Hello()&#125;// Hello Name is 张学生,Age is 15// Hello Name is 李老师,Age is 35\n\n方法重写package mainimport &quot;fmt&quot;type People struct &#123;    Name string    Age  int&#125;func (p People) Hello() &#123;    fmt.Printf(&quot;Hello Name is %s,Age is %d&quot;, p.Name, p.Age)&#125;type Student struct &#123;    People&#125;func (s Student) Hello() &#123;    fmt.Println(&quot;子类的方法-Hello&quot;)&#125;type Teacher struct &#123;    People&#125;func (t Teacher) Hello() &#123;    fmt.Println(&quot;子类的方法-Hello&quot;)&#125;func main() &#123;    s := Student&#123;People&#123;&quot;张学生&quot;, 15&#125;&#125;    t := Teacher&#123;People&#123;&quot;李老师&quot;, 35&#125;&#125;    // 调用方法(继承父类)    s.Hello()    t.Hello()&#125;// 子类的方法-Hello// 子类的方法-Hello\n\n","categories":["Golang"],"tags":["go","method"]},{"title":"Golang学习 - 切片（slice）","url":"/2022/12/13/go-slice.html","content":"Go 语言中数组和切片都属于集合类的类型，它们的值也都可以用来存储某一种类型的值（或者说元素）。数组类型的值的长度是固定的，而切片类型的值（以下简称切片）是可变长的。数组的长度在声明它的时候就必须给定，并且之后不会再改变。而切片的类型字面量中只有元素的类型，而没有长度。切片的长度可以自动地随着其中元素数量的增长而增长，但不会随着元素数量的减少而减小。\n\n\n切片的底层数据结构数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。go/src/runtime/slice.go\ntype slice struct &#123;    array unsafe.Pointer    len   int    cap   int&#125;\narray：指向底层数据的一个指针,(底层数组是可以被多个slice同时指向的，因此对一个slice的元素进行操作是有可能影响到其他slice的)len：切片的长度cap：切片是容量\n切片的初始化切片有长度和容量的区别，可以在初始化时指定。由于切片具有可扩展性，所以当它的容量比长度大时，意味着为切片元素的增长预留了内存空间。初始化的时候如果不指定长度，则默认其容量与长度相同。\n三种初始化切片的方式//1. 通过下标的方式获得数组或者切片的一部分arr := [...]int&#123;1, 2, 3, 4, 5&#125;s := []int&#123;1, 2, 3, 4, 5&#125;newS1 := arr[0:3]newS2 := s[0:3]fmt.Println(newS1)fmt.Println(newS2)//2. 使用字面量初始化新的切片s1 := []int&#123;1, 2, 3&#125;fmt.Println(s1)//3. 使用关键字 `make` 创建切片：s2 := make([]int, 3, 5)\t// len=3，cap=5fmt.Println(s2)\n\n使用下标初始化使用下标初始化切片也是发生在编译期间，编译器会将 arr[0:3] 或者 slice[0:3] 等语句转换成 OpSliceMake 操作\n\nSliceMake 操作会接受四个参数创建新的切片，元素类型、数组指针、切片大小和容量，这也是我们在数据结构一节中提到的切片的几个字段 ，需要注意的是使用下标初始化切片不会拷贝原数组或者原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。\n字面量初始化字面量初始化主要是发生在编译期间，当使用形如[]int&#123;1，2，3&#125;的字面量创建新的切片时，会创建一个array数组([3]int&#123;1，2，3&#125;)存储于静态区中，并在堆区创建一个新的切片，在程序启动时将静态区的数据复制到堆区，核心逻辑在 /usr/local/go/src/cmd/compile/internal/walk/complit.go | slicelit\n\n《Go语言设计与实现》和《Go语言底层原理剖析》两本书都说核心逻辑在cmd/compile/internal/gc.slicelit中，但是没有找到，应该是迁移了，因为把分支切换到1.17的时候文件就找不到了\n\nmake初始化对形如make([]int，3，4)的初始化切片。在类型检查阶段 typecheck1函数中，节点Node的Op操作为OMAKESLICE，并且左节点存 储长度为3，右节点存储容量为4。\ngo/src/cmd/compile/internal/typecheck/typecheck.go | typecheck1\nfunc typecheck1(n ir.Node, top int) ir.Node &#123;    if n, ok := n.(*ir.Name); ok &#123;        typecheckdef(n)    &#125;    switch n.Op() &#123;        default:        ir.Dump(&quot;typecheck&quot;, n)        base.Fatalf(&quot;typecheck %v&quot;, n.Op())        panic(&quot;unreachable&quot;)        // ... 省略代码        case ir.OMAKE:        n := n.(*ir.CallExpr)        return tcMake(n)        // ... 省略代码    &#125;&#125;\n/usr/local/go/src/cmd/compile/internal/typecheck/func.go | tcMake\nfunc tcMake(n *ir.CallExpr) ir.Node &#123;        // --- 省略代码 ---    case types.TSLICE:        if i &gt;= len(args) &#123;            base.Errorf(&quot;missing len argument to make(%v)&quot;, t)            n.SetType(nil)            return n        &#125;        l = args[i]        i++        l = Expr(l)        var r ir.Node        if i &lt; len(args) &#123;            r = args[i]            i++            r = Expr(r)        &#125;        if l.Type() == nil || (r != nil &amp;&amp; r.Type() == nil) &#123;            n.SetType(nil)            return n        &#125;        if !checkmake(t, &quot;len&quot;, &amp;l) || r != nil &amp;&amp; !checkmake(t, &quot;cap&quot;, &amp;r) &#123;            n.SetType(nil)            return n        &#125;        if ir.IsConst(l, constant.Int) &amp;&amp; r != nil &amp;&amp; ir.IsConst(r, constant.Int) &amp;&amp; constant.Compare(l.Val(), token.GTR, r.Val()) &#123;            base.Errorf(&quot;len larger than cap in make(%v)&quot;, t)            n.SetType(nil)            return n        &#125;        nn = ir.NewMakeExpr(n.Pos(), ir.OMAKESLICE, l, r)        // --- 省略代码 ---    &#125;    // --- 省略代码 ---    nn.SetType(t)    return nn&#125;\n\n编译时对于字面量的重要优化是判断变量应该被分配到栈中还是 应该逃逸到堆区。如果make函数初始化了一个太大的切片，则该切片会逃逸到堆中。如果分配了一个比较小的切片，则会直接在栈中分配。\n这个临界值定义在go/src/cmd/compile/internal/ir/cfg.go中，默认大小是64KB\n\nmake([]int64，1023)与make([]int64，1024)实现的细节是截然 不同的。\n\n切片的扩容切片使用append函数添加元素的时候，如果新切片是长度超过现在的容量，就会进行扩容。这里需要注意的是调用append函数之后会返回新的切片（如果扩容）切片的扩容规则：1.18版本之前的规则当原 slice 容量小于 1024的时候，新 slice 容量变成原来的 2 倍；原 slice 容量超过 1024，新 slice 容量变成原来的1.25倍。1.18版本之后的规则当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量newcap = oldcap+(oldcap+3*256)/4\n不过还是有一个需要注意的地方，扩容的时候会根据切片的类型，分配不同大小的内存。为了对 齐内存，申请的内存可能大于实际的类型大小×容量大小\npackage mainimport &quot;fmt&quot;func main() &#123;    s := make([]int, 0)    oldCap := cap(s)    for i := 0; i &lt; 2048; i++ &#123;        s = append(s, i)        newCap := cap(s)        if newCap != oldCap &#123;            fmt.Printf(&quot;[%d -&gt; %4d] cap = %-4d  |  after append %-4d  cap = %-4d\\n&quot;, 0, i-1, oldCap, i, newCap)            oldCap = newCap        &#125;    &#125;&#125;\n\n运行结果：\n[0 -&gt;   -1] cap = 0     |  after append 0     cap = 1   [0 -&gt;    0] cap = 1     |  after append 1     cap = 2   [0 -&gt;    1] cap = 2     |  after append 2     cap = 4   [0 -&gt;    3] cap = 4     |  after append 4     cap = 8   [0 -&gt;    7] cap = 8     |  after append 8     cap = 16  [0 -&gt;   15] cap = 16    |  after append 16    cap = 32  [0 -&gt;   31] cap = 32    |  after append 32    cap = 64  [0 -&gt;   63] cap = 64    |  after append 64    cap = 128 [0 -&gt;  127] cap = 128   |  after append 128   cap = 256 [0 -&gt;  255] cap = 256   |  after append 256   cap = 512 [0 -&gt;  511] cap = 512   |  after append 512   cap = 1024[0 -&gt; 1023] cap = 1024  |  after append 1024  cap = 1280[0 -&gt; 1279] cap = 1280  |  after append 1280  cap = 1696[0 -&gt; 1695] cap = 1696  |  after append 1696  cap = 2304\n\n在老 slice 容量小于1024的时候，新 slice 的容量的确是老 slice 的2倍。目前还算正确。\n但是，当老slice容量大于等于 1024 的时候，情况就有变化了。当向slice中添加元素1280 的时候，老slice的容量为 1280，之后变成了 1696，两者并不是 1.25 倍的关系（1696/1280=1.325）。添加完 1696 后，新的容量 2304 当然也不是 1696 的 1.25 倍。\n扩容的时候会调用growslice函数\n// go/src/runtime/slice.gofunc growslice(et *_type, old slice, cap int) slice &#123;    // ... 省略前面的    newcap := old.cap    doublecap := newcap + newcap    if cap &gt; doublecap &#123;        newcap = cap    &#125; else &#123;        if old.cap &lt; 1024 &#123;            newcap = doublecap        &#125; else &#123;            // Check 0 &lt; newcap to detect overflow            // and prevent an infinite loop.            for 0 &lt; newcap &amp;&amp; newcap &lt; cap &#123;                newcap += newcap / 4            &#125;            // Set newcap to the requested cap when            // the newcap calculation overflowed.            if newcap &lt;= 0 &#123;                newcap = cap            &#125;        &#125;    &#125;    var overflow bool    var lenmem, newlenmem, capmem uintptr    // 上面已经计算出来新的cap的长度,下面就是在进行内存补齐的操作,roundupsize这个函数就是    switch &#123;        case et.size == 1:        lenmem = uintptr(old.len)        newlenmem = uintptr(cap)        capmem = roundupsize(uintptr(newcap))        overflow = uintptr(newcap) &gt; maxAlloc        newcap = int(capmem)        case et.size == sys.PtrSize:        lenmem = uintptr(old.len) * sys.PtrSize        newlenmem = uintptr(cap) * sys.PtrSize        capmem = roundupsize(uintptr(newcap) * sys.PtrSize)        overflow = uintptr(newcap) &gt; maxAlloc/sys.PtrSize        newcap = int(capmem / sys.PtrSize)        case isPowerOfTwo(et.size):        var shift uintptr        if sys.PtrSize == 8 &#123;            // Mask shift for better code generation.            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63        &#125; else &#123;            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31        &#125;        lenmem = uintptr(old.len) &lt;&lt; shift        newlenmem = uintptr(cap) &lt;&lt; shift        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)        newcap = int(capmem &gt;&gt; shift)        default:        lenmem = uintptr(old.len) * et.size        newlenmem = uintptr(cap) * et.size        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))        capmem = roundupsize(capmem)        newcap = int(capmem / et.size)    &#125;    // ... 省略一部分    return slice&#123;p, old.len, newcap&#125;&#125;// go/src/runtime/msize.gofunc roundupsize(size uintptr) uintptr &#123;    if size &lt; _MaxSmallSize &#123;        if size &lt;= smallSizeMax-8 &#123;            return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]])        &#125; else &#123;            return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]])        &#125;    &#125;    if size+_PageSize &lt; size &#123;        return size    &#125;    return alignUp(size, _PageSize)&#125;\n\n切片的复制切片是引用类型，如果用赋值的方式来进行复制，底层数据还是使用的一个。如果要完全的进行复制，需要使用copy函数来进行\ns := []int&#123;1, 2, 3&#125;s1 := sfmt.Println(s)                                  // 1,2,3fmt.Println(s1)                                 // 1,2,3fmt.Printf(&quot;s pointer %p,s1 pointer %p&quot;, s, s1) // s pointer 0xc000160000,s1 pointer 0xc000160000s[0] = 100fmt.Println(s)  // 100,2,3fmt.Println(s1) // 100,2,3ss := []int&#123;1, 2, 3&#125;newS := make([]int, len(ss), cap(ss))copy(newS, ss)fmt.Println(ss)   // 1,2,3fmt.Println(newS) // 1,2,3fmt.Printf(&quot;ss pointer %p,newS pointer %p \\n&quot;, ss, newS)ss[0] = 100fmt.Println(ss)   // 100,2,3fmt.Println(newS) // 1,2,3\n","categories":["Golang"],"tags":["go","array","slice"]},{"title":"Golang常用包 - validator","url":"/2023/02/19/go-package-validator.html","content":"validator 是一个开源的验证器包，可以快速校验输入信息是否符合自定规则。\n\n\n介绍validator 可以验证单个变量、Map、Slice、还有结构体，有丰富的验证规则，而且还能自定义规则，在web开发中有广泛的应用。\n项目地址https://github.com/go-playground/validator\n安装go get github.com/go-playground/validator\n\n验证单个变量email := &quot;hanpy126.com&quot;err := validate.Var(email, &quot;email&quot;)if err != nil &#123;    fmt.Println(err) // output: Key: &quot;&quot; Error:Field validation for &quot;&quot; failed on the &quot;email&quot; tag&#125;\n\n验证结构体var validate *validator.Validate = validator.New()type User struct &#123;    Name string `validate:&quot;required&quot;`    Age  int    `validate:&quot;required&quot;`&#125;type Addr struct &#123;    City   string    Street string&#125;func TestValidateStruct1(t *testing.T) &#123;    user := User&#123;&#125;    err := validate.Struct(user)    if err != nil &#123;        // Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag        // Key: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag        fmt.Println(err)    &#125;&#125;func TestValidateStruct2(t *testing.T) &#123;    // 这种情况适用于在结构体中没有定义tag和验证规则    rules := map[string]string&#123;        &quot;City&quot;:   &quot;required&quot;,        &quot;Street&quot;: &quot;required&quot;,    &#125;    // 注册一个验证规则,如果结构体上面有验证规则,这个方法会覆盖    validate.RegisterStructValidationMapRules(rules, Addr&#123;&#125;)    addr := Addr&#123;City: &quot;北京&quot;&#125;    err := validate.Struct(addr)    if err != nil &#123;        // Key: &#x27;Addr.Street&#x27; Error:Field validation for &#x27;Street&#x27; failed on the &#x27;required&#x27; tag        fmt.Println(err)    &#125;&#125;\n\n验证slice需要用到dive，max 验证slice长度,min验证没一个元素的长度\nsliceone := []string&#123;&quot;123&quot;, &quot;onetwothree&quot;, &quot;myslicetest&quot;, &quot;four&quot;, &quot;five&quot;&#125;err = validate.Var(sliceone, &quot;max=15,dive,min=4&quot;)if err != nil &#123;    // Key: &#x27;[0]&#x27; Error:Field validation for &#x27;[0]&#x27; failed on the &#x27;min&#x27; tag    fmt.Println(err)&#125;\n\n验证Mapmap的验证中也需要tag关键字 dive， 另外，它还有 keys 和 endkeys 两tag，验证这2个tag之间map的 key，而不是value值。\nvar mapone map[string]stringmapone = map[string]string&#123;&quot;one&quot;: &quot;jimmmy&quot;, &quot;two&quot;: &quot;tom&quot;, &quot;three&quot;: &quot;&quot;&#125;err = validate.Var(mapone, &quot;gte=3,dive,keys,eq=1|eq=2,endkeys,required&quot;)if err != nil &#123;    // Key: &#x27;[one]&#x27; Error:Field validation for &#x27;[one]&#x27; failed on the &#x27;eq=1|eq=2&#x27; tag    // Key: &#x27;[two]&#x27; Error:Field validation for &#x27;[two]&#x27; failed on the &#x27;eq=1|eq=2&#x27; tag    // Key: &#x27;[three]&#x27; Error:Field validation for &#x27;[three]&#x27; failed on the &#x27;eq=1|eq=2&#x27; tag    // Key: &#x27;[three]&#x27; Error:Field validation for &#x27;[three]&#x27; failed on the &#x27;required&#x27; tag    fmt.Println(err)&#125;\n\n常用的验证规则字段验证https://github.com/go-playground/validator/blob/master/README.md#fields\n带有cs的都是跨结构体验证\n\n\n\n标记\n标记说明\n举例\n\n\n\neqfield\n同一结构体字段验证相等\n\n\n\nnefield\n同一结构体字段验证不相等\nvalidate:”eqfield=Password”\n\n\neqcsfield\n跨不同结构体字段验证\n\n\n\nnecsfield\n跨不同结构体字段不相等\n\n\n\ngtefield\n大于等于同一结构体字段\n\n\n\nltefield\n小于等于同一结构体字段\n\n\n\n网络验证https://github.com/go-playground/validator/blob/master/README.md#network\n\n\n\n标记\n标记说明\n举例\n\n\n\nip\n字段值是否包含有效的IP地址\nvalidate:&quot;ip&quot;\n\n\n字符串验证\n\n\n标记\n标记说明\n举例\n\n\n\nip\n字段值是否包含有效的IP地址\nvalidate:&quot;ip&quot;\n\n\n自定义验证规则修改获取验证规则的标签名字SetTagName 修改验证默认的标签，默认的标签是validate\n// 默认的标签是validatetype User struct &#123;    Name string `validate:&quot;required&quot;`    Age  int    `validate:&quot;required&quot;`&#125;// 修改为checkvalidate.SetTagName(&quot;check&quot;)// 就可以这么写了type User struct &#123;    Name string `check:&quot;required&quot;`    Age  int    `check:&quot;required&quot;`&#125;\n注册一个获取tag的自定义方法RegisterTagNameFunc  默认情况下在错误信息中是获取的结构体的字段，可以修改为获取字段描述中其他字段的，比如说 json tag\nvar validate *validator.Validate = validator.New()type User struct &#123;    Name string `json:&quot;name_json&quot; form:&quot;name_form&quot; validate:&quot;required&quot;`    Age  int    `json:&quot;age_json&quot; form:&quot;age_form&quot; validate:&quot;required&quot;`&#125;func TestValidateStruct1(t *testing.T) &#123;    user := User&#123;&#125;    err := validate.Struct(user)    if err != nil &#123;        // Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag        // Key: &#x27;User.Age&#x27; Error:Field validation for &#x27;Age&#x27; failed on the &#x27;required&#x27; tag        fmt.Println(err)    &#125;&#125;--------------------------------------------------------------------------// 注册一个获取json tag的自定义方法validate.RegisterTagNameFunc(func(fld reflect.StructField) string &#123;    name := strings.SplitN(fld.Tag.Get(&quot;json&quot;), &quot;,&quot;, 2)[0]    // skip if tag key says it should be ignored    if name == &quot;-&quot; &#123;        return &quot;&quot;    &#125;    return name&#125;)func TestValidateStruct1(t *testing.T) &#123;    user := User&#123;&#125;    err := validate.Struct(user)    if err != nil &#123;        // Key: &#x27;User.name_json&#x27; Error:Field validation for &#x27;name_json&#x27; failed on the &#x27;required&#x27; tag        // Key: &#x27;User.age_json&#x27; Error:Field validation for &#x27;age_json&#x27; failed on the &#x27;required&#x27; tag        fmt.Println(err)    &#125;&#125;\n\n为一个自定义标签创建验证规则RegisterValidation 函数接收一个标签名字和一个验证函数。\npackage testimport (    &quot;fmt&quot;    &quot;github.com/go-playground/validator/v10&quot;    &quot;testing&quot;)var validate *validator.Validate = validator.New()type User struct &#123;    Name string `validate:&quot;required,check_name&quot;`    Age  int    `validate:&quot;required&quot;`&#125;//// TestRegisterValidation//  @Description: 自定义tag创建验证规则//  @param t//func TestRegisterValidation(t *testing.T) &#123;    // 为tag为check_name注册验证规则    _ = validate.RegisterValidation(&quot;check_name&quot;, CheckName)    user := User&#123;&quot;zhangsan&quot;, 30&#125;    err := validate.Struct(user)    if err != nil &#123;        // Key: &#x27;User.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;check_name&#x27; tag        fmt.Println(err)    &#125;    fmt.Println(&quot;Check Done!&quot;)&#125;//// CheckName//  @Description: 自定义验证规则-验证name//  @param f//func CheckName(f validator.FieldLevel) bool &#123;    // 获取字段的值,然后判断是否等于&quot;hanpy&quot;    return f.Field().String() == &quot;hanpy&quot;&#125;\n\n为结构体注册验证规则RegisterStructValidation \npackage testimport (    &quot;fmt&quot;    &quot;github.com/go-playground/validator/v10&quot;    &quot;testing&quot;)var validate *validator.Validate = validator.New()type User struct &#123;    Name string `validate:&quot;required&quot;`    Age  int    `validate:&quot;required&quot;`&#125;//// TestRegisterStructValidation//  @Description: 为结构体注册验证规则//  @param t//func TestRegisterStructValidation(t *testing.T) &#123;    // 为User注册规则    validate.RegisterStructValidation(UserStructLevelValidation, User&#123;&#125;)    user := User&#123;&quot;zha&quot;, 30&#125;    err := validate.Struct(user)    if err != nil &#123;        // Key: &#x27;User.fname&#x27; Error:Field validation for &#x27;fname&#x27; failed on the &#x27;fnameorlname&#x27; tag        fmt.Println(err)    &#125;    fmt.Println(&quot;Check Done!&quot;)&#125;//// UserStructLevelValidation//  @Description: 自定义结构体验证//  @param sl//func UserStructLevelValidation(sl validator.StructLevel) &#123;    user := sl.Current().Interface().(User)    if len(user.Name) == 3 &#123;        sl.ReportError(user.Name, &quot;fname&quot;, &quot;FirstName&quot;, &quot;fnameorlname&quot;, &quot;&quot;)    &#125;&#125;\n\n为某个类型创建验证规则RegisterCustomTypeFunc  可以为某种类创建验证规则\n// \n\n多语言的支持错误信息中支持中文\npackage testimport (\t&quot;fmt&quot;\t&quot;github.com/go-playground/locales/en&quot;\t&quot;github.com/go-playground/locales/zh&quot;\tut &quot;github.com/go-playground/universal-translator&quot;\t&quot;github.com/go-playground/validator/v10&quot;\tzhs &quot;github.com/go-playground/validator/v10/translations/zh&quot;\t&quot;testing&quot;)var (\tvalidate = validator.New()          // 实例化验证器\tchinese  = zh.New()                 // 获取中文翻译器\tenglish  = en.New()                 // 英文翻译器\tuni      = ut.New(english, chinese) // 第一个参数是必填，如果没有其他的语言设置，就用这第一个; 设置成中文翻译器\ttrans, _ = uni.GetTranslator(&quot;zh&quot;)  // 获取翻译字典)type Teacher struct &#123;\tName  string `validate:&quot;required,min=3,max=5&quot;`\tEmail string `validate:&quot;email&quot;`\tAge   int8   `validate:&quot;gte=18,lte=20&quot;`&#125;func TestValidatorZh(t *testing.T) &#123;\t// 注册翻译器\t_ = zhs.RegisterDefaultTranslations(validate, trans)\tteacher := Teacher&#123;&quot;zh&quot;, &quot;han126.com&quot;, 10&#125;\terr := validate.Struct(teacher)\tif err != nil &#123;\t\t// map[Teacher.Age:Age必须大于或等于18 Teacher.Email:Email必须是一个有效的邮箱 Teacher.Name:Name长度必须至少为3个字符]\t\tif errors, ok := err.(validator.ValidationErrors); ok &#123;\t\t\tfmt.Println(errors.Translate(trans))\t\t&#125;\t&#125;&#125;\n\n为字段添加描述Todo\n可以为结构体中的字段添加一个描述，验证失败的时候可以进行中文的提示，比如下面这种\ntype User struct &#123;    Name string `json:&quot;name&quot; validate:&quot;required&quot; desc:&quot;姓名&quot;`&#125;// 最后要达到的效果是，验证失败提示：姓名必填\n\n","categories":["Golang","Package"],"tags":["go","validator"]},{"title":"Golang学习 - 命令源码文件","url":"/2022/12/11/go-source-code.html","content":"Golang的环境变量 GOPATH 指向的是一个或多个工作区，每个工作区中都会有以代码包为基本组织形式的源码文件。源码文件又分为三种，即：命令源码文件、库源码文件和测试源码文件，它们都有着不同的用途和编写规则。\n\n\n命令源码文件定义：如果一个源码文件声明属于main包，并且包含一个无参数无返回的main函数，这个文件就是命令源码文件。\n命令源码文件的特性\n独立的程序入口\n属于main包，并且有一个无参数无返回值的main函数\n可以通过 go run 命令来执行，可以接收命令行参数\nmain函数的结束就意味着程序的结束\n同一个代码包不要放多个命令源码文件\n命令源码文件和库源码文件也不要在同一个文件中\n\n命令源码文件构建\n构建后生成可执行文件\n生成位置在命令可执行目录（GOBIN目录）\n\n命令源码文件安装\n安装后生成可执行文件\n位置在当前工作区的bin目录，或者是GOBIN包含的目录\n\n库源码文件库源码文件的特性用来放置其他代码使用的程序实体，也就是代码包\n\n库源码文件编译\n作用在于检查和验证\n构建后只生成临时文件\n\n库文件安装\n安装后生成归档文件\n生成位置在GOPATH的pkg目录下\n\n\n测试源码文件功能测试源码文件函数名称规则：TestXXX函数签名：（t *testing.T）性能测试（基准测试）文件函数名称规则：BenchmarkXXXX函数签名：（b *testing.B）\n","categories":["Golang"],"tags":["go"]},{"title":"Golang学习 - 反射（reflect）简单使用","url":"/2023/01/30/go-reflect.html","content":"Go 中的反射是用 reflect  包实现，reflect  包实现了运行时的反射能力，能够让程序操作不同的对象。反射是 Go 语言很重要的一个特性\n\n\n反射的两种基本类型反射包中有两对非常重要的函数和类型\n\n\n\n方法名\n描述\n\n\n\nreflect.TypeOf\n可以获得任意值的类型对象,返回类型: reflect.Type\n\n\nreflect.ValueOf\n可以获得任意值的值对象,返回类型: reflect.Value\n\n\n这两个函数的参数都是空接口 interface&#123;&#125; ，内部存储了即将被反射的变量。\n可以将 reflect.Value 看作反射的值，reflect.Type 看作反射的实际类型。其中，reflect.Type是一个接口，包含和类型有关的许多方法签名。reflect.Value 是一个结构体，其内部包含了很多方法。\nreflect.TypeOfreflect.Type 接口具体方法列表\n常用方法\n\n\n方法\n描述\n\n\n\nKind() Kind\n返回该变量的的具体分类\n\n\nName() string\n返回该类型在自身包内的类型名，如果是未命名类型会返回””\n\n\nNumField() int\n返回struct类型的字段数（匿名字段算作一个字段），如非结构体类型将 panic\n\n\nField(i int) StructField\n返回struct类型的第i个字段的类型，如非结构体或者i不在[0, NumField())内将会 panic\n\n\nImplements(u Type) bool\n如果该类型实现了u代表的接口，会返回真\n\n\nLen() int\n返回array类型的长度，如非数组类型将 panic\n\n\nElem() Type\n返回该类型的元素类型，如果该类型的Kind不是 Array、Chan、Map、Ptr 或 Slice，会 panic\n\n\nKey() Type\n返回map类型的键的类型。如非映射类型将 panic\n\n\n常见的两个结构体和类型StructField 类型描述结构体中的一个字段的信息。\ntype StructField struct &#123;    // Name是字段的名字。PkgPath是非导出字段的包路径，对导出字段该字段为&quot;&quot;。    // 参见http://golang.org/ref/spec#Uniqueness_of_identifiers    Name    string    PkgPath string    Type      Type      // 字段的类型    Tag       StructTag // 字段的标签    Offset    uintptr   // 字段在结构体中的字节偏移量    Index     []int     // 用于Type.FieldByIndex时的索引切片    Anonymous bool      // 是否匿名字段&#125;\n\nStructTag  是结构体字段的标签。\ntype StructTag string// Get方法返回标签字符串中键key对应的值。如果标签中没有该键，会返回&quot;&quot;。如果标签不符合标准格式，Get的返回值是不确定的。func (tag StructTag) Get(key string) string\n\n简单使用package mainimport (    &quot;fmt&quot;    &quot;reflect&quot;)type User struct &#123;    Name string    Age  int&#125;func main() &#123;    user := User&#123;&quot;zhangsan&quot;, 30&#125;    // 通过反射的方式获取user的类型信息    userTypeOf := reflect.TypeOf(user)    // Kind:返回该变量的的具体分类    fmt.Printf(&quot;%v \\n&quot;, userTypeOf.Kind().String()) // struct    // Name 返回该类型在自身包内的类型名，如果是未命名类型会返回&quot;&quot;    fmt.Println(userTypeOf.Name())                    // User    fmt.Printf(&quot;user有%d个字段\\n&quot;, userTypeOf.NumField()) // user有2个字段    fmt.Printf(&quot;user的第一个字段的类型是是%v\\n&quot;, userTypeOf.Field(0).Name)    arr := [...]int&#123;1, 2, 3, 4, 5&#125;    arrTypeOf := reflect.TypeOf(arr)    // 返回array类型的长度，如非数组类型将 panic    fmt.Printf(&quot;数组arr的长度是%d\\n&quot;, arrTypeOf.Len()) // 数组arr的长度是5    // 返回该类型的元素类型，如果该类型的Kind不是 `Array`、`Chan`、`Map`、`Ptr` 或 `Slice`，会 panic    fmt.Printf(&quot;数组arr的类型是%s\\n&quot;, arrTypeOf.Elem().Kind().String()) // 数组arr的类型是int    m := map[string]string&#123;        &quot;name&quot;: &quot;zhangsan&quot;,    &#125;    mTypeOf := reflect.TypeOf(m)    // 返回map类型的键的类型。如非映射类型将 panic    fmt.Printf(&quot;Map m的key的类型是%s\\n&quot;, mTypeOf.Key().Kind().String()) // Map m的key的类型是string&#125;\n\nreflect.Valuereflect.ValueOf() 获取数据信息，返回 Value 类型。Value被声明成了结构体。这个结构体没有对外暴露的字段，但是提供了获取或者写入数据的方法\n常用方法\n\n\n方法名\n描述\n\n\n\nField(i int) StructField\n返回结构体的第i个字段（的Value封装）。如果v的Kind不是Struct或i出界会panic\n\n\nFieldByName(name string) Value\n返回该类型名为name的字段（的Value封装）（会查找匿名字段及其子字段）\n\n\nIndex(i int) Value\n返回第 i 个元素,主要用于遍历,不能越界。前提类型是Array, Slice, String之一，\n\n\nSet(x Value)\n通过反射修改值。\n\n\nType() Type\n获取值的类型\n\n\n简单使用func ValueOf() &#123;    user := User&#123;&quot;hanpy&quot;, 32&#125;    userValueOf := reflect.ValueOf(user)    // 返回struct 类型的第 i 个字段的值，不是struct 会 panic，越界也会panic    fmt.Printf(&quot;结构体user第1个字段值是: %v\\n&quot;, userValueOf.Field(0)) // 结构体user第1个字段值: hanpy    // 根据属性名获取值    fmt.Printf(&quot;结构体user字段%s的值是: %v\\n&quot;, &quot;Name&quot;, userValueOf.FieldByName(&quot;Name&quot;)) // 结构体user字段Name的值是: hanpy    strSlice := []string&#123;&quot;你&quot;, &quot;我&quot;, &quot;他&quot;, &quot;!&quot;&#125;    strSliceValOf := reflect.ValueOf(strSlice)    fmt.Printf(&quot;打印字符串第%d个元素值v: %v\\n&quot;, 0, strSliceValOf.Index(0)) // 打印字符串第0个元素值v: 你    fmt.Printf(&quot;打印字符串第%d个元素值v: %v\\n&quot;, 1, strSliceValOf.Index(1)) // 打印字符串第1个元素值v: 我    fmt.Printf(&quot;打印字符串第%d个元素值v: %v\\n&quot;, 3, strSliceValOf.Index(2)) // 打印字符串第3个元素值v: 他    // 修改值    num := 10    numValOf := reflect.ValueOf(&amp;num) //注意这里需要传地址    fmt.Printf(&quot;修改前的值: %v \\n&quot;, num)    numValOf.Set(reflect.ValueOf(100))    fmt.Printf(&quot;修改后的值: %v \\n&quot;, num)&#125;\n\n","categories":["Golang"],"tags":["go","reflect"]},{"title":"Golang标准库学习 - flag","url":"/2022/12/30/go-standard-flag.html","content":"flag 包实现了命令行参数的解析。\n\n\n命令行选项格式flag 库支持三种命令行选项格式。\n-flag-flag=x-flag x\n\n-和--都可以使用，它们的作用是一样的。第一种形式只支持布尔类型的选项，出现即为true，不出现为默认值。 第三种形式不支持布尔类型的选项。因为这种形式的布尔选项在类 Unix 系统中可能会出现意想不到的行为。\n接收参数flag.Type 的方式package mainimport (    &quot;flag&quot;    &quot;fmt&quot;)var (    stringflag *string    intflag    *int    boolflag   *bool)func init() &#123;    stringflag = flag.String(&quot;stringflag&quot;, &quot;default&quot;, &quot;提示: stringflag&quot;)    intflag = flag.Int(&quot;intflag&quot;, 10, &quot;提示: intflag&quot;)    boolflag = flag.Bool(&quot;boolflag&quot;, false, &quot;提示: boolflag&quot;)&#125;func main() &#123;    flag.Parse()    fmt.Println(&quot;int flag:&quot;, *intflag)    fmt.Println(&quot;bool flag:&quot;, *boolflag)    fmt.Println(&quot;string flag:&quot;, *stringflag)&#125;\n\n# 编译➜ go build -o main -v main.go# 无参数运行➜ ./main int flag: 10bool flag: falsestring flag: default# 有参数运行➜ ./main -stringflag=han -intflag=10 -boolflagint flag: 10bool flag: truestring flag: han# 帮助命令➜ ./main -hUsage of ./main:  -boolflag        提示: boolflag  -intflag int        提示: intflag (default 10)  -stringflag string        提示: stringflag (default &quot;default&quot;)\n\nflag.TypeVar方式package mainimport (    &quot;flag&quot;    &quot;fmt&quot;)var (    stringflag string    intflag    int    boolflag   bool)func init() &#123;    flag.StringVar(&amp;stringflag, &quot;stringflag&quot;, &quot;default&quot;, &quot;提示: stringflag&quot;)    flag.IntVar(&amp;intflag, &quot;intflag&quot;, 10, &quot;提示: intflag&quot;)    flag.BoolVar(&amp;boolflag, &quot;boolflag&quot;, false, &quot;提示: boolflag&quot;)&#125;func main() &#123;    flag.Parse()    fmt.Println(&quot;int flag:&quot;, intflag)    fmt.Println(&quot;bool flag:&quot;, boolflag)    fmt.Println(&quot;string flag:&quot;, stringflag)&#125;\n\n输出和 flag.Type 的方式是一样的。\nflag.Var 方式flag.Var 这种方式需要实现 flag.Value 接口\ntype Value interface &#123;    String() string    Set(string) error&#125;\n\n简单使用\npackage mainimport (    &quot;flag&quot;    &quot;fmt&quot;    &quot;strings&quot;)type List []stringfunc (l *List) String() string &#123;    return fmt.Sprintf(&quot;%v&quot;, *l)&#125;func (l *List) Set(s string) error &#123;    // 分割字符串    split := strings.Split(s, &quot;,&quot;)    *l = split    return nil&#125;var l Listfunc init() &#123;    flag.Var(&amp;l, &quot;list&quot;, &quot;长标记-列表,用英文逗号分割&quot;)    flag.Var(&amp;l, &quot;l&quot;, &quot;短标记-列表,用英文逗号分割&quot;)&#125;func main() &#123;    // 解析参数    flag.Parse()    fmt.Printf(&quot;listi s %v \\n&quot;, l)&#125;\n\n执行\n➜ ./main -list=one,two,threelisti s [one two three]➜ ./main -l=name,age,addrlisti s [name age addr]➜ ./main- hUsage of ./main:  -l value    \t短标记-列表,用英文逗号分割  -list value    \t长标记-列表,用英文逗号分割\n\n解析程序中的字符串有时候选项并不是通过命令行传递的。例如，从配置表中读取或程序生成的。这时候可以使用flag.FlagSet结构的相关方法来解析这些选项。\npackage mainimport (    &quot;flag&quot;    &quot;fmt&quot;)func main() &#123;    // 创建FlagSet类型变量    myFlagSet := flag.NewFlagSet(&quot;myFlag&quot;, flag.ExitOnError)    // 从切片中解析    // args := []string&#123;&quot;-intflag&quot;, &quot;12&quot;, &quot;-stringflag&quot;, &quot;test&quot;&#125;    args := []string&#123;&quot;-intflag&quot;, &quot;12&quot;, &quot;-stringflag&quot;, &quot;test&quot;&#125;    intflag := myFlagSet.Int(&quot;intflag&quot;, 10, &quot;提示: intflag&quot;)    stringflag := myFlagSet.String(&quot;stringflag&quot;, &quot;default&quot;, &quot;提示: stringflag&quot;)    // 解析    myFlagSet.Parse(args)    // 打印    fmt.Printf(&quot;stringflag的值是 %v \\n&quot;, *stringflag)    fmt.Printf(&quot;intflag的值是 %v \\n&quot;, *intflag)&#125;\n\n➜ ./mainstringflag的值是 testintflag的值是 12\n\n几个常用的数据结构错误相关\ntype ErrorHandling intconst (    ContinueOnError ErrorHandling = iota\t// 发生错误后继续解析,返回错误    ExitOnError\t// 出错时调用os.Exit(2)退出程序    PanicOnError\t// 出错时产生 panic)\n\nFlag类型代表一条flag的状态。\ntype Flag struct &#123;    Name     string // flag在命令行中的名字    Usage    string // 帮助信息    Value    Value  // 要设置的值    DefValue string // 默认值（文本格式），用于使用信息&#125;\n\nFlagSet代表一个已注册的flag的集合。FlagSet零值没有名字，采用ContinueOnError错误处理策略。\ntype FlagSet struct &#123;    Usage         func()           // 解析标志时发生错误时调用的函数    name          string           // FlagSet 的名字。CommandLine 给的是 os.Args[0]    parsed        bool             // 是否执行过 Parse()    actual        map[string]*Flag // 存放实际传递了的参数（即命令行参数）    formal        map[string]*Flag // 存放所有已定义命令行参数    args          []string         // 开始存放所有参数，最后保留 非 flag（non-flag）参数    errorHandling ErrorHandling    // 当解析出错时，处理错误的方式    output        io.Writer        // nil means stderr; use Output() accessor&#125;\n\n","categories":["Golang","标准库"],"tags":["flag"]},{"title":"Golang标准库学习 - strconv","url":"/2022/11/18/go-standard-strconv.html","content":"strconv主要用于字符串和基本数据类型之间转换，练习一下常用到的方法来加深记忆。\n\n\n字符串和整型之间的转换字符串转为整型func ParseInt(s string, base int, bitSize int) (i int64, err error)func ParseUint(s string, base int, bitSize int) (n uint64, err error)func Atoi(s string) (i int, err error)\n\n参数 base 代表字符串按照给定的进制进行解释。一般的，base 的取值为 2~36，如果 base 的值为 0，则会根据字符串的前缀来确定 base 的值：”0x” 表示 16 进制； “0” 表示 8 进制；否则就是 10 进制。\n参数 bitSize 表示的是整数取值范围，或者说整数的具体类型。取值 0、8、16、32 和 64 分别代表 int、int8、int16、int32 和 int64。\nAtoi 是 ParseInt 的便捷版，内部通过调用 ParseInt(s, 10, 0) 来实现的\n主要来看一下ParseInt的使用\n// 把字符串s转换为int8类型的整数s := &quot;20&quot;// base代表字符串按照给定的进制进行解释,base的取值为 2~36// bitSize表示的是整数取值范围，或者说整数的具体类型。// 取值 0、8、16、32 和 64 分别代表 int、int8、int16、int32 和 int64parseInt64, err := strconv.ParseInt(s, 10, 8)if err != nil &#123;    fmt.Println(err)&#125;pInt8 := int8(parseInt64)fmt.Println(pInt8)\n\n函数返回的是int64的类型,这是为了能够容纳所有的整型，在实际使用中，可以根据传递的 bitSize，然后将结果转为实际需要的类型。\n只要是传入的base和bitSize是匹配的并且err为nil，转换为bitSize的类型就是没有问题的。如果字符串表示的整数超过了 bitSize 参数能够表示的范围，则会返回 ErrRange，同时会返回 bitSize 能够表示的最大或最小值。\n// 把字符串s转换为int8类型的整数(int8最大可表示整数为127)s := &quot;128&quot;parseInt64, err := strconv.ParseInt(s, 10, 8)fmt.Println(parseInt64)if err != nil &#123;    fmt.Println(err)    return&#125;// 127// strconv.ParseInt: parsing &quot;128&quot;: value out of range\n\n整型转为字符串func FormatUint(i uint64, base int) string    // 无符号整型转字符串func FormatInt(i int64, base int) string    // 有符号整型转字符串func Itoa(i int) string\n\ni := 1289str := strconv.FormatInt(int64(i), 10)fmt.Println(str)\n\n还有另外的方法\nfmt.Sprintf(&quot;%d&quot;, 127)\n\nSprintf性能要差一些，因为它接收的是 interface，需要进行反射等操作，所以建议使用 strconv 包中的方法进行转换。\n字符串和布尔值之间的转换// 接受 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False 等字符串；// 其他形式的字符串会返回错误func ParseBool(str string) (value bool, err error)// 直接返回 &quot;true&quot; 或 &quot;false&quot;func FormatBool(b bool) string// 将 &quot;true&quot; 或 &quot;false&quot; append 到 dst 中// 这里用了一个 append 函数对于字符串的特殊形式：append(dst, &quot;true&quot;...)func AppendBool(dst []byte, b bool)\n\n","categories":["Golang","标准库"],"tags":["go","strconv"]},{"title":"Golang标准库学习 - Strings","url":"/2022/12/03/go-standard-strings.html","content":"strings 包实现了用于操作字符的简单函数。\n\n\n常用的方法列表strings标准库文档\n\n\n\n方法名\n描述\n\n\n\nEqualFold(s, t string) bool\n判断两个字符串是否相同(忽略大小写)\n\n\nHasPrefix(s, prefix string) bool\n判断s是否有前缀字符串prefix。\n\n\nHasSuffix(s, suffix string) bool\n判断s是否有后缀字符串suffix\n\n\nContains(s, substr string) bool\n判断字符串s是否包含子串substr，(substr如果是“ ”返回true)\n\n\nIndex(s, sep string) int\n子串sep在字符串s中第一次出现的位置，不存在则返回-1\n\n\nLastIndex(s, sep string) int\n子串sep在字符串s中最后一次出现的位置，不存在则返回-1。\n\n\nTitle(s string) string\n返回s中每个单词的首字母都改为标题格式的字符串拷贝。\n\n\nToLower(s string) string\n转换为小写\n\n\nToUpper(s string) string\n转换为大写\n\n\nContains判断字符串s是否包含子串substr，(substr如果是“ ”返回true)\nfmt.Println(strings.Contains(&quot;seafood&quot;, &quot;&quot;))\t// true\n\nIndex子串sep在字符串s中第一次出现的位置，不存在则返回-1\nfmt.Println(strings.Index(&quot;chicken&quot;, &quot;ken&quot;))\t// 4fmt.Println(strings.Index(&quot;chicken&quot;, &quot;dmr&quot;))\t// -1\n\nLastIndex子串sep在字符串s中最后一次出现的位置，不存在则返回-1。\nfmt.Println(strings.Index(&quot;go gopher&quot;, &quot;go&quot;))\t// 0fmt.Println(strings.LastIndex(&quot;go gopher&quot;, &quot;go&quot;))\t// 3fmt.Println(strings.LastIndex(&quot;go gopher&quot;, &quot;rodent&quot;))\t// -1\n\nTitlefmt.Println(strings.Title(&quot;hello wor1d&quot;)) // Hello Wor1d\n\nToLower | ToUpperfmt.Println(strings.ToLower(&quot;HELLO&quot;)) // hellofmt.Println(strings.ToUpper(&quot;word&quot;))  // WORD\n\n字符串分割\n\n\n方法名\n描述\n\n\n\nFields(s string) []string\n将字符串s以空白字符分割，返回切片\n\n\nFieldsFunc(s string, f func(rune) bool) []string\n使用函数f来确定分割符如果字符串全部是分隔符或者是空字符串的话，会返回空切片。\n\n\nSplit(s, sep string) []string\n将字符串s以sep作为分割符进行分割，分割后字符最后去掉sep,返回切片\n\n\nSplitN(s, sep string, n int) []string\n将字符串s以sep作为分割符进行分割，分割后字符最后去掉sep,n决定分割成切片长度\n\n\nSplitAfter(s, sep string) []string\n将字符串s以sep作为分割符进行分割，分割后字符最后加上sep,返回切片\n\n\nSplitAfterN(s, sep string, n int) []string\n将字符串s以sep作为分割符进行分割，分割后字符最后加上sep,n决定分割成切片长度\n\n\nFieldss := &quot;hello word golang&quot;fmt.Println(strings.Fields(s)) // [hello word golang]\n\nSplitss := &quot;@123@张@AB@001&quot;sep := &quot;@&quot;slice1 := strings.Split(s, sep)fmt.Println(slice1) // [ 123 张 AB 001]\n\nSplitN将字符串s以sep作为分割符进行分割,分割后字符最后去掉sep,n决定分割成切片长度\nn &gt; 0 : 返回的切片最多n个，最后一个子字符串包含未进行切割的部分。n == 0: 返回niln &lt; 0 : 返回所有的子字符串组成的切片\n\ns := &quot;a@b@c@d@e&quot;fmt.Println(strings.SplitN(s, &quot;@&quot;, 2))  // [a b@c@d@e]fmt.Println(strings.SplitN(s, &quot;@&quot;, 0))  // []fmt.Println(strings.SplitN(s, &quot;@&quot;, -1)) // [a b c d e]\n\nSplitAfter、SplitAfterNfmt.Println(strings.SplitAfter(s, &quot;@&quot;))     // [a@ b@ c@ d@ e]fmt.Println(strings.SplitAfterN(s, &quot;@&quot;, 2)) // [a@ b@c@d@e]\n\n字符串替换\n\n\n方法名\n描述\n\n\n\nReplace(s, old, new string, n int) string\n返回将s中前n个不重叠old子串都替换为new的新字符串，如果n&lt;0会替换所有old子串。\n\n\nReplaceAll(s, old, new string) string\n将字符串s中的old子串全部替换为new的新字符串\n\n\nstr := &quot;a@b@c@d@e&quot;fmt.Println(strings.ReplaceAll(str, &quot;@&quot;, &quot;|&quot;))  // a|b|c|d|efmt.Println(strings.Replace(str, &quot;@&quot;, &quot;#&quot;, -1)) // a#b#c#d#e\n\n","categories":["Golang","标准库"],"tags":["go","string"]},{"title":"Golang标准库学习 - Time","url":"/2022/12/20/go-standard-time.html","content":"time包提供了时间和日历的相关的函数与方法\n\n\n主要类型\nLocation：代表一个地区，并表示该地区所在的时区（可能多个）\nTime：代表一个纳秒精度的时间点，是公历时间。\nDuration：代表两个时间点之间经过的时间，以纳秒为单位。可表示的最长时间段大约 290 年。\nTimer 和 Ticker\nWeekday 和 Month\n\n当前时间操作\n\n\n方法\n描述\n\n\n\nfunc Now() Time\nNow返回当前本地时间。\n\n\nfunc (t Time) Unix() int64\n返回一个时间戳\n\n\nfunc (t Time) Format(layout string) string\nFormat根据layout指定的格式返回t代表的时间点的格式化文本表示2006-01-02 15:04:05\n\n\n// 1. 获取当前时间now := time.Now()// 2. 当前时间时间戳timestamp := now.Unix()fmt.Println(timestamp)// 3. 当前时间格式化nowDate := now.Format(&quot;2006-01-02 15:04:05&quot;)fmt.Println(nowDate)fmt.Printf(&quot;year:%v\\n&quot;, now.Format(&quot;2006&quot;))fmt.Printf(&quot;Hour:%v\\n&quot;, now.Format(&quot;15&quot;))\n\n时间转换\n\n\n方法\n描述\n\n\n\nfunc Unix(sec int64, nsec int64) Time\nUnix创建一个本地时间，对应sec和nsec表示的Unix时间\n\n\nfunc Parse(layout, value string) (Time, error)\n解析一个格式化的时间字符串并返回它代表的时间\n\n\n// 1. 时间戳转时间var tt int64 = 1671524861unix := time.Unix(tt, 0)fmt.Println(unix.Format(&quot;2006-01-02 15:04:05&quot;))// 2. 时间戳转时间(字符串)s := &quot;1671524861&quot;sInt64, _ := strconv.ParseInt(s, 10, 64)timeUnix := time.Unix(sInt64, 0)fmt.Println(timeUnix.Format(&quot;2006-01-02 15:04:05&quot;))// 3. 时间格式转Timedates := &quot;2022-12-04 12:01:02&quot;parseTime, _ := time.Parse(&quot;2006-01-02 15:04:05&quot;, dates)fmt.Println(parseTime.Format(&quot;2006-01-02 15:04:05&quot;))\n时间比较\n\n\n方法\n描述\n\n\n\nfunc (t Time) Equal(u Time) bool\n判断时间是否相同，会考虑时区和地区\n\n\nfunc (t Time) Before(u Time) bool\nt代表的时间点在u之前，返回真；否则返回假\n\n\nfunc (t Time) After(u Time) bool\nt代表的时间点在u之后，返回真；否则返回假。\n\n\nd1 := &quot;2022-12-03 12:01:02&quot;d2 := &quot;2022-12-04 12:01:02&quot;d1Time, _ := time.Parse(&quot;2006-01-02 15:04:05&quot;, d1)d2Time, _ := time.Parse(&quot;2006-01-02 15:04:05&quot;, d2)fmt.Println(d1Time.Before(d2Time)) // truefmt.Println(d1Time.After(d2Time))  // false\n\n其他常用方法\n\n\n方法\n描述\n\n\n\nfunc (t Time) Date() (year int, month Month, day int)\n回时间点t对应的年、月、日\n\n\nfunc (t Time) Clock() (hour, min, sec int)\n返回t对应的那一天的时、分、秒。\n\n\nfunc (t Time) Year() int\n返回时间点t对应的年份。\n\n\nfunc (t Time) Month() Month\n返回时间点t对应那一年的第几月。\n\n\nfunc (t Time) Day() int\n返回时间点t对应那一月的第几日。\n\n\nfunc (t Time) YearDay() int\n返回时间点t对应的那一年的第几天，平年的返回值范围[1,365]，闰年[1,366]。\n\n\nfunc (t Time) Weekday() Weekday\n返回时间点t对应的那一周的周几。\n\n\nfunc (t Time) Hour() int\n返回t对应的那一天的第几小时，范围[0, 23]。\n\n\nfunc (t Time) Minute() int\n返回t对应的那一小时的第几分种，范围[0, 59]。\n\n\nfunc (t Time) Second() int\n返回t对应的那一分钟的第几秒，范围[0, 59]。\n\n\n","categories":["Golang","标准库"],"tags":["go","time"]},{"title":"Golang学习 - 结构体（struct）","url":"/2023/01/16/go-struct.html","content":"Go 语言提供了结构体来定义复杂的数据类型。结构体是由一系列相同类型或不同类型的数据构成的数据集合。\n\n\n定义和实例化定义结构体的定义使用关键字 type 和 struct 来进行\ntype 类型名称 struct &#123;    field type    field type     field1,field2,field3 type // 同类型变量可以写在一行&#125;\n\n需要注意几点\n\n类型名在包内是唯一的\n在同一个结构体中字段也是唯一的\n相同类型的字段可以写在一行\n实例化之后才能使用结构体的字段\n\n实例化type People struct &#123;    Name string    Age  int    Like []string&#125;\n\n使用var\nfunc main() &#123;    var p People    p.Name = &quot;hanpy&quot;    p.Age = 30    p.Like = []string&#123;&quot;basketball&quot;&#125;    // 变量p,类型: main.People 值: &#123;hanpy 30 [basketball]&#125;     fmt.Printf(&quot;变量p,类型: %T 值: %v \\n&quot;,p,p)&#125;\n\n使用:=\nfunc main()  &#123;    // 1. 分开赋值    p1 := People&#123;&#125;    p1.Name = &quot;zhangsan&quot;    p1.Age = 20    p1.Like = []string&#123;&quot;basketball&quot;&#125;    // 变量p,类型: main.People 值: &#123;zhangsan 20 [basketball]&#125;    fmt.Printf(&quot;变量p,类型: %T 值: %v \\n&quot;,p1,p1)    // 2. 直接赋值    p2:= People&#123;        Name: &quot;hanpy&quot;,        Age:  30,        Like: []string&#123;&quot;football&quot;&#125;,    &#125;    //变量p,类型: main.People 值: &#123;hanpy 30 [football]&#125;    fmt.Printf(&quot;变量p,类型: %T 值: %v \\n&quot;,p2,p2)&#125;\n\nnew\nfunc main()  &#123;    p := new(People)    fmt.Printf(&quot; 变量p,类型: %T 值: %v \\n&quot;,p,p)    // 给属性赋值    (*p).Name = &quot;lisi&quot;    (*p).Age = 20    (*p).Like = []string&#123;&quot;daze&quot;&#125;    fmt.Printf(&quot; 变量p,类型: %T 值: %v \\n&quot;,p,p)    // 语法糖写法    p.Name = &quot;wangwu&quot;    p.Age = 99    p.Like = []string&#123;&quot;sleep&quot;&#125;    fmt.Printf(&quot; 变量p,类型: %T 值: %v \\n&quot;,p,p)&#125;\n\n匿名结构体func main()  &#123;    // 声明初始化匿名结构体    p := struct &#123;        Name string        Age int        Like []string    &#125;&#123;        Name: &quot;zhaoliu&quot;,        Age:  40,        Like: []string&#123;&quot;eat&quot;&#125;,    &#125;    fmt.Printf(&quot; 变量p,类型: %T 值: %v \\n&quot;,p,p)&#125;\n\n匿名字段匿名字段就是在结构体中的字段没有名字，只包含一个没有字段名的类型。这些字段被称为匿名字段。在同一个结构体中,同一个类型只能有一个匿名字段。\ntype People struct &#123;    Name string    int&#125;func main()  &#123;    // 声明初始化匿名结构体    p := People&#123;        Name: &quot;zhangsan&quot;,        int:  20,    &#125;    fmt.Printf(&quot;变量 p 的值: %v \\n&quot;, p)    // 声明初始化匿名结构体(省略属性名)    p1 := People&#123;&quot;lisi&quot;, 19&#125;    fmt.Printf(&quot;变量 p1 的值: %v \\n&quot;, p1)&#125;/*变量 p 的值: &#123;zhangsan 20&#125;变量 p1 的值: &#123;lisi 19&#125; */\n\n结构体嵌套把一个结构体作为另一个结构的字段，就是结构体嵌套。通过结构体嵌套可以模拟出来面向对象编程中的聚合关系和继承关系\n聚合关系type Addr struct &#123;    Province string    City     string    Address  string&#125;type People struct &#123;    Name     string    Age      int    AddrInfo Addr&#125;func main() &#123;    // 1. var    var p1 People    p1.Name = &quot;zhangsan&quot;    p1.Age = 20    p1.AddrInfo.Province = &quot;河北&quot;    p1.AddrInfo.City = &quot;张家口&quot;    p1.AddrInfo.Address = &quot;河西街道&quot;    // 1.1    // p1.AddrInfo = Addr&#123;&quot;河北&quot;, &quot;张家口&quot;, &quot;河西街道&quot;&#125;    // 1.2    //p1.AddrInfo = Addr&#123;    //\tProvince: &quot;河北&quot;,    //\tCity:     &quot;张家口&quot;,    //\tAddress:  &quot;河西街道&quot;,    //&#125;    fmt.Printf(&quot;变量 p1 的值: %v 类型: %T \\n&quot;, p1, p1)    // 2. :=    addrInfo := Addr&#123;&quot;河北&quot;, &quot;张家口&quot;, &quot;河西街道&quot;&#125;    p2 := People&#123;&quot;lishi&quot;, 30, addrInfo&#125;    fmt.Printf(&quot;变量 p2 的值: %v 类型: %T \\n&quot;, p2, p2)    p3 := new(People)    p3.Name = &quot;wangwu&quot;    p3.Age = 40    p3.AddrInfo.Province = &quot;河北&quot;    p3.AddrInfo.City = &quot;张家口&quot;    p3.AddrInfo.Address = &quot;河西街道&quot;    fmt.Printf(&quot;变量 p3 的值: %v 类型: %T \\n&quot;, p3, p3)&#125;\n\n继承关系在结构体中，属于匿名结构体的字段称为提升字段，它们可以被访问，匿名结构体就像是该结构体的父类。\ntype People struct &#123;    Name string    Age  int&#125;type Student struct &#123;    People    // 集成父类结构体    ClassName string&#125;func main() &#123;    s := Student&#123;        People:    People&#123;&quot;zhangsan&quot;, 30&#125;,        ClassName: &quot;三年二班&quot;,    &#125;    fmt.Println(s.ClassName) // 三年二班&#125;\n\n成员冲突type A struct &#123;    Name string    Age  int&#125;type B struct &#123;    Name string&#125;type C struct &#123;    A    B&#125;func main() &#123;    a := A&#123;        Name: &quot;A-Name&quot;,        Age:  1,    &#125;    b := B&#123;        Name: &quot;B-Name&quot;,    &#125;    c := C&#123;        A: a,        B: b,    &#125;    fmt.Println(c.Name)&#125;// ambiguous selector c.Name\n\n","categories":["Golang"],"tags":["go","struct"]},{"title":"iterm2 常用操作","url":"/2021/08/16/iterm2-op.html","content":"记录一些iterm2的常用操作\n\n\niterm2恢复默认配置defaults delete com.googlecode.iterm2\n\niterm2窗口操作\n\n\n操作\n作用\n\n\n\ncommand + t\n新建窗口\n\n\ncommand + d\n垂直分屏\n\n\ncommand + shift + d\n水平分屏\n\n\ncommand + ] 和command + [\n在最近使用的分屏直接切换\n\n\ncommand + alt + 方向键\n切换到指定位置的分屏\n\n\ncommand + 数字\n切换标签页\n\n\ncommand + 方向键\n按方向切换标签页\n\n\ncommand + /\n定位到当前光标\n\n\niterm2命令行常用操作\n\n\n命令\n作用\n\n\n\nctrl + u\n清除当前行\n\n\nctrl + a\n到行首\n\n\nctrl + e\n到行尾\n\n\nctrl + r\n搜索命令历史\n\n\nctrl + d\n删除当前光标的字符\n\n\nctrl + h\n删除光标之前的字符\n\n\nctrl + w\n删除光标之前的单词\n\n\nctrl + k\n删除到文本末尾\n\n\nctrl + t\n交换光标处文本\n\n\n","categories":["随手记"],"tags":["iterm2"]},{"title":"hexo相关整理","url":"/2018/03/22/hexo.html","content":"hexo的各种\n\n\nThemehttps://hexo.io/themes大道至简Theme Cards\nhttps://theme.typora.io/\n","categories":["随手记"],"tags":["hexo"]},{"title":"Linux 系统任务相关命令","url":"/2018/05/20/linux-command-1.html","content":"用了好多次，忘了好多次，也查了好多次，我也是醉了……\n\n\nfg、bg、jobs、&amp;、ctrl + z都是跟系统任务有关的\n1、**&amp;**：放在命令的后面就是后台执行了。\n2、ctrl+z：把一个程序挂起，并且暂停。\n3、jobs：查看当前有多少在后台运行的命令。\n4、fg：将后台中的命令调至前台继续运行(fg:jobnumber)。\n5、bg：将一个在后台暂停的命令，变成继续执行(bg:jobnumber)。\n","categories":["Linux"]},{"title":"JWT 简单了解一下","url":"/2023/03/28/jwt-basic.html","content":"JWT 的全称是 JSON Web Token\n\n\n\n官方网站：https://jwt.io/\n\nJWT 解决的问题\n可以为多种终端提供统一的令牌格式\n跨域认证的问题。（传统的web或者其他开发使用session，都会面临数据同步和持久化的问题）\n\nJWT 的组成从外观上来看，jwt就是一个很长的字符串，中间用两个点（.）分隔成三个部分，这三个部分分别是 Header（头部） 、 Payload（负载）、 Signature（签名）\n# 写成一行就是这样的排列Header.Payload.Signature\n\nHeader（头部）Header 部分是一个 JSON 对象，描述 JWT 的元数据，比如其类型以及签名所用的算法等，可以表示为一个 json 对象\n&#123;  &quot;alg&quot;: &quot;HS256&quot;,  &quot;typ&quot;: &quot;JWT&quot;&#125;\nalg 属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256） \ntyp属性表示这个令牌（token）的类型（type），JWT 令牌统一写为 JWT\n将上面的 JSON 对象使用 Base64URL 算法转成字符串\nPayload（负载）Payload 部分有7个官方规定的字段（不是必须的）\niss (issuer)：签发人exp (expiration time)：过期时间sub (subject)：主题aud (audience)：受众nbf (Not Before)：生效时间iat (Issued At)：签发时间jti (JWT ID)：编号\n\n还可以自定义字段，比如官网的例子\n&#123;  &quot;sub&quot;: &quot;1234567890&quot;,  &quot;name&quot;: &quot;John Doe&quot;,  &quot;iat&quot;: 1516239022&#125;\n\n将上面的 JSON 对象使用 Base64URL 算法转成字符串\nSignature（签名）Signature 部分是对前两部分的签名，防止数据篡改。指定一个密钥（secret），然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256）按照下面的公式计算出签名\nHMACSHA256(  base64UrlEncode(header) + &quot;.&quot; +  base64UrlEncode(payload),  secret)\n\n把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。\n","categories":["随手记"],"tags":["jwt"]},{"title":"Curl 命令的使用","url":"/2019/03/24/linux-curl.html","content":"\ncurl 是常用的命令行工具，用来请求 Web 服务器。c的意思是client的意思。功能非常强大，命令行参数多达几十种，但是我记不住，罗列一些常用的。\n\n\n\n官方网站: https://curl.se官网文档: https://curl.se/docs/manpage.html\n\n-X, –request-X 或者 --request 参数指定 HTTP 请求的方法\nGET方式不带有任何参数时，curl 就是发出 GET 请求。\n# 不带参数$ curl https://hanpy.cn# 带参数$ curl https://hanpy.cn?name=hanpy\n\n-G,--get 参数用来构造 URL 的查询字符串\n下面命令会发出一个GET请求，实际请求的 URL 为https://google.com/search?q=kitties&amp;count=20。如果省略--G，会发出一个 POST 请求。\n#1 $ curl -G -d &#x27;q=kitties&#x27; -d &#x27;count=20&#x27; https://google.com/search#2 如果数据需要 URL 编码，可以结合--data--urlencode参数。$ curl -G --data-urlencode &#x27;comment=hello world&#x27; https://www.example.com\n\nPOST方式# 不带参数$ curl -X POST http://hanpy.cn# 带参数 $ curl -X POST -d &quot;name=hanpy&quot; http://hanpy.cn\n\nHEAD方式#1$ curl -X HEAD -I http://hanpy.cn\n\n-I,--head 参数向服务器发出 HEAD 请求，并将返回服务器的HTTP标头，所以添加-X HEAD好像是没有太大意义\nDELETE方式#1$ curl -X DELETE http://hanpy.cn\n\n-d,–data用于发送 POST 请求的数据体\n-d 参数会自动加上标头 Content-Type : application/x-www-form-urlencoded 并且会自动将请求转为 POST 方法，因此可以省略-X POST\n#1$ curl -d &quot;name=hanpy&amp;age=28&quot; http://hanpy.cn#2$ curl -d &quot;name=hanpy&quot; -d &quot;age=28&quot; http://hanpy.cn#3 读取本地文件发送请求$ curl -d &quot;@param.txt&quot; http://hanpy.cn\n\n--data-urlencode 和 -d 的区别是会进行URL编码\n$ curl --data-urlencode &#x27;content=hello world&#x27; http://hanpy.cn\n\n-H, –header添加 HTTP 请求的标头\n#1$ curl -H &#x27;Accept-Language: en-US&#x27; -H &#x27;Secret-Message: xyzzy&#x27; http://hanpy.cn#2 json格式请求$ curl -d &#x27;&#123;&quot;login&quot;: &quot;emma&quot;, &quot;pass&quot;: &quot;123&quot;&#125;&#x27; -H &#x27;Content-Type: application/json&#x27; http://hanpy.cn\n\n-A,–user-agent指定客户端的用户代理标头，即User-Agent\n#1 User-Agent 修改为google浏览器$ curl -A &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36&#x27; http://hanpy.cn#2 用-H也可以搞定$ curl -H &#x27;User-Agent: php/1.0&#x27; http://hanpy.cn\n\n-b,–cookie参数用来向服务器发送 Cookie。\n#1 单个$ curl -b &#x27;foo=bar&#x27; http://hanpy.cn#2 多个$ curl -b &#x27;name=hanpy;age=28&#x27; http://hanpy.cn#3 发送文本中的cookie$ curl -b cookie.txt http://hanpy.cn\n\n-c,–cookie-jar将服务器设置的 Cookie 写入一个文件。\n#1 将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。$ curl -c cookies.txt http://hanpy.cn\n\n-e,–referer用来设置 HTTP 的标头Referer，表示请求的来源\n#1$ curl -e &#x27;https://www.baidu.com?source=xxx&#x27; https://hanpy.cn#2 用-H还是可以搞定$ curl -H &#x27;Referer: https://google.com?q=example&#x27; https://www.example.com\n\n-o,–output将服务器的回应保存成文件，等同于wget命令\n$ curl -o hanpy.html https://hanpy.cn\n\n-O,–remote-name将服务器回应保存成文件，并将 URL 的最后部分当作文件名。\n$ curl -O https://hanpy.cn\n\n-u, –user用来设置服务器认证的用户名和密码\n#1$ curl -u &#x27;bob:12345&#x27; https://google.com/login#2$ curl https://bob:12345@google.com/login#3 只设置了用户名，执行后，curl 会提示用户输入密码$ curl -u &#x27;bob&#x27; https://google.com/login\n\n-x,–proxy指定 HTTP 请求的代理\n\n-x, –proxy [protocol://]host[:port]\n\n#1 如果没有指定代理协议，默认为 HTTP$ curl -x 127.0.0.1:9999 http://www.cip.cc/地址\t: 美国  加利福尼亚州  洛杉矶运营商\t: digicoreglobal.com数据二\t: 美国 | 加利福尼亚州洛杉矶DGCHost数据中心数据三\t: 中国香港URL\t: http://www.cip.cc/103.82.4.14\n\n","categories":["Linux"],"tags":["curl"]},{"title":"Linux rz sz","url":"/2018/03/27/linux-rz-sz.html","content":"rz，sz是Linux/Unix同Windows进行ZModem文件传输的命令行工具\n\n\n安装：\nyum install lrzsz\n用法：\nsz：将选定的文件发送（send）到本地机器\nrz：运行该命令会弹出一个文件选择窗口，从本地选择文件上传到Linux服务器\n客户端配置：\n在弹出的框中选择文件，上传文件的用户和组是当前登录的用户\nSecureCRT设置默认路径：\nOptions -&gt; Session Options -&gt; Terminal -&gt; Xmodem/Zmodem -&gt;Directories\nXshell设置默认路径：\n右键会话 -&gt; 属性 -&gt; ZMODEM -&gt; 接收文件夹\n","categories":["Linux"],"tags":["rz","sz"]},{"title":"各种资料汇总","url":"/2023/01/01/material-collect.html","content":"各种网络资料整理汇总，方便查看学习。\n\n\nGoGo 文档相关\nGo语言标准库文档中文版 \nGo by Example | Go by Example 中文版\nGo命令行工具\nGo源码分析\n\nGo 书籍\nGo 语言设计与实现\nGo 程序设计\nGo语言圣经 \nGolang修养之路\nGo语言高级编程\n\nGo 面试\nGOLANG ROADMAP\nGo 程序员面试笔试宝典\n\nBlogs\nGo学习文档 (liuqh.icu)\nGolang源码剖析系列\n\nRedis\nRedis 设计与实现（第一版）\nRedis 设计与实现 （新版 \nRedis内部数据结构详解\nRedis实战 — Redis 实战\nRedis源码 (ditanshow.com)\n\n","categories":["随手记"],"tags":["wiki"]},{"title":"基础架构：一条SQL查询语句是如何执行的？","url":"/2020/04/05/mysql45-01.html","content":"MySQL实战45讲 - 基础架构：一条SQL查询语句是如何执行的？\n\n\nMySQL 的逻辑架构图\n\n\nMySQL 可以分为 Server 层和存储引擎层两部分\nServer 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n不同的存储引擎其实是公用一个Server层的\n连接器连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n$ mysql -h$ip -P$port -u$user -p\n\n输入用户和密码验证通过之后，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接的断开\n建立连接之后，如果长时间没有发生交互，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n# 可以通过这个命令来查看show variables like &#x27;wait_timeout&#x27;;\n\n连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n查询缓存不建议使用查询缓存，在8.0版本中已经去掉了这个功能\n分析器词法分析：识别输入的字符串\n语法分析：判断是否符合mysql的语法规则\n优化器优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器执行之前要先进行权限的判断，通过之后就会根据存储引擎提供的接口来操作数据\n","categories":["MySQL","MySQL实战学习笔记"]},{"title":"Nginx API for Lua","url":"/2020/06/27/nginx-api-for-lua-for.html","content":"记录一下\n\n\n \nngx.argngx.var.VARIABLECore constantsHTTP method constantsHTTP status constantsNginx log level constantsprintngx.ctxngx.location.capturengx.location.capture_multingx.statusngx.header.HEADERngx.resp.get_headersngx.req.is_internalngx.req.start_timengx.req.http_versionngx.req.get_method  \n \nngx.arg\nsyntax: val = ngx.arg[index]context: set_by_lua*, body_filter_by_lua*\n\nlocation /foo &#123;    set $a 32;    set $b 56;    set_by_lua $sum        &#x27;return tonumber(ngx.arg[1]) + tonumber(ngx.arg[2])&#x27;        $a $b;    echo $sum;&#125;\n\ntop↑ \nngx.var.VARIABLE读写Nginx变量值。\n请注意，只能写入已经定义的Nginx变量\n\nsyntax: ngx.var.VAR_NAMEcontext: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*\n\nvalue = ngx.var.some_nginx_variable_namengx.var.some_nginx_variable_name = value\n\n可以为某些特殊的Nginx变量（例如$ args和$ limit_rate）分配一个值，而其他一些则不能，例如$query_string，$arg_PARAMETER和$http_NAME。\n从Nginx变量读取时，Nginx将在每个请求的内存池中分配内存，该内存池仅在请求终止时才释放。 因此，当您需要在Lua代码中重复读取Nginx变量时，请将Nginx变量值缓存到您自己的Lua变量中\n上面的意思就是可能会出现内存溢出的情况，这个时候就需要把变量本地化到lua中，就想下面这样。\nlocal val = ngx.var.some_var--- use the val repeatedly later\n\ntop↑ \nCore constants核心常量\n\ncontext: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*\n\nngx.OK (0)ngx.ERROR (-1)ngx.AGAIN (-2)ngx.DONE (-4)ngx.DECLINED (-5)\n\ntop↑ \nHTTP method constantshttp 方法常量\n这些常量通常在ngx.location.capture和ngx.location.capture_multi方法调用中使用。\n\ncontext: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*\n\nngx.HTTP_GETngx.HTTP_HEADngx.HTTP_PUTngx.HTTP_POSTngx.HTTP_DELETEngx.HTTP_OPTIONS   (added in the v0.5.0rc24 release)ngx.HTTP_MKCOL     (added in the v0.8.2 release)ngx.HTTP_COPY      (added in the v0.8.2 release)ngx.HTTP_MOVE      (added in the v0.8.2 release)ngx.HTTP_PROPFIND  (added in the v0.8.2 release)ngx.HTTP_PROPPATCH (added in the v0.8.2 release)ngx.HTTP_LOCK      (added in the v0.8.2 release)ngx.HTTP_UNLOCK    (added in the v0.8.2 release)ngx.HTTP_PATCH     (added in the v0.8.2 release)ngx.HTTP_TRACE     (added in the v0.8.2 release)\n\ntop↑ \nHTTP status constantshttp 状态常量\n\ncontext: init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*\n\nvalue = ngx.HTTP_CONTINUE (100) (first added in the v0.9.20 release)value = ngx.HTTP_SWITCHING_PROTOCOLS (101) (first added in the v0.9.20 release)value = ngx.HTTP_OK (200)value = ngx.HTTP_CREATED (201)value = ngx.HTTP_ACCEPTED (202) (first added in the v0.9.20 release)value = ngx.HTTP_NO_CONTENT (204) (first added in the v0.9.20 release)value = ngx.HTTP_PARTIAL_CONTENT (206) (first added in the v0.9.20 release)value = ngx.HTTP_SPECIAL_RESPONSE (300)value = ngx.HTTP_MOVED_PERMANENTLY (301)value = ngx.HTTP_MOVED_TEMPORARILY (302)value = ngx.HTTP_SEE_OTHER (303)value = ngx.HTTP_NOT_MODIFIED (304)value = ngx.HTTP_TEMPORARY_REDIRECT (307) (first added in the v0.9.20 release)value = ngx.HTTP_PERMANENT_REDIRECT (308)value = ngx.HTTP_BAD_REQUEST (400)value = ngx.HTTP_UNAUTHORIZED (401)value = ngx.HTTP_PAYMENT_REQUIRED (402) (first added in the v0.9.20 release)value = ngx.HTTP_FORBIDDEN (403)value = ngx.HTTP_NOT_FOUND (404)value = ngx.HTTP_NOT_ALLOWED (405)value = ngx.HTTP_NOT_ACCEPTABLE (406) (first added in the v0.9.20 release)value = ngx.HTTP_REQUEST_TIMEOUT (408) (first added in the v0.9.20 release)value = ngx.HTTP_CONFLICT (409) (first added in the v0.9.20 release)value = ngx.HTTP_GONE (410)value = ngx.HTTP_UPGRADE_REQUIRED (426) (first added in the v0.9.20 release)value = ngx.HTTP_TOO_MANY_REQUESTS (429) (first added in the v0.9.20 release)value = ngx.HTTP_CLOSE (444) (first added in the v0.9.20 release)value = ngx.HTTP_ILLEGAL (451) (first added in the v0.9.20 release)value = ngx.HTTP_INTERNAL_SERVER_ERROR (500)value = ngx.HTTP_METHOD_NOT_IMPLEMENTED (501)value = ngx.HTTP_BAD_GATEWAY (502) (first added in the v0.9.20 release)value = ngx.HTTP_SERVICE_UNAVAILABLE (503)value = ngx.HTTP_GATEWAY_TIMEOUT (504) (first added in the v0.3.1rc38 release)value = ngx.HTTP_VERSION_NOT_SUPPORTED (505) (first added in the v0.9.20 release)value = ngx.HTTP_INSUFFICIENT_STORAGE (507) (first added in the v0.9.20 release)\n\ntop↑ \nNginx log level constantsNginx 错误日志级别\n\ncontext: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*\n\nngx.STDERRngx.EMERGngx.ALERTngx.CRITngx.ERRngx.WARNngx.NOTICEngx.INFOngx.DEBUG\n\ntop↑ \nprint\nsyntax: print(…)context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*\n\n将参数值以ngx.NOTICE日志级别写入Nginx error.log文件。\n这个地方可能会写的失败，因为写入的日志级别必须是NOTICE或者是更低的，这个地方是要注意的\n等价下面的\nngx.log(ngx.NOTICE, ...)\n\n关于日志Nginx内核中的错误消息长度有一个硬编码的2048字节限制。 此限制包括尾随换行符和前置时间戳。 如果消息大小超出此限制，Nginx将相应地截断消息文本。 可以通过编辑Nginx源码中src / core / ngx_log.h文件中的NGX_MAX_ERROR_STR宏定义来手动修改此限制\ntop↑ \nngx.ctx该表可用于存储每个请求的Lua上下文数据，并且其生命周期与当前请求相同（与Nginx变量一样）。\n\ncontext: init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua\n\nngx.ctx.foo在请求的重写，访问和内容阶段持续存在。\nlocation /test &#123;    rewrite_by_lua_block &#123;        ngx.ctx.foo = 76    &#125;    access_by_lua_block &#123;        ngx.ctx.foo = ngx.ctx.foo + 3    &#125;    content_by_lua_block &#123;        ngx.say(ngx.ctx.foo)    &#125;&#125;# 输出 79\n\n每个请求（包括子请求）都有自己的表副本。\nlocation /sub &#123;    content_by_lua_block &#123;        ngx.say(&quot;sub pre: &quot;, ngx.ctx.blah)        ngx.ctx.blah = 32        ngx.say(&quot;sub post: &quot;, ngx.ctx.blah)    &#125;&#125;location /main &#123;    content_by_lua_block &#123;        ngx.ctx.blah = 73        ngx.say(&quot;main pre: &quot;, ngx.ctx.blah)        local res = ngx.location.capture(&quot;/sub&quot;)        ngx.print(res.body)        ngx.say(&quot;main post: &quot;, ngx.ctx.blah)    &#125;&#125; GET /mainmain pre: 73sub pre: nilsub post: 32main post: 73\n\ntop↑ \n* ngx.location.capture\nsyntax: res = ngx.location.capture(uri, options?)context: rewrite_by_lua*, access_by_lua*, content_by_lua*\n\n使用uri发出同步但仍非阻塞的Nginx子请求。\nNginx的子请求可以向配置了磁盘文件目录或其他任何Nginx C模块（例如ngx_proxy，ngx_fastcgi，ngx_memc，ngx_postgres，ngx_drizzle甚至ngx_lua本身等）的其他位置发出无阻塞内部请求。\n子请求仅模仿HTTP接口，但没有额外的HTTP/TCP通信或IPC。一切都在C级别内部有效地进行。\n子请求与HTTP301/302重定向（通过ngx.redirect）和内部重定向（通过ngx.exec）完全不同。\n在启动子请求之前，必须通过调用ngx.req.read_body或将lua_need_request_body配置为on\n此API函数（以及ngx.location.capture_multi）始终在内存中缓冲子请求的整个响应主体。 因此，如果必须处理较大的子请求响应，则应改用cosocket和流处理。\n基本用法\nres = ngx.location.capture(uri)\n返回一个table，包含res.status, res.header, res.body, and res.truncated\nres.status：保留子请求响应的响应状态代码。res.header：包含子请求的所有响应标头，它是一个普通的Lua表。 对于多值响应标头，该值是一个Lua（数组）表，该表按它们出现的顺序保存所有值。res.body：保留子请求的响应正文数据，该数据可能会被截断。 您始终需要检查res.truncated布尔标志，         以查看res.body是否包含截断的数据。此处的数据截断只能由您的子请求中的那些不可恢复的错误引起，例如在响应主体数据流的中间，远程端过早中止连接，或者当您的子请求从中接收响应主体数据时发生读取超时的情况 遥控器。\n\n增加URI查询字符串的请求\nres = ngx.location.capture(&#x27;/foo/bar?a=3&amp;b=4&#x27;)\n\n可选的options支持的选项\nmethod  指定子请求的request方法，该方法仅接受 HTTP status constants （默认值是 ngx.HTTP_GET）\nbody 指定子请求的请求主体（仅支持字符串值）  \nargs  指定子请求的URI查询参数（接受字符串值和Lua table）\nctx  将Lua表指定为子请求的ngx.ctx表。 它可以是当前请求的ngx.ctx表，可以使当前请求和子请求共享完全相同的上下文表。 \nvars 取得一个Lua table，该table保存将子请求中指定的Nginx变量设置为该选项的值的值。\ncopy_all_vars 指定是否将当前请求的所有Nginx变量值复制到子请求中。子请求中对Nginx变量的修改不会影响当前请求。 \nshare_all_vars 指定是否与当前请求共享子请求的所有Nginx变量。子请求中对Nginx变量的修改将影响当前请求。 启用此选项可能会由于不良的副作用而导致难以调试的问题，并且被认为是有害的。仅在完全知道自己在做什么时才启用此选项。\nalways_forward_body 如果设置为true，则如果未指定body选项，则当前（父）请求的请求主体将始终转发到正在创建的子请求。 由ngx.req.read_body（）或lua_need_request_body读取的请求正文将直接转发到子请求，而无需在创建子请求时复制整个请求正文数据（无论请求正文数据是缓存在内存缓冲区还是临时文件中） 。 默认情况下，此选项为false，并且当未指定body选项时，仅当子请求采用PUT或POST请求方法时才转发当前（父）请求的请求正文。\n\nPOST子请求的写法\nres = ngx.location.capture( &#x27;/foo/bar&#x27;, &#123; method = ngx.HTTP_POST, body = &#x27;hello, world&#x27; &#125;)\n\nargs 参数可以增加额外的参数\n// 以下两个请求是等价的 ngx.location.capture(&#x27;/foo?a=1&#x27;,     &#123; args = &#123; b = 3, c = &#x27;:&#x27; &#125; &#125; )  ngx.location.capture(&#x27;/foo?a=1&amp;b=3&amp;c=%3a&#x27;)\n\nshare_all_vars选项控制是否在当前请求及其子请求之间共享Nginx变量。 如果此选项设置为true，则当前请求和关联的子请求将共享相同的Nginx变量范围。 子请求对Nginx变量所做的更改将影响当前请求, 选项的默认值是false。\n使用此选项时应格外小心，因为变量范围共享可能会产生意外的副作用。 通常最好使用args，vars或copy_all_vars选项。\nlocation /other &#123;    set $dog &quot;$dog world&quot;;    echo &quot;$uri dog: $dog&quot;;&#125;location /lua &#123;    set $dog &#x27;hello&#x27;;    content_by_lua_block &#123;        res = ngx.location.capture(&quot;/other&quot;,        &#123; share_all_vars = true &#125;);        ngx.print(res.body)        ngx.say(ngx.var.uri, &quot;: &quot;, ngx.var.dog)    &#125;&#125;# 访问 /lua/other dog: hello world/lua: hello world\n\ncopy_all_vars选项将父请求的Nginx变量的副本提供给子请求。 此类子请求对这些变量所做的更改不会影响父请求或共享父请求变量的任何其他子请求。\nlocation /other &#123;    set $dog &quot;$dog world&quot;;    echo &quot;$uri dog: $dog&quot;;&#125;location /lua &#123;    set $dog &#x27;hello&#x27;;    content_by_lua_block &#123;        res = ngx.location.capture(&quot;/other&quot;,        &#123; copy_all_vars = true &#125;);        ngx.print(res.body)        ngx.say(ngx.var.uri, &quot;: &quot;, ngx.var.dog)    &#125;&#125;# 访问 /lua/other dog: hello world/lua: hello\n\n如果将share_all_vars和copy_all_vars都设置为true，则share_all_vars优先。\n除了上述两个设置之外，还可以使用vars选项为子请求中的变量指定值。 这些变量是检查了变量的共享或复制之后设置的，并提供了一种更有效的方法，即通过将特定值编码为URL参数并将其转义到Nginx配置文件中，将特定值传递给子请求。\nlocation /other &#123;     content_by_lua_block &#123;         ngx.say(&quot;dog = &quot;, ngx.var.dog)         ngx.say(&quot;cat = &quot;, ngx.var.cat)     &#125; &#125;location /lua &#123;    set $dog &#x27;&#x27;;    set $cat &#x27;&#x27;;    content_by_lua_block &#123;        res = ngx.location.capture(&quot;/other&quot;,        &#123; vars = &#123; dog = &quot;hello&quot;, cat = 32 &#125;&#125;);            ngx.print(res.body)    &#125;&#125;# /luadog = hellocat = 32\n\nctx选项可用于指定自定义Lua表，以用作子请求的ngx.ctx表。\nlocation /sub &#123;    content_by_lua_block &#123;        ngx.ctx.foo = &quot;bar&quot;;    &#125;&#125;location /lua &#123;    content_by_lua_block &#123;        local ctx = &#123;&#125;        res = ngx.location.capture(&quot;/sub&quot;, &#123; ctx = ctx &#125;)            ngx.say(ctx.foo);        ngx.say(ngx.ctx.foo);    &#125;&#125;  # /lua bar nil\n\n也可以使用此ctx选项在当前（父）请求和子请求之间共享相同的ngx.ctx表\nlocation /sub &#123;    content_by_lua_block &#123;        ngx.ctx.foo = &quot;bar&quot;;    &#125;&#125;location /lua &#123;    content_by_lua_block &#123;        res = ngx.location.capture(&quot;/sub&quot;, &#123; ctx = ngx.ctx &#125;)        ngx.say(ngx.ctx.foo);    &#125;&#125;# /luabar\n\ntop↑ \nngx.location.capture_multi\nsyntax: res1, res2, … = ngx.location.capture_multi({ {uri, options?}, {uri, options?}, … })context: rewrite_by_lua*, access_by_lua*, content_by_lua*\n\n和ngx.location.capture一样，但支持多个并行运行的子请求\n此函数发出输入表指定的几个并行子请求，并以相同顺序返回其结果。\nres1, res2, res3 = ngx.location.capture_multi&#123;    &#123; &quot;/foo&quot;, &#123; args = &quot;a=3&amp;b=4&quot; &#125; &#125;,    &#123; &quot;/bar&quot; &#125;,    &#123; &quot;/baz&quot;, &#123; method = ngx.HTTP_POST, body = &quot;hello&quot; &#125; &#125;,&#125;if res1.status == ngx.HTTP_OK then    ...endif res2.body == &quot;BLAH&quot; then    ...end\n\n在所有子请求终止之前，该函数不会返回。总等待时间是各个子请求的最长等待时间，而不是总和。\n当事先不知道要发出的子请求数时，Lua表可用于请求和响应\n-- construct the requests tablelocal reqs = &#123;&#125;table.insert(reqs, &#123; &quot;/mysql&quot; &#125;)table.insert(reqs, &#123; &quot;/postgres&quot; &#125;)table.insert(reqs, &#123; &quot;/redis&quot; &#125;)table.insert(reqs, &#123; &quot;/memcached&quot; &#125;)-- issue all the requests at once and wait until they all returnlocal resps = &#123; ngx.location.capture_multi(reqs) &#125;-- loop over the responses tablefor i, resp in ipairs(resps) do    -- process the response table &quot;resp&quot;end\n\ntop↑ \nngx.status\ncontext: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*  \n\n读取和写入当前请求的响应状态。 在发送响应头之前应调用此方法。\nngx.status = ngx.HTTP_CREATEDstatus = ngx.status\n\n发送响应头后设置ngx.status无效，但会在Nginx的错误日志文件中留下一条错误消息：\nattempt to set ngx.status after sending out response headers\n\ntop↑ \nngx.header.HEADER\nsyntax: ngx.header.HEADER = VALUEsyntax: value = ngx.header.HEADERcontext: rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*  \n\n设置，添加或清除要发送的当前请求的HEADER响应标头。默认情况下，标题名称中的下划线（_）将替换为连字符（-）。 可以通过lua_transform_underscores_in_response_headers指令关闭此转换。标头名称不区分大小写。\n-- 相当于 ngx.header[&quot;Content-Type&quot;] = &#x27;text/plain&#x27;ngx.header.content_type = &#x27;text/plain&#x27;;ngx.header[&quot;X-My-Header&quot;] = &#x27;blah blah&#x27;;\n多个值的设置方法\nngx.header[&#x27;Set-Cookie&#x27;] = &#123;&#x27;a=32; path=/&#x27;, &#x27;b=4; path=/&#x27;&#125;\n产生的效果\nSet-Cookie: a=32; path=/Set-Cookie: b=4; path=/\n\n仅接受Lua表（仅表中的最后一个元素将对仅包含单个值的标准标头（如Content-Type）生效）。\nngx.header.content_type = &#123;&#x27;a&#x27;, &#x27;b&#x27;&#125;# 相当于ngx.header.content_type = &#x27;b&#x27;\n\n删除的方式\nngx.header[&quot;X-My-Header&quot;] = nil;ngx.header[&quot;X-My-Header&quot;] = &#123;&#125;;\n\n发送响应标头后设置ngx.header.HEADER（显式使用ngx.send_headers或隐式使用ngx.print等）将记录一条错误消息。读取ngx.header.HEADER将返回名为HEADER的响应标头的值。标题名称中的下划线（_）也将由短划线（-）替换，并且标题名称将不区分大小写地进行匹配。 如果响应头根本不存在，将返回nil。这在header_filter_by_lua *的上下文中特别有用\nlocation /test &#123;    set $footer &#x27;&#x27;;    proxy_pass http://some-backend;    header_filter_by_lua_block &#123;        if ngx.header[&quot;X-My-Header&quot;] == &quot;blah&quot; then            ngx.var.footer = &quot;some value&quot;        end    &#125;    echo_after_body $footer;&#125;\n\n请注意，ngx.header不是普通的Lua表，因此，无法使用Lua ipairs函数对其进行迭代。\n注意：如果HEADER或VALUE包含不安全的字符（控制字符），则此函数将引发Lua错误。\n要读取请求标头，请改用ngx.req.get_headers函数。\ntop↑ \nngx.resp.get_headers\nsyntax: headers, err = ngx.resp.get_headers(max_headers?, raw?)context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*  \n\n返回一个Lua表，其中包含当前请求的所有当前响应头。\nlocal h, err = ngx.resp.get_headers()if err == &quot;truncated&quot; then    -- one can choose to ignore or reject the current response hereendfor k, v in pairs(h) do    ...end\n\n函数与ngx.req.get_headers具有相同的签名，除了获取响应标头而不是请求标头。\n请注意，默认情况下最多解析100个响应标头（包括具有相同名称的响应标头），并且静默丢弃其他响应标头，以防止潜在的拒绝服务攻击。 从v0.10.13开始，超过限制时，它将返回第二个值，即字符串”truncated”。\ntop↑ \nngx.req.is_internal\nsyntax: is_internal = ngx.req.is_internal()context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*  \n\n返回一个布尔值，指示当前请求是否为“内部请求”，即从当前Nginx服务器内部而不是客户端发起的请求。\n子请求都是内部请求，内部重定向之后的请求也是如此。\ntop↑ \nngx.req.start_time\nsyntax: secs = ngx.req.start_time()context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*  \n\n时间戳\nlocal request_time = ngx.now() - ngx.req.start_time()\n\ntop↑ \nngx.req.http_version\nsyntax: num = ngx.req.http_version()context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*  \n\n以Lua编号的形式返回当前请求的HTTP版本号。当前可能的值为2.0、1.0、1.1和0.9。 对于无法识别的值，返回nil。\nngx.req.raw_header\nsyntax: str = ngx.req.raw_header(no_request_line?)context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*  \n\n返回Nginx服务器收到的原始原始HTTP协议标头。默认情况下，还将包括请求行和尾随CR LF终结符。例如，\nngx.print(ngx.req.raw_header()) GET /t HTTP/1.1Host: localhostConnection: closeFoo: bar\n\n您可以将可选的no_request_line参数指定为true值，以将请求行从结果中排除\nngx.print(ngx.req.raw_header(true))Host: localhostConnection: closeFoo: bar\n\ntop↑ \nngx.req.get_method\nsyntax: method_name = ngx.req.get_method()context: set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, balancer_by_lua*, log_by_lua*  \n\n检索当前请求的请求方法名称。 返回诸如“ GET”和“ POST”之类的字符串，而不是数字方法常量。如果当前请求是Nginx子请求，则将返回子请求的方法名称。\n","categories":["Lua"],"tags":["openrety","Lua","nginx"]},{"title":"Nginx基本配置文件","url":"/2019/03/25/nginx-basic-conf.html","content":"\n\n基本的配置文件注释\n\n\n#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes  1;#全局错误日志及PID文件#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;#工作模式及连接数上限events &#123;    #epoll是多路复用IO(I/O Multiplexing)中的一种方式,    #仅用于linux2.6以上内核,可以大大提高nginx的性能    use   epoll;     #单个后台worker process进程的最大并发链接数        worker_connections  1024;    # 并发总数是 worker_processes 和 worker_connections 的乘积    # 即 max_clients = worker_processes * worker_connections    # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么    # 为什么上面反向代理要除以4，应该说是一个经验值    # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000    # worker_connections 值的设置跟物理内存大小有关    # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数    # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右    # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：    # $ cat /proc/sys/fs/file-max    # 输出 34336    # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内    # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置    # 使得并发总数小于操作系统可以打开的最大文件数目    # 其实质也就是根据主机的物理CPU和内存进行配置    # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。    # ulimit -SHn 65535&#125;http &#123;    #设定mime类型,类型由mime.type文件定义    include    mime.types;    default_type  application/octet-stream;    #设定日志格式    log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    access_log  logs/access.log  main;    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，    #对于普通应用，必须设为 on,    #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，    #以平衡磁盘与网络I/O处理速度，降低系统的uptime.    sendfile     on;    #tcp_nopush     on;    #连接超时时间    #keepalive_timeout  0;    keepalive_timeout  65;    tcp_nodelay     on;    #开启gzip压缩    gzip  on;    gzip_disable &quot;MSIE [1-6].&quot;;    #设定请求缓冲    client_header_buffer_size    128k;    large_client_header_buffers  4 128k;    #设定虚拟主机配置    server &#123;        #侦听80端口        listen    80;        #定义使用 www.nginx.cn访问        server_name  www.nginx.cn;        #定义服务器的默认网站根目录位置        root html;        #设定本虚拟主机的访问日志        access_log  logs/nginx.access.log  main;        #默认请求        location / &#123;                        #定义首页索引文件的名称            index index.php index.html index.htm;           &#125;        # 定义错误提示页面        error_page   500 502 503 504 /50x.html;        location = /50x.html &#123;        &#125;        #静态文件，nginx自己处理        location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;                        #过期30天，静态文件不怎么更新，过期可以设大一点，            #如果频繁更新，则可以设置得小一点。            expires 30d;        &#125;        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.        location ~ \\.php$ &#123;            fastcgi_pass 127.0.0.1:9000;            fastcgi_index index.php;            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;            include fastcgi_params;        &#125;        #禁止访问 .htxxx 文件            location ~ /.ht &#123;            deny all;        &#125;    &#125;&#125;\n\n","categories":["Linux"],"tags":["nginx"]},{"title":"php.ini 配置选项设定范围","url":"/2020/03/10/php-ini-set-range.html","content":"记录一个同事给挖的坑~php中的ini_set函数可以为一个配置选项设置值，但是并不是所有的配置都可以在代码中使用该函数设置\n\n\n事情的起因是需要修改一下上传文件最大的限制，从8M修改为20M，因为同事写的代码没有测试就去做别的项目并且代码已经提交到git，所以在我接手的时候就以为是可以使用的，看到他在代码中写了类似下面的代码\n&lt;?phpini_set(&quot;post_max_size&quot;, &quot;20M&quot;);ini_set(&quot;upload_max_filesize&quot;, &quot;20M&quot;);class UploadClass&#123;\t// ...&#125;\n折腾就是死活不生效，nginx的client_max_body_size配置也修改了，容器也销毁重建了…..,最后仔细一想就是下面的限制.\n配置可被设定范围\n一个配置选项是否可以在ini_set中进行设置，主要是取决于该设置是什么模式，手册中的每个指令都有其所属的模式。\n\n\n\n模式\n含义\n\n\n\nPHP_INI_USER\n可在用户脚本以及 .user.ini 中设定\n\n\nPHP_INI_PERDIR\n可在 php.ini，.htaccess 或 httpd.conf 中设定\n\n\nPHP_INI_SYSTEM\n可在 php.ini 或 httpd.conf 中设定\n\n\nPHP_INI_ALL\n可在任何地方设定\n\n\n上面两个配置的模式是PHP_INI_PERDIR，所以必须在php.ini中修改才是会生效的\n\n\n\n名字\n默认\n可修改范围\n\n\n\nupload_max_filesize\n“2M”\nPHP_INI_PERDIR\n\n\npost_max_size\n“8M”\nPHP_INI_PERDIR\n\n\nPHP: php.ini 配置选项列表 - Manual\n","categories":["PHP"],"tags":["配置"]},{"title":"PHP面试题整理","url":"/2018/03/11/php-exam-list.html","content":"常见的面试题整理，来源是各个地方…\n\n\n基础篇1. 表单提交中的Get和Post的异同点语义不同：get请求一般情况多用于请求数据，post请求一般多用于新增或者修改数据传输大小限制：get传参是在url上，有大小限制，post请求是在请求体中没有大小限制安全性:post安全性相对高一下\n\n2. 用PHP写出显示客户端IP与服务器IP的代码// 使用超全局变量$_SERVER$_SERVER[&#x27;REMOTE_ADDR&#x27;]\t// 客户端$_SERVER[&#x27;SERVER_ADDR&#x27;]\t// 服务器IP\n\n3. include和require的区别是什么?两个函数都是包含引入的文件include在引入不存在的文件时，产生一个警告且脚本还会继续执行require则会导致一个致命性错误且脚本停止执行\n\n4. PHP 不使用第三个变量实现交换两个变量的值$a = 1;$b = 2;list($a, $b) = [$b, $a];\n\n5. 取文件的扩展名function getExt1($fileName)&#123;    $ext = &quot;&quot;;    if (empty($fileName)) return $ext;    return pathinfo($fileName, PATHINFO_EXTENSION);&#125;function getExt2($fileName)&#123;    $ext = &quot;&quot;;    $pathArr = explode(&quot;.&quot;, $fileName);    if (count($pathArr) == 1) return $ext;    return end($pathArr);&#125;function getExt3($fileName)&#123;    return substr(strrchr($fileName, &#x27;.&#x27;), 1);&#125;\n\n6. 用PHP header()函数实现页面404错误提示功能Header(&quot;HTTP/1.1 404 Not Found&quot;);\n\n7. 约瑟夫环  n 只猴子,数m踢出一只，最后的就是大王function king($n, $m)&#123;    $monkey = range(1, $n);    $i = 0;    while (count($monkey) &gt; 1) &#123;        $i++;        $head = array_shift($monkey);        if ($i % $m != 0) &#123;            array_push($monkey, $head);        &#125;    &#125;    return current($monkey);&#125;\n\n8. 文件加锁写入// w+ : 读写方式打开// LOCK_EX 写锁，LOCK_SH 读锁// 文件加锁$file = fopen(&#x27;test.log&#x27;, &#x27;w+&#x27;);if (flock($file, LOCK_EX)) &#123;    fwrite($file, &#x27;test content&#x27;);    flock($file, LOCK_UN);&#125; else &#123;    // 文件已经被锁定&#125;fclose($file);\n\n9. 遍历文件夹function myDir($path)&#123;    $files = [];    if (is_dir($path)) &#123;        if ($handle = opendir($path) ) &#123;            while (($file = readdir($handle)) !== false) &#123;                if ($file != &#x27;.&#x27; &amp;&amp; $file != &#x27;..&#x27;) &#123;                    if (is_dir($path . &#x27;/&#x27; . $file)) &#123;                        $files[$file] = myDir($path . &#x27;/&#x27; . $file);                    &#125; else &#123;                        $files[] = $path . &#x27;/&#x27; . $file;                    &#125;                &#125;            &#125;        &#125;    &#125;    return $files;&#125;\n\n10. 单例模式class DB&#123;    private static $db = null;    private function __construct()&#123;        // 连接数据库    &#125;    private function __clone()&#123;&#125;    public function getDb()    &#123;        if (!self::db instanceof self) &#123;            self::db = new self();        &#125;        return self::db;    &#125;&#125;\n\n","categories":["面试题","PHP"],"tags":["面试"]},{"title":"PHP常见排序算法","url":"/2018/01/12/php-sort.html","content":"面试PHP过程中遇到的频率比较高的排序算法\n\n\n冒泡排序$arr = array(1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39);// 冒泡排序function bubble($arr)&#123;    // 控制比较的轮数    for ($i = 1, $len = count($arr); $i &lt; $len; $i++) &#123;        // 比较的元素        for ($j = 0; $j &lt; $len - $i; $j++) &#123;            if ($arr[$j] &gt; $arr[$j + 1]) &#123;                list($arr[$j], $arr[$j + 1]) = array($arr[$j + 1], $arr[$j]);            &#125;        &#125;    &#125;    return $arr;&#125;print_r(bubble($arr));// 冒泡排序(加强一点点)function bubble($arr, $sort = &#x27;asc&#x27;)&#123;    $sort = strtolower($sort);    if (!in_array($sort, array(&#x27;asc&#x27;, &#x27;desc&#x27;)))        $sort = &#x27;asc&#x27;;    // 控制比较的轮数    for ($i = 1, $len = count($arr); $i &lt; $len; $i++) &#123;        // 比较的元素        for ($j = 0; $j &lt; $len - $i; $j++) &#123;            if ($sort == &#x27;desc&#x27;) &#123;                if ($arr[$j] &lt; $arr[$j + 1]) &#123;                    list($arr[$j], $arr[$j + 1]) = array($arr[$j + 1], $arr[$j]);                &#125;            &#125; else &#123;                if ($arr[$j] &gt; $arr[$j + 1]) &#123;                    list($arr[$j], $arr[$j + 1]) = array($arr[$j + 1], $arr[$j]);                &#125;            &#125;        &#125;    &#125;    return $arr;&#125;\n\n快速排序$arr = array(1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39);// 快速排序function fastSort($arr)&#123;    $len = count($arr);    if ($len &lt;= 1) return $arr;    $left = $right = array();    $offset = current($arr);    for ($i = 1; $i &lt; $len; $i++) &#123;        if ($arr[$i] &gt; $offset) &#123;            $right[] = $arr[$i];        &#125; else &#123;            $left[] = $arr[$i];        &#125;    &#125;    $left = fastSort($left);    $right = fastSort($right);    return array_merge($left, array($offset), $right);&#125;print_r(fastSort($arr));\n\n","categories":["面试题","PHP"],"tags":["面试","算法","排序"]},{"title":"Redis 主从同步（复制）","url":"/2023/02/12/redis-master-slave.html","content":"Redis 的持久化功能保证了即使在服务器重启的情况下也不会损失（或少量损失）数据。但是单机出现故障还是会出现数据丢失。Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。\n\n\nRedis 的主从架构中，可以是一主一从，也可以是一主多从，也就是一个master可以有多个slave，也就相当于有了多份的数据副本。在redis主从架构中，Master节点负责处理写请求，Slave节点只处理读请求，除了主从同步，redis也可以从从同步。\n\n\n同步的原理和步骤主从同步主要是通过 RDB 文件和主库维护的一个积压队列来实现的。\n第一次同步的时候，或者是直接输入命令的时候都会进行同步。\n当客户端向服务器发送SLAVEO命令（新版的是replicaof），要求从服务器复制主服务器时，从服务器首先需要执行同步操作。\n从服务器对主服务器的同步操作主要是通过SYNC命令来完成，下面是步骤\n\n从服务器向主服务器发送sync命令\n主服务器收到sync命令之后，执行bgsave命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令\n主服务器执行完毕bgsave之后，把生成的rdb文件发送给从服务器，从服务器载入rdb文件同步数据\n主服务器将记录在缓存区中的所有写命令发送给从服务器，从服务器执行这些写命令，更新到现在主库的状态\n\n全量同步在2.8版本之前，Redis 只支持全量同步。\n初次同步的时候，首先需要在主节点上进行一次 bgsave 将当前内存的数据全部快照到RDB文件中，然后再将快照文件的内容全部传送到从节点。从节点将RDB文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完毕后通知主节点继续进行增量同步。\nMaster 和 Slave 网络发生了抖动，那一段时间内这些数据就会丢失，对于 Slave 来说这段时间 Master 更新的数据是不知道的。最简单的方式就是再做一次全量复制，从而获取到最新的数据，在redis2.8之前是这么做的。\n全量复制的开销1.bgsave的开销，每次bgsave需要fork子进程，对内存和CPU的开销很大\n2.RDB文件网络传输的时间（网络带宽）\n3.从节点清空数据的时间\n4.从节点加载RDB的时间\n5.可能的AOF重写时间（如果我们的从节点开启了AOF，则加载完RDB后会对AOF进行一个重写，保证AOF是最新的）\n增量同步Master 节点会将写命令记录在本地的内存 buffer（复制缓冲区） 中，然后异步发送给 Slave 节点，Slave 节点一边执行同步的指令流来达到和主节点一样的状态，一边向主节点反馈自己偏移量。内存的 buffer 是有限的，只能记录一部分内容，如果 buffer 内容满了，就会从头开始覆盖前面的内容。\n主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果偏移量之后的数据仍然存在于复制积压缓存区里面，主服务器将对从服务器执行部分同步操作，如果网络中断时间过长，造成主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制\n","categories":["Redis"],"tags":["replication"]},{"title":"Redis 数据持久化","url":"/2023/02/11/redis-rdb.html","content":"Redis 以数据结构的形式将数据维持在内存中， 为了让这些数据在 Redis 重启之后仍然可用， Redis 分别提供了 RDB 和 AOF 两种持久化模式。\n\n\nRDB 方式RDB 持久化方式也叫“快照”方式，当符合一定条件时 Redis 会自动将内存中的所有数据生成一份副本并存储在硬盘上。\nRDB 功能最核心的是 rdbSave 和 rdbLoad 两个函数，前者用于生成 RDB 文件到磁盘，而后者则用于将 RDB 文件中的数据重新载入到内存中\n进行快照的时机\n根据配置规则进行自动快照\n用户执行 SAVE或 BGSAVE命令\n执行 FLUSHALL命令\n执行复制（replication）时\n\nRDB文件的创建与载入创建：\nrdbSave 用于生成RDB文件， SAVE 和 BGSAVE 两个命令都会调用 rdbSave 函数，但它们调用的方式各有不同\n\nsave 命令在执行的时候会阻塞redis的服务器进程，直到RDB文件创建完毕为止。在执行命令的期间服务器不能处理任何命令请求。\nbgsave 命令执行的时候会派生出一个子进程，然后由子进程负责创建RDB文件，父进程继续处理命令请求。\n\n载入：\nrdbLoad函数用于读取 RDB 文件，当 Redis 服务器启动时， rdbLoad 函数就会被执行， 它读取 RDB 文件， 并将文件中的数据库数据载入到内存中。因为 AOF 文件的保存频率通常要高于 RDB 文件保存的频率，所以一般来说， AOF 文件中的数据会比 RDB 文件中的数据要新，因此服务器在启动时， 打开了 AOF 功能， 那么程序优先使用 AOF 文件来还原数据\nRDB 相关的配置################################ SNAPSHOTTING  ################################# 900s内有大于等于1个key修改过就进行快照save 900 1save 300 10save 60 10000# rdb 文件的名称dbfilename dump.rdb# 保存rdb文件的位置dir ./\n\n快照的过程\nRedis使用fork函数复制一份当前进程（父进程）的副本（子进程）\n父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件\n当子进程写入完所有数据后会用该临时文件替换旧的 RDB 文件，至此一次快照操作完成\n\nAOF 方式AOF 以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。\nAOF文件的写入与同步当AOF持久化功能处于打开的时候，服务器在执行完一个写命令之后，会以协议格式的格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。\n# 同步时机# appendfsync always # 每次执行写入都会执行同步appendfsync everysec  # 每秒执行一次同步操作# appendfsync no # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次）\n\nAOF 相关的配置############################## APPEND ONLY MODE ################################ 是否开启AOF， yes | noappendonly no# AOF文件名字appendfilename &quot;appendonly.aof&quot;# 保存的位置也是通过 dir 来设置的，和RDB使用的一样# 同步时机# appendfsync always # 每次执行写入都会执行同步appendfsync everysec  # 每秒执行一次同步操作# appendfsync no # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次）# 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写auto-aof-rewrite-percentage 100# 限制了允许重写的最小AOF文件大小auto-aof-rewrite-min-size 64mb\n\n","categories":["Redis"],"tags":["RDB","AOF"]},{"title":"Redis 数据结构（一）字符串","url":"/2023/02/10/redis-sds.html","content":"SDS 是在 Redis 中被广泛使用的字符串结构，它的全称是 Simple Dynamic String。\n\n\n\n内容来只《Redis设计与实现》和其他网络资料，Redis3.0源码-注释版\n\nSDS的定义redis-3.0-annotated/src/sds.h\ntypedef char *sds;struct sdshdr &#123;    // buf 中已占用空间的长度    int len;    // buf 中剩余可用空间的长度    int free;    // 数据空间    char buf[];&#125;;\n\nSDS与C字符串的区别C 语言使用长度为 N+1 的字符数组来表示长度为 N 的字符串， 并且字符数组的最后一个元素总是空字符 &#39;\\0&#39;，C 语言使用的这种简单的字符串表示方式， 并不能满足 Redis 对字符串在安全性、效率、以及功能方面的要求\n常数复杂度获取字符串长度C 字符串并不记录自身的长度信息， 所以为了获取一个 C 字符串的长度， 程序必须遍历整个字符串， 对遇到的每个字符进行计数， 直到遇到代表字符串结尾的空字符为止。\nSDS 在 len 属性中记录了 SDS 本身的长度， 所以获取一个 SDS 长度的复杂度仅为 O(1) \n杜绝缓冲区溢出C 字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出（buffer overflow）。\n修改两个相邻的字符串的时候，需要修改前一个没有重新分配内存就有可能覆盖后一个字符串的内容。\nSDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小， 也不会出现前面所说的缓冲区溢出问题。\n减少修改字符串时带来的内存重分配次数C 字符串底层是一个字符数组，每次增长或者缩短一个 C 字符串， 程序都总要对保存这个 C 字符串的数组进行一次内存重分配操作，无论是增加、拼接、截取都得先通过内存重分配来扩展底层数组的空间大小，否则就可能造成溢出的情况\nSDS空间预分配内存重分配涉及复杂的算法，并且可能需要执行系统调用是一个比较耗时的操作。SDS通过空间预分配的方式来减少系统调用从而加快执行的速度。\n当 SDS 的 API 对一个 SDS 进行修改， 并且需要对 SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间\n额外分配的未使用空间数量由以下公式决定\n\n如果对SDS进行修改之后，SDS的长度（也即是 len 属性的值）将小于1 MB，那么程序分配和 len 属性同样大小的未使用空间，这时SDS的len属性的值将和 free 属性的值相同。举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配 13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）\n如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。\n\n惰性空间释放惰性空间释放用于优化SDS的字符串缩短操作： 当SDS的API需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。\nSDS是二进制安全的C字符串中的字符必须符合某种编码（比如 ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。\nSDS使用 len 属性的值而不是空字符来判断字符串是否结束，因此SDS的API都是二进制安全的（binary-safe）。\n","categories":["Redis"],"tags":["string","redis","SDS"]},{"title":"RocketMQ 入门","url":"/2023/01/04/rockermq-basic.html","content":"RocketMQ 是一款纯java、分布式、队列模型的开源消息中间件，支持事务消息、顺序消息、批量消息、定时消息、消息回溯等。\n\n\n官方文档：\nhttps://github.com/apache/rocketmqhttps://rocketmq.apache.org/zh/\n基本概念主题（Topic）主题（Topic）可以看做消息的归类，表示一类消息的集合，它是消息的第一级类型，用于标识同一类业务逻辑的消息。每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。\n主题内部由多个队列组成，消息的存储和水平扩展能力最终是由队列实现的；并且针对主题的所有约束和属性设置，最终也是通过主题内部的队列来实现。\n\n消息标签（MessageTag）消息标签主要用于同一主题下区分不同类型的消息，如果把 Topic 比作一级分类，那 tag 就是二级分类。\nTopic: 货物\ttag=上海\ttag=北京\ttag=天津# 消费者可以根据Tag实现对不同子主题的不同消费逻辑1. topic=货物 tag=上海2. topic=货物 tag=上海|北京\n\n队列（MessageQueue）队列是 RocketMQ 存储消息的物理实体，一个 Topic 中可以包含多个 Queue，每个 Queue 中存放的就是该Topic的消息。一个 Topic 的 Queue 也被称为一个 Topic中 消息的分区（Partition）。\n一个Topic的Queue中的消息只能被一个消费者组中的一个消费者消费。一个Queue中的消息不允许同一个消费者组中的多个消费者同时消费。\n\n消息标识（MessageId/Key）RocketMQ 中每个消息拥有唯一的 MessageId，且可以携带具有业务标识的 Key，以方便对消息的查询。不过需要注意的是，MessageId 有两个：在生产者发送消息时会自动生成一个 MessageId（msgId)，当消息到达 Broker 后，Broker 也会自动生成一个 MessageId(offsetMsgId)。msgId、offsetMsgId 与 key 都称为消息标识。 msgId ：由producer端生成，其生成规则为：producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode +当前时间 + AutomicInteger自增计数器offsetMsgId：由broker端生成，其生成规则为：brokerIp + 物理分区的offset（Queue中的偏移量）key：由用户指定的业务相关的唯一标识\nRocketMQ 核心概念\nName ServerNameServer 是 RocketMQ Broker与Topic路由的注册中心，支持Broker的动态注册与发现。在启动服务的时候，NameServer 需要先于 Broker 启动，每个 Broker 在启动的时候会到 NameServer 注册。每个 NameServer 中都保存着 Broker 集群的整个路由信息和用于客户端查询的队列信息。Producer 和 Conumser 通过 NameServer可 以获取整个 Broker 集群的路由信息，从而进行消息的投递和消费。\n路由注册NameServer 被设计成几乎无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。在 Broker 节点启动时，轮询NameServer 列表，与每个 NameServer 节点建立长连接，发起注册请求。在 NameServer 内部维护着一个 Broker 列表，用来动态存储 Broker 的信息。\n\n优点：NameServer集群搭建简单，扩容简单。缺点：对于Broker，必须明确指出所有 NameServer 地址。否则未指出的将不会去注册。也正因为如此，NameServer 并不能随便扩容。因为，若Broker不重新配置，新增的NameServer对于Broker来说是不可见的，其不会向这个NameServer进行注册。Broker 每30s会发送一次心跳包给 NameServer，心跳包中包含BrokerId、Broker地址(IP+Port)、Broker名称、Broker所属集群名称等。NameServer在接收到心跳包后，会更新心跳时间戳，记录这个Broker的最新存活时间。\n\n路由剔除如果发生网络阻塞或者 Broker关机等情况，NameServer没有收到Broker的心跳，NameServer可能会将其从Broker列表中剔除。NameServer 的定时任务每隔10s会扫描一次 Broker 表，查看每一个Broker的最新心跳时间戳距离当前时间是否超过 120 秒，如果超过，则会判定Broker失效，然后将其从Broker列表中剔除。\n\nBroker升级，需要停掉Broker的工作，需要怎么做？\n\n将Broker的读写权限禁掉。一旦client(Consumer或Producer)向broker发送请求，都会收到broker的NO_PERMISSION响应，然后client会进行对其它Broker的重试。\nBroker没有流量后，再关闭它，实现Broker从NameServer的移除。\n\n\n路由发现路由发现采用的是Pull模型。当Topic路由信息出现变化时，NameServer不会主动推送给客户端，而是客户端定时拉取主题最新的路由。默认客户端每 30 秒会拉取一次最新的路由。\nNameServer选择策略（Producer与Consumer）会生产一个随机数，然后再与NameServer节点数量取模，此时得到的就是所要连接的节点索引，然后就会进行连接。如果连接失败，则会采用round-robin（轮询）策略，逐个尝试着去连接其它节点。\nBrokerBroker 是消息存储中心，主要负责存储消息、转发消息。存储与消息相关的元数据，包括用户组、消费进度偏移量、队列信息等。Broker 分为 Master 与 Slave 两种，从物理结构上看 Broker 的集群部署方式有四种：单 Master 、多 Master 、多 Master 多 Slave（同步刷盘）、多 Master多 Slave（异步刷盘）。\nBroker的组成1. Client Manager：客户端管理器。负责接收、解析客户端(Producer/Consumer)请求，管理客户端。例如，维护Consumer的Topic订阅信息2. Store Service：存储服务。提供方便简单的API接口，处理消息存储到物理硬盘和消息查询功能。3. HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。4. Index Service：索引服务。根据特定的Message key，对投递到Broker的消息进行索引服务，同时也提供根据Message Key对消息进行快速查询的功能。\nBroker的集群部署Broker一般都是以集群形式出现的，各个节点存放着相同Topic的不同Queue。可以通过将集群每个Broker集群节点进行横向扩展，即将Broker节点再建为一个HA集群，解决单点问题。\nMaster负责处理读写操作请求，Slave负责对Master中的数据进行备份。当Master挂掉了，Slave则会自动切换为Master去工作。一个Master可以包含多个Slave，但一个Slave只能隶属于一个Master。Master与Slave 的对应关系是通过指定相同的BrokerName、不同的BrokerId 来确定的。BrokerId为 0 表示Master，非 0 表示Slave。\nBroker集群模式\n\n单Master只有一个broker（其本质上就不能称为集群）。这种方式也只能是在测试时使用，生产环境下不能使用，因为存在单点问题。\n多Masterbroker集群仅由多个master构成，不存在Slave。同一Topic的各个Queue会平均分布在各个master节点上。\n优点：配置简单，单个Master宕机或重启维护对应用无影响缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅（不可消费），消息实时性会受到影响。\n\n\n多Master多Slave模式-异步复制\n\nbroker集群由多个master构成，每个master又配置了多个slave,master与slave的关系是主备关系，即master负责处理消息的读写请求，而slave仅负责消息的备份与master宕机后的角色切换。\n\n该模式的最大特点之一是，当master宕机后slave能够自动切换为master。不过由于slave从master的同步具有短暂的延迟（毫秒级），所以当master宕机后，这种异步复制方式可能会存在少量消息的丢失问题。\n\n\n多Master多Slave模式-同步双写该模式是多Master多Slave模式的同步复制实现。所谓同步双写，指的是消息写入master成功后，master会等待slave同步数据成功后才向producer返回成功ACK，即master与slave都要写入成功后才会返回成功ACK，也即双写。该模式与异步复制模式相比，优点是消息的安全性更高，不存在消息丢失的情况。但单个消息的RT略高，从而导致性能要略低（大约低10%）。\n\n该模式存在一个大的问题：对于目前的版本，Master宕机后，Slave不会自动切换到Master。复制策略复制策略是Broker的Master与Slave间的数据同步方式。分为同步复制与异步复制：\n\n同步复制：消息写入master后，master会等待slave同步数据成功后才向producer返回成功ACK\n异步复制：消息写入master后，master立即向producer返回成功ACK，无需等待slave同步数据成功\n\n刷盘策略刷盘策略指的是broker中消息的落盘方式，即消息发送到broker内存后消息持久化到磁盘的方式。分为同步刷盘与异步刷盘。\n\n同步刷盘：当消息持久化到broker的磁盘后才算是消息写入成功。\n异步刷盘：当消息写入到broker的内存后即表示消息写入成功，无需等待消息持久化到磁盘。\n\n生产者（Producer）消息发布者，负责生产并发送消息至 Topic。RocketMQ 支持同步发送、异步发送、单向发送。\n消费者（Consumer）消息订阅者，负责从 Topic 接收并消费消息。消费者从brokers那里拉取信息并将其输入应用程序。\n两种类型的消费者：\n\nPull：Pull型消费者主动地从brokers那里拉取信息。只要批量拉取到消息，用户应用程序就会启动消费过程\nPush：Push型消费者封装消息的拉取、消费进度和维护内部的其他工作，将一个在消息到达时执行的回调接口留给终端用户来实现。\n\n工作流程\n启动NameServer，NameServer启动后开始监听端口，等待Broker、Producer、Consumer连接。\n启动Broker时，Broker会与所有的NameServer建立并保持长连接，然后每 30 秒向NameServer定时发送心跳包。\n发送消息前，可以先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，当然，在创建Topic时也会将Topic与Broker的关系写入到NameServer中。不过，这步是可选的，也可以在发送消息时自动创建Topic。\nProducer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取路由信息，即当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系。然后根据算法策略从队选择一个Queue，与队列所在的Broker建立长连接从而向Broker发消息。当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每 30 秒从NameServer更新一次路由信息。\nConsumer跟Producer类似，跟其中一台NameServer建立长连接，获取其所订阅Topic的路由信息，然后根据算法策略从路由信息中获取到其所要消费的Queue，然后直接跟Broker建立长连接，开始消费其中的消息。Consumer在获取到路由信息后，同样也会每 30 秒从NameServer更新一次路由信息。不过不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态。\n\n","categories":["RocketMQ"]},{"title":"RocketMQ 消费消息","url":"/2023/01/10/rocketmq-consumer.html","content":"从 Broker 获取消息的方式有两种，pull 拉取方式和 push 推动方式。消费者组对于消费的模式又分为两种，广播消费（ Broadcasting ）和集群消费（ Clustering ）\n\n\nRoketMQ 中所说的“消费”可以为两个步骤：\n\nConsumer 从 Broker 拉取消息到本地，并保存到本地的消息缓存队列( ProcessQueue )。这个步骤中，消费的主体是 RocketMQ 的 Consumer 模块。\nConsumer 从本地的消息缓存队列取出消息，并调用上层应用程序指定的回调函数对消息进行处理。这个步骤中，消费的主体是上层应用程序。\n\n消费类型拉取式消费（pull）Consumer 主动从 Broker 中拉取消息，主动权由 Consumer 控制。一旦获取了批量消息，就会启动消费过程。不过，该方式的实时性较弱，即Broker中有了新的消息时消费者并不能及时发现并消费。\n\n因为是由客户端发起请求，所以不存在数据积压的问题。缺点是可能不够及时，对客户端来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。\n\n推送式消费（push）这个是典型的发布-订阅模式，Consumer 向其关联的 Queue 注册了监听器，一旦发现有新的消息到来就会触发回调的执行，回调方法是 Consumer 去 Queue 中拉取消息。而这些都是基于 Consumer 与 Broker 间的长连接的\n优点有消息就推给消费者。延迟小,几乎可以做到实时\n缺点\n\n加大Server端的工作量，进而影响Server的性能，\nClient的处理能力各不相同，Client的状态不受Server控制，如果Client不能及时处理Server推送过来的消息，会造成各种潜在问题（比如消息堆积）。\n有的消费者机器配置好处理能力强,有的配置低处理能力低,但是server推相同数量级消息给消费者，就会导致消费者强的等待,弱的处理效率跟不上,从而导致崩溃。\nserver资源相比消费者的资源肯定是更宝贵\n总结下就是客户端慢消费(设计到io等耗时操作)时会放大缺点。\n\n消费模式广播消费（Broadcasting）相同 Consumer Group 的每个 Consumer 实例都接收同一个 Topic 的全量消息。即每条消息都会被发送到 Consumer Group 中的每个 Consumer。\n\n可以理解为同组各自消费。即同一 Topic 下，同一消息会被多个实例各自都消费一次，消息队列 RocketMQ 会将每条消息推送给集群内所有注册过的客户端，保证消息至少被每台机器消费一次。广播消费模式中的 ConsumerGroup 概念没有太大的意义。这适用于一些分发消息的场景。\n\n适用场景&amp;注意事项\n\n广播消费模式下不支持顺序消息。\n广播消费模式下不支持重置消费位点。\n每条消息都需要被相同逻辑的多台机器处理。\n消费进度在客户端维护，出现重复的概率稍大于集群模式。\nRocketMQ 保证每条消息至少被每台客户端消费一次，但是并不会对消费失败的消息进行失败重投，因此业务方需要关注消费失败的情况。\n客户端每一次重启都会从最新消息消费。客户端在被停止期间发送至服务端的消息将会被自动跳过\n\n集群消费（Clustering）相同Consumer Group 的每个 Consumer 实例平均分摊同一个Topic的消息。即每条消息只会被发送到Consumer Group中的某个 Consumer。\n\n可以理解成同组公共消费，公共资源我拿了你就没有。即同一 Topic 下，一个 ConsumerGroup 下如果有多个实例，那么这些实例会均摊消费这些消息\n\n适用场景&amp;注意事项\n\n消费端集群化部署， 每条消息只需要被处理一次。\n由于消费进度在服务端维护， 可靠性更高。\n集群消费模式下，每一条消息都只会被分发到一台机器上处理。如果需要被集群下的每一台机器都处理，请使用广播模式。\n集群消费模式下，不保证每一次失败重投的消息路由到同一台机器上，因此处理消息时不应该做任何确定性假设。\n\n消费进度保存广播模式：消费进度保存在 consumer 端。因为广播模式下 consumer group 中每个 consumer 都会消费所有消息，但它们的消费进度是不同。所以consumer 各自保存各自的消费进度。集群模式：消费进度保存在broker中。consumer group中的所有consumer共同消费同一个Topic中的消息，同一条消息只会被消费一次。消费进度会参与到了消费的负载均衡中，故消费进度是需要共享的。下图是broker中存放的各个Topic的各个Queue的消费进度。\nRebalance 机制集群消费模式才会存在 Rebalance 的情况Rebalance 指的是将一个 Topic 下的多个 Queue 在同一个 Consumer Group 中的多个 Consumer 间进行重新分配的过程。导致Rebalance产生的原因，无非就两个：消费者所订阅Topic的Queue数量发生变化，或消费者组中消费者的数量发生变化。\n\n举个列子：一个Topic下 5 个队列，在只有 1 个消费者的情况下，这个消费者将负责消费这 5 个队列的消息。如果增加一个消费者，那么就可以给其中一个消费者分配 2 个队列，给另一个分配 3 个队列。\n\nRebalance 限制由于一个队列最多分配给一个消费者，因此当某个消费者组下的消费者实例数量大于队列的数量时，多余的消费者实例将分配不到任何队列。\nRebalance 带来的问题1. 消费暂停比如在新增了一个 Consumer 后会触发Rebalanc，这个时候之前的 Consumer 就需要暂停消费，等重新分配完才会再重新工作。2. 消费重复重新分配之后，加入的 Consumer 会接着之前队列所属的 Consumer 的进度 offset 继续消费，如果之前 Consumer 消费的offset没有提交，就会导致重复消费。3. 消费突刺由于Rebalance可能导致重复消费，如果需要重复消费的消息过多，或者因为Rebalance暂停时间过长从而导致积压了部分消息。那么有可能会导致在Rebalance结束之后瞬间需要消费很多消息。\nQueue 分配算法一个 Topic 中的 Queue 只能由 Consumer Group 中的一个 Consumer 进行消费，而一个 Consumer 可以同时消费多个 Queue 中的消息。queue要分配给哪个Consumer进行消费，有几种常见的策略。平均分配策略根据 avg = QueueCount / ConsumerCount 的计算结果进行分配的。如果能够整除，则按顺序将 avg 个 Queue 逐个分配 Consumer,如果不能整除，则将多余出的 Queue  按照 Consumer 顺序逐个分配。环形平均策略根据消费者的顺序，依次在由queue队列组成的环形图中逐个分配（该算法不用事先计算每个Consumer需要分配几 个Queue，直接一个一个分即可）。 \n一致性hash策略将 consumer 的 hash 值作为 Node 节点存放到 hash 环上，然后将 queue 的 hash 值也放到 hash 环上，通过顺时针方向，距离 queue 最近的那个 consume r就是该 queue 要分配的 consumer。\n至少一次原则RocketMQ 有一个原则：每条消息必须要被成功消费一次。\n\nConsumer 在消费完消息后会向其消费进度记录器提交其消费消息的 offset，offset 被成功记录到记录器中，那么这认为条消费就被成功消费了。对于广播消费模式来说，Consumer本身就是消费进度记录器。对于集群消费模式来说，Broker是消费进度记录器。\n\n消费幂等消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响，那么这个消费过程就是消费幂等的。\n\n若某操作执行多次与执行一次对系统产生的影响是相同的，则称该操作是幂等的。\n\n消息重复的场景发送时消息重复消息到了 Broker 并完成持久化，因为网络或者其他原因 Broker 对 Producer 应答失败，这个时候Producer意识到消息发送失败并尝试再次发送消息，此时Broker中就可能会出现两条内容相同并且Message ID也相同的消息，那么后续Consumer就一定会消费两次该消息。\n消费时消息重复Consumer 消费之后没有对对 Broker 发送成功响应，为了保证消息至少被消费一次的原则，Broker 会再次尝试投递之前已被处理过的消息，此时消费者就会收到与之前处理过的内容相同、Message ID也相同的消息。\nRebalance 时消息重复发生 Rebalance 的时候，因为新的 Consumer 是从之前 Consumer 的 offset 开始消费的，如果之前消费的 offset 没有成功写入，此时 Consumer 可能会收到曾经被消费过的消息\n通用解决方案设计的两个要素\n\n幂等令牌：是生产者和消费者两者中的既定协议，通常指具备唯一业务标识的字符串。例如，订单号、流水号。一般由Producer随着消息一同发送来的。\n唯一性处理：服务端通过采用一定的算法策略，保证同一个业务逻辑不会被重复执行成功多次。例如，对同一笔订单的多次支付操作，只会成功一次。\n\n通用性解决方案\n\n首先通过缓存去重。在缓存中如果已经存在了某幂等令牌，则说明本次操作是重复性操作，若缓存没有命中，则进入下一步。 \n在唯一性处理之前，先在数据库中查询幂等令牌作为索引的数据是否存在。若存在，则说明本次操作为重复性操作，若不存在，则进入下一步。\n在同一事务中完成三项操作：唯一性处理后，将幂等令牌写入到缓存，并将幂等令牌作为唯一索引的数据写入到DB中。基本思路就是指定不会重复的唯一标识，不建议以Message ID作为处理依据，最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息Key设置。\n\n消息的清理消息的清理是以消息为单位进行清理的，而是以commitlog文件为单位进行清理的。commitLog文件过期时间默认为 72 小时自动清理的情况：\n\n文件过期，且到达清理时间点（默认为凌晨 4 点）后，自动清理过期文件。\n文件过期，且磁盘空间占用率已达过期清理警戒线（默认75%）后，无论是否达到清理时间点，都会自动清理过期文件。\n磁盘占用率达到清理警戒线（默认85%）后，开始按照设定好的规则清理文件，无论是否过期。默认会从最老的文件开始清理。\n磁盘占用率达到系统危险警戒线（默认90%）后，Broker将拒绝消息写入\n\n\n注意两点\n\n删除是一个压力巨大的IO操作，删除会造成系统性能会骤然下降。默认清理时间点为凌晨 4 点，访问量最小的时间，所以尽量要保障磁盘空间的空闲率，不要使系统出现在其它时间点删除commitlog文件的情况\n官方建议RocketMQ服务的Linux文件系统采用ext4。因为对于文件删除操作，ext4要比ext3性能更好\n\n\n","categories":["RocketMQ"]},{"title":"RocketMQ Docker 环境","url":"/2023/01/05/rocketmq-docker.html","content":"使用 docker compose 搭建 RocketMQ 环境\n\n\n目录结构rocketmq├── .env├── broker│   ├── Dockerfile│   ├── broker.conf│   └── data│       ├── logs│       └── store├── docker-compose.yml└── namesrv    ├── Dockerfile    └── data        ├── logs        │   └── rocketmqlogs        │       ├── namesrv.log        │       └── namesrv_default.log        └── store\n\n.env# 本机IPDOCKER_HOST_IP=192.168.31.211# RocketMQ版本ROCKETMQ_VERSION=4.4.0# RocketMQ端口ROCKET_SERVER_PORT=9876\n\nnamesrv/DockerfileARG ROCKETMQ_VERSIONFROM rocketmqinc/rocketmq:$&#123;ROCKETMQ_VERSION&#125;CMD [&quot;sh&quot;, &quot;mqnamesrv&quot;]\n\nbroker/DockerfileARG ROCKETMQ_VERSIONFROM rocketmqinc/rocketmq:$&#123;ROCKETMQ_VERSION&#125;ARG LOCAL_HOST_IPRUN echo $&#123;LOCAL_HOST_IP&#125;## 修改配置内容USER root# 覆盖配置文件COPY broker.conf /opt/rocketmq-$&#123;ROCKETMQ_VERSION&#125;/conf/broker.conf# 动态修改IPRUN sed -i &quot;s/dockerHost/$&#123;LOCAL_HOST_IP&#125;/g&quot; /opt/rocketmq-$&#123;ROCKETMQ_VERSION&#125;/conf/broker.conf\n\nbroker/broker.conf# 所属集群名字brokerClusterName=DefaultCluster# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a,# 在 broker-b.properties 使用: broker-bbrokerName=broker-a# 0 表示 Master，大于 0 表示 SlavebrokerId=0# nameServer地址，分号分割# namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &amp;lt;192.168.0.120:10909&amp;gt; failed# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，# 解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP# “dockerHost”只是一个占位的，在定义Dockerfile的时候是替换成本机IP的brokerIP1=dockerHost# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，falseautoCreateTopicEnable=true# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true# Broker 对外服务的监听端口listenPort=10911# 删除文件时间点，默认凌晨4点deleteWhen=04# 文件保留时间，默认48小时fileReservedTime=120# commitLog 每个文件的大小默认1GmapedFileSizeCommitLog=1073741824# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整mapedFileSizeConsumeQueue=300000# destroyMapedFileIntervalForcibly=120000# redeleteHangedFileInterval=120000# 检测物理文件磁盘空间diskMaxUsedSpaceRatio=88# 存储路径# storePathRootDir=/home/ztztdata/rocketmq-all-4.1.0-incubating/store# commitLog 存储路径# storePathCommitLog=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/commitlog# 消费队列存储# storePathConsumeQueue=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/consumequeue# 消息索引存储路径# storePathIndex=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/index# checkpoint 文件存储路径# storeCheckpoint=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/checkpoint# abort 文件存储路径# abortFile=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/abort# 限制的消息大小maxMessageSize=65536# flushCommitLogLeastPages=4# flushConsumeQueueLeastPages=2# flushCommitLogThoroughInterval=10000# flushConsumeQueueThoroughInterval=60000# Broker 的角色# - ASYNC_MASTER 异步复制Master# - SYNC_MASTER 同步双写Master# - SLAVEbrokerRole=ASYNC_MASTER# 刷盘方式# - ASYNC_FLUSH 异步刷盘# - SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH# 发消息线程池数量# sendMessageThreadPoolNums=128# 拉消息线程池数量# pullMessageThreadPoolNums=128\n\ndocker-compse.yamlversion: &quot;3&quot;networks:  rocket_n:    driver: bridgeservices:  rocketmq:    build:      context: ./namesrv      args:        - ROCKETMQ_VERSION=$&#123;ROCKETMQ_VERSION&#125;    volumes:      - ./namesrv/data/logs:/opt/logs      - ./namesrv/data/store:/opt/store    ports:      - &quot;$&#123;ROCKET_SERVER_PORT&#125;:9876&quot;    environment:      JAVA_OPT_EXT: &quot;-Duser.home=/opt -Xms512M -Xmx512M -Xmn128m&quot;      MAX_POSSIBLE_HEAP: 100000000    networks:      - rocket_n  rocketmq-broker:    build:      context: ./broker      args:        - LOCAL_HOST_IP=$&#123;DOCKER_HOST_IP&#125;        - ROCKETMQ_VERSION=$&#123;ROCKETMQ_VERSION&#125;    volumes:      - ./broker/data/logs:/opt/logs      - ./broker/data/store:/opt/store    ports:      - 10909:10909      - 10911:10911      - 10912:10912    command: sh mqbroker -n rocketmq:9876 -c ../conf/broker.conf    environment:      - JAVA_HOME=/usr/lib/jvm/jre    depends_on:      - rocketmq    networks:      - rocket_n  rocketmq-console:    image: styletang/rocketmq-console-ng    ports:      - 8087:8080    environment:      - JAVA_OPTS= -Dlogging.level.root=info   -Drocketmq.namesrv.addr=rocketmq:9876      - Dcom.rocketmq.sendMessageWithVIPChannel=false    depends_on:      - rocketmq    networks:      - rocket_n\n\n$ docker compose up -d\n\n访问设置的本地IP:8087\n\n","categories":["RocketMQ"]},{"title":"RocketMQ 消息发送","url":"/2023/01/06/rocketmq-producer.html","content":"简单的记录一下 RocketMQ 消息发送的方式\n\n\n消息发送方式RocketMQ支持3种消息发送方式：\n\n单向\n同步\n异步\n\n单向发送producer 只负责发送消息，不等待 broker 发回响应结果，而且也没有回调函数触发，这也就意味着 producer 只发送请求不等待响应结果。发送消息的过程耗时非常短，一般在微秒级别。\n一般用在日志收集这种对可靠性要求并不高的场景\n同步发送同步发送消息是指，Producer发出一条消息后，会在收到MQ返回的ACK之后才发下一条消息。该方式的消息可靠性最高，但消息发送效率太低。\n适合一些发送比较重要的消息场景，比如说重要的通知邮件、营销短信等等\n需要注意：这种方式具有内部重试机制，默认为2次，发送的结果存在同一个消息可能被多次发送给给broker，这里需要应用的开发者自己在消费端处理幂等性问题。\n异步发送producer 发出一条消息后，不需要等待 broker 响应，就接着发送下一条消息的通信方式。需要注意的是，不等待 broker 响应，并不意味着 broker 不响应，而是通过回调接口来接收 broker 的响应。所以要记住一点，异步发送同样可以对消息的响应结果进行处理。\n适合于一些比较注重响应时间的场景，比如上传视频之后的转码，上传成功马上返回成功，转码成功之后通过回调函数通知调用方。\nRocketMQ内部只对同步模式做了重试，异步发送模式是没有自动重试的，需要自己手动实现\n消息批量发送发送限制：\n\n同一批发送的消息的Topic必须相同\n批量发送的消息必须具有相同的刷盘策略\n批量发送的消息不能是延时消息与事务消息\n\n一批发送的消息总大小不能超过 4MB ，如果超出了可以将消息拆分再批量发送，还可以修改Producer端与Broker端的属性，Producer端需要在发送之前设置Producer 的maxMessageSize 属性, Broker 端需要修改其加载的配置文件中的maxMessageSize属性。\n消息的生产Producer 可以将消息写入到某 Broker 中的某 Queue 中，大致过程如下：\n\nProducer 发送消息之前，会先向 NameServer 发出获取消息 Topic 的路由信息的请求\nNameServer 返回该 Topic 的路由表及 Broker 列表\nProducer 根据指定的 Queue 选择策略，从 Queue 列表中选出一个队列，用于后续存储消息\nProduer 对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩\nProducer 向选择出的 Queue 所在的 Broker 发出 RPC 请求，将消息发送到选择出的 Queue\n\nQueue 选择策略轮询算法默认选择算法。该算法保证了每个Queue中可以均匀的获取到消息。如果某个Broker上的Queue投递延迟较严重，就会导致Producer的缓存队列中出现较大的消息积压，影响消息的投递性能。\n最小投递延迟算法会统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。如果延迟相同，则采用轮询算法投递。该算法可以有效提升消息的投递性能。这个算法会造成Queue上的分配不均匀。投递延迟小的Queue其可能会存在大量的消息。而对该Queue的消费者压力会增大，降低消息的消费能力，可能会导致MQ中消息的堆积。\n","categories":["RocketMQ"]},{"title":"RocketMQ 消息存储","url":"/2023/01/08/rocketmq-msg-save.html","content":"RocketMQ 中的消息存储在本地文件系统中，这些相关文件默认在当前用户主目录下的 store 目录中，主要存储的文件包括 Commitlog 文件、 ConsumeQueue文件、 IndexFile等。\n\n\n消息存储结构目录结构\n\n\nabort：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动Broker的情况下，发现这个文件是存在的，则说明之前Broker的关闭是非正常关闭。\ncheckpoint：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳\ncommitlog：其中存放着commitlog文件，而消息是写在commitlog文件中的\nconfig：存放着Broker运行期间的一些配置数据\nconsumequeue：其中存放着consumequeue文件，队列就存放在这个目录中\nindex：其中存放着消息索引文件indexFile\nlock：运行期间使用到的全局资源锁\n\nCommitLogCommitLog 以物理文件的方式存放，每台 Broker 上的 CommitLog 被本机器所有 ConsumeQueue 共享，文件地址：$ &#123;user.home&#125; \\store$ &#123; commitlog&#125; \\ $ &#123; fileName&#125;。\n文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。\n一个 Broker 中只包含一个 CommitLog 目录，无论当前Broker中存放着多少Topic的消息，这些消息都是被顺序写入到了 CommitLog 下面，这些消息在Broker中存放时并没有被按照Topic进行分类存放。\n文件的消息单元存储详细信息\n每个消息单元中包含消息总长度MsgLen、消息的物理位置physicalOffset、消息体内容Body、消息体长度BodyLength、消息主题Topic、Topic长度 TopicLength、消息生产者BornHost、消息发送时间戳BornTimestamp、消息所在的队列QueueId、消息在Queue中存储的偏移量QueueOffset等近 20 余项消息相关属性。\n\n\n\n序号\n字段\n大小（字节）\n含义\n\n\n\n1\nmsgSize\n4\n代表这个消息的大小\n\n\n2\nMAGICCODE\n4\nMAGICCODE = daa320a7\n\n\n3\nBODY CRC\n4\n消息体BODY CRC 当broker重启recover时会校验\n\n\n4\nqueueId\n4\n\n\n\n5\nflag\n4\n\n\n\n6\nQUEUEOFFSET\n8\n这个值是个自增值不是真正的consume queue的偏移量，可以代表这个consumeQueue队列或者tranStateTable队列中消息的个数，若是非事务消息或者commit事务消息，可以通过这个值查找到consumeQueue中数据，QUEUEOFFSET * 20才是偏移地址；若是PREPARED或者Rollback事务，则可以通过该值从tranStateTable中查找数据\n\n\n7\nPHYSICALOFFSET\n8\n代表消息在commitLog中的物理起始地址偏移量\n\n\n8\nSYSFLAG\n4\n指明消息是事物事物状态等消息特征，二进制为四个字节从右往左数：当4个字节均为0（值为0）时表示非事务消息；当第1个字节为1（值为1）时表示表示消息是压缩的（Compressed）；当第2个字节为1（值为2）表示多消息（MultiTags）；当第3个字节为1（值为4）时表示prepared消息；当第4个字节为1（值为8）时表示commit消息；当第3/4个字节均为1时（值为12）时表示rollback消息；当第3/4个字节均为0时表示非事务消息\n\n\n9\nBORNTIMESTAMP\n8\n消息产生端(producer)的时间戳\n\n\n10\nBORNHOST\n8\n消息产生端(producer)地址(address:port)\n\n\n11\nSTORETIMESTAMP\n8\n消息在broker存储时间\n\n\n12\nSTOREHOSTADDRESS\n8\n消息存储到broker的地址(address:port)\n\n\n13\nRECONSUMETIMES\n8\n消息被某个订阅组重新消费了几次（订阅组之间独立计数）,因为重试消息发送到了topic名字为%retry%groupName的队列queueId=0的队列中去了，成功消费一次记录为0；\n\n\n14\nPreparedTransaction Offset\n8\n表示是prepared状态的事物消息\n\n\n15\nmessagebodyLength\n4\n消息体大小值\n\n\n16\nmessagebody\n\n消息体内容\n\n\n17\ntopicLength\n1\ntopic名称内容大小\n\n\n18\ntopic\n\ntopic的内容值\n\n\n19\npropertiesLength\n2\n属性值大小\n\n\n20\nproperties\n\npropertiesLength大小的属性数据\n\n\nConsumequeue由于不同的主题的消息不连续的存储在commitlog文件中，如果只是检索该消息文件速度就会很慢，为了加快消息的检索和节省磁盘空间，每一个consumequeue条目存储了消息的关键信息commitog文件中的偏移量、消息长度、tag的hashcode值。\nConsumeQueue 文件类似数据库的索引文件，存储的是指向物理存储的地址。每个 Topic 下的每个 Message Queue 都有一个对应的 ConsumeQueue 文件。\n\n性能提升\nconsumequeue中的数据是顺序存放的，还引入了 PageCache 的预读取机制，使得对 consumequeue 文件的读取几乎接近于内存读取，即使在有消息堆积情况下也不会影响性能。\n\nPageCache机制，页缓存机制，是OS对文件的缓存机制，用于加速对文件的读写操作。Write:OS会先将数据写入到PageCache中，随后会以异步方式将Cache中的数据刷盘到物理磁盘Read:首先会从PageCache中读取，若没有命中，则OS在从物理磁盘上加载该数据到PageCache的同时，也会顺序 对其相邻数据块中的数据进行预读取。\n\nIndexFileindex 存的是索引文件，可以提高根据主题与消息检索 消息的速度 ，使用 Hash 索引机制，具体是 Hash 槽与 Hash 冲突的链表结构。\n每个indexFile文件由三部分构成：indexHeader，slots槽位，indexes索引数据。\nindexHeaderindexHeader 固定占用 40 个字节，其中存放着如下数据：\n\nbeginTimestamp：该indexFile中第一条消息的存储时间\nendTimestamp：该indexFile中最后一条消息存储时间\nbeginPhyoffset：该indexFile中第一条消息在commitlog中的偏移量commitlog offset\nendPhyoffset：该indexFile中最后一条消息在commitlog中的偏移量commitlog offset\nhashSlotCount：已经填充有index的slot数量（并不是每个slot槽下都挂载有index索引单元，这里统计的是所有挂载了index索引单元的slot槽的数量）\nindexCount：该indexFile中包含的索引单元个数（统计出当前indexFile中所有slot槽下挂载的所有index索引单元的数量之和）\n\nHash 槽一个 IndexFile 默认包含 500W 个 Hash 槽，每个 Hash 槽存储的是落在该 Hash 槽的 hashcode 最新的 Index 的索引。key 的 hash值 % 500w 的结果即为 slot 槽位，然后将该 slot 值修改为该 index 索引单元的 indexNo，根据这个 indexNo 可以计算出该 index 单元在 indexFile    中的位置。为了解决取模重复很高的问题，在每个index索引单元中增加了preIndexNo，用于指定该slot中当前index索引单元的前一个index索引单元。而slot中始终存放的是其下最新的index索引单元的indexNo，\n\nindexNo 是一个在 indexFile 中的流水号，从 0 开始依次递增。即在一个 indexFile 中所有 indexNo 是以此递增的。indexNo 在 index 索引单元中是没有体现的，其是通过 indexes 中依次数出来的。\n\n\nindexes索引数据index索引单元默写 20 个字节，其中存放着以下四个属性：\n\nkeyHash：消息中指定的业务key的hash值\nphyOffset：当前key对应的消息在commitlog中的偏移量commitlog offset\ntimeDiff：当前key对应消息的存储时间与当前indexFile创建时间的时间差\npreIndexNo：当前slot下当前index索引单元的前一个index索引单元的indexNo\n\nindexFile的创建indexFile的创建时机\n\n当第一条带 key 的消息发送来后，系统发现没有 indexFile，此时会创建第一个 indexFile 文件\n当一个 indexFile 中挂载的 index 索引单元数量超出2000w个时，会创建新的 indexFile。当带key的消息发送到来后，系统会找到最新的 indexFile，并从其indexHeader的最后 4 字节中读取到indexCount。若indexCount &gt;= 2000w时，会创建新的indexFile。\n\nCheckpointcheckpoint文件的作用是记录commitlog、consumequeue、index文件的刷盘时间点，文件固定长度4k,其中只用了该文件的前24个字节。查看其存储格式\n\nphysicMsgTimestamp：commitlog文件刷盘时间点\nlogicsMsgTimestamp：消息的消费队列文件刷盘时间点\nindexMsgTimestamp：索引文件刷盘时间点\n\nConfigconfig 文件夹中 存储着 Topic 和 Consumer 等相关信息。主题和消费者群组相关的信息就存在在此。\n\ntopics.json：topic 配置属性\nsubscriptionGroup.json：消息消费组配置信息。\ndelayOffset.json：延时消息队列拉取进度。\nconsumerOffset.json：集群消费模式消息消进度。consumerFilter.json ：主题消息过滤信息。\n\n","categories":["RocketMQ"]},{"title":"终端配置代理","url":"/2021/06/01/terminal-proxy.html","content":"Mac配置了Vpn，在浏览器中访问可以，但是在命令行中就不可以，需要配置http_proxy每次重新打开都要输入一下命令，太麻烦，写两个函数扔到.zshrc中\n\n\n设置代理函数function proxy_on() &#123;    export http_proxy=http://127.0.0.1:xxxx    export https_proxy=http://127.0.0.1:xxxx    echo &quot;已开启代理&quot;&#125;function proxy_off() &#123;    unset http_proxy    unset https_proxy    echo &quot;已关闭代理&quot;&#125;# 查看IP来源alias ip_info=&quot;curl http://www.cip.cc/&quot;\n\n使用方法在终端直接运行下面的命令(要先执行 source ~/.zshrc )proxy_on  即可打开终端http代理proxy_off  关闭终端http代理ip_info 查看IP来源信息\n","categories":["随手记"],"tags":["iterm2","proxy"]},{"title":"Vagrant","url":"/2021/07/19/vagrant-record.html","content":"搭建学习环境需要的东西，记录一下\n\n\n安装JDKsudo apt-get install openjdk-8-jdk\n\n软件下载地址zookeeper:https://archive.apache.org/dist/zookeeper/zookeeper-3.5.7/apache-zookeeper-3.5.7-bin.tar.gzkafkahttps://archive.apache.org/dist/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz-- /home/vagrant/opt/apps/kafka_2.11-0.11.0.0/bin/kafka-server-start.sh*if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then\t#export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;\texport KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms256M&quot;fi\n\n环境变量#ZK_HOMEexport ZK_HOME=/home/vagrant/opt/apps/zookeeper-3.5.7export PATH=$PATH:$ZK_HOME/bin#KAFKA_HOMEexport KAFKA_HOME=/home/vagrant/opt/apps/kafka_2.11-0.11.0.0export PATH=$PATH:$KAFKA_HOME/bin\n\nvagrant ssh 登录# 修改root密码sudo passwd# 修改ssh配置/etc/ssh/sshd_configPermitRootLogin yesPasswordAuthentication yes# 重启sshd服务service sshd restart\n\nvagrant大概配置Vagrant.configure(&quot;2&quot;) do |config|  config.vm.box = &quot;ubuntu/xenial64&quot;  config.vm.hostname = &quot;Study-01&quot;  config.vm.network &quot;private_network&quot;, ip: &quot;10.0.0.10&quot;  config.vm.provider &quot;virtualbox&quot; do |vb|    vb.memory = &quot;1024&quot;    vb.name = &quot;Study-01&quot;  endend\n\n","categories":["随手记"],"tags":["vagrant"]}]